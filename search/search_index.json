{
    "docs": [
        {
            "location": "/", 
            "text": "Overview\n\n\nThe aim of this tutorial is to provide a step by step guide as to how to perform basic polygenic risk score analyses, therefore\nallow for a better understanding of the inner mechanism implemented in most polygenic risk score software. \n\n\nThe tutorial is separated into three main sections\n\n\n\n\nHow to perform basic filtering on the summary statistic file (Base)\n\n\nHow to perform quanilty controls on the target genotype file\n\n\nThe details steps involved in calculating PRS (using \nplink\n)\n\n\n\n\nWe also provided a brief example on how to perform PRS using the three polygenic risk score software: \nPRSice-2\n, \nLDpred\n and \nlassosum\n\n\nIf you are only interested in how to perform PRS, you can directly skipped to (step 3)[plink.md]. Links to download the required data are provided under each section.\n\n\n\n\nNote\n\n\nThis tutorial is based on linux and OS X systems. Users who would like to perform polygenic risk score analyses\non their Windows machine will need to change some of the commands.\n\n\n\n\n\n\nNote\n\n\nThroughout the tutorial, you might see some codes with tab on top:\n\n\n\n\n\n\nA\n\n\necho\n \nTab A\n\n\n\n\n\n\nB\n\n\necho\n \nTab B\n\n\n\n\n\n\nYou can click on the tab to change to relevant codes (e.g. different operation system)\n\n\n\n\nRequirements\n\n\nTo follow the tutorial, you will need the following programs installed:\n\n\n\n\nR\n (\nversion 3.2.3+\n)\n\n\nPLINK 1.9\n\n\n\n\nCitation\n\n\nIf you find this tutorial helpful, then please cite:\n\n\n\n\nCitation\n\n\nA guide to performing Polygenic Risk Score analyses, \n\n\nShing Wan Choi, Timothy Shin Heng Mak, Paul O'Reilly \n\n\nbioRxiv 416545 (2018). doi:10.1101/416545", 
            "title": "Overview"
        }, 
        {
            "location": "/#overview", 
            "text": "The aim of this tutorial is to provide a step by step guide as to how to perform basic polygenic risk score analyses, therefore\nallow for a better understanding of the inner mechanism implemented in most polygenic risk score software.   The tutorial is separated into three main sections   How to perform basic filtering on the summary statistic file (Base)  How to perform quanilty controls on the target genotype file  The details steps involved in calculating PRS (using  plink )   We also provided a brief example on how to perform PRS using the three polygenic risk score software:  PRSice-2 ,  LDpred  and  lassosum  If you are only interested in how to perform PRS, you can directly skipped to (step 3)[plink.md]. Links to download the required data are provided under each section.   Note  This tutorial is based on linux and OS X systems. Users who would like to perform polygenic risk score analyses\non their Windows machine will need to change some of the commands.    Note  Throughout the tutorial, you might see some codes with tab on top:    A  echo   Tab A    B  echo   Tab B    You can click on the tab to change to relevant codes (e.g. different operation system)", 
            "title": "Overview"
        }, 
        {
            "location": "/#requirements", 
            "text": "To follow the tutorial, you will need the following programs installed:   R  ( version 3.2.3+ )  PLINK 1.9", 
            "title": "Requirements"
        }, 
        {
            "location": "/#citation", 
            "text": "If you find this tutorial helpful, then please cite:   Citation  A guide to performing Polygenic Risk Score analyses,   Shing Wan Choi, Timothy Shin Heng Mak, Paul O'Reilly   bioRxiv 416545 (2018). doi:10.1101/416545", 
            "title": "Citation"
        }, 
        {
            "location": "/base/", 
            "text": "First step in Polygenic Risk Score (PRS) analyses is to obtain the GWAS summary statistics. \n\n\nIn this example, we will use a modified version of the Height GWAS summary statistics generated by the \nGIANT consortium\n\n\nObtaining the summary statistic file\n\n\nYou can download the summary statistic file using the following script:\n\ncurl https://github.com/choishingwan/PRS-Tutorial/raw/master/resources/GIANT.height.gz -L -O\n\n\n\nwhich will create a file call \nGIANT.height.gz\n in your current directory. \n\n\nA common problem is that the downloaded file can be corrupted, which can generate various error messages in the \ndown-stream analyses. To avoid un-necessary waste of time, it is generally a good practice to check if the file is\nintact. This can be done by performing the \nmd5sum\n check:\n\n\n\n\n\n\nLinux\n\n\nmd5sum GIANT.height.gz\n\n\n\n\n\nOS X\n\n\nmd5 GIANT.height.gz\n\n\n\n\n\nif the file is intact, \nmd5sum\n should generate a string of characters: \nc79734b099cea663d2808bfde2e9a422\n. \nIf a different string is generated, the file is likely corrupted \n\n\n\n\nNote\n\n\nIn most scenarios, a different \nmd5sum\n is generated for different files. Therefore it is a nice simple way of \nchecking whether the file is downloaded correctly. \n\n\n\n\nReading the summary statistic file\n\n\nGIANT.height.gz\n is compressed. To read its content, you can type:\n\n\ngunzip -c GIANT.height.gz \n|\n head\n\n\n\n\nwhich will shows the first 10 lines of the file\n\n\n\n\nNote\n\n\nIn general, we like to work with compressed files to reduce storage space requirements\n\n\n\n\nThe \nGIANT.height.gz\n file contains the following columns:\n\n\n\n\n\n\n\n\nSNP\n\n\nCHR\n\n\nBP\n\n\nA1\n\n\nA2\n\n\nMAF\n\n\nSE\n\n\nP\n\n\nN\n\n\nINFO\n\n\nOR\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith each column corresponds to the following\n\n\n\n\nSNP\n: SNP ID, usually in the form of RS-ID\n\n\nCHR\n: The chromosome of which the SNP resides on\n\n\nBP\n: Chromosomal coordinate of the SNP\n\n\nA1\n: The effective alllele of the SNP\n\n\nA2\n: The non-effective allele of the SNP\n\n\nMAF\n: The minor allele frequency of the SNP\n\n\nSE\n: The standard error of the effect size esimate\n\n\nP\n: The P-value of association between the genotype of the SNP and the phenotype of interest\n\n\nN\n: Number of samples used to obtain the effect size estimate\n\n\nINFO\n: Usually the imputation information score. \n\n\nOR\n: The effect size estimate of the SNP. Can also be BETA\n\n\n\n\n\n\nImportant\n\n\nSome GWAS results files do not make clear which allele is the effect allele and which the non-effect allele. \nIf the incorrect assumption is made in computing the PRS, then the effect of the PRS in the target data will be in the wrong direction, and so to avoid misleading conclusions it is critical that the effect allele from the base (GWAS) data is known.\n\n\n\n\nRemoving duplicated SNPs\n\n\nWhile it is raw, duplciated SNPs can sometimes be found in your base file.\nAs most PRS software do not allow duplicated SNPs in the base input, and to avoid confusion, \nit might be beneficial to remove the duplicated SNPs from the base file. \n\n\ngunzip -c GIANT.height.gz \n|\n\\\n\nawk \n{ print $1}\n \n|\n\\\n\nsort \n|\n\\\n\nuniq -d \n duplicated.snp\n\n\n\n\nBriefly, the above command does the following:\n\n\n\n\nDecompress and read the \nGIANT.height.gz\n file\n\n\nPrint out the first column of the file (which contains the SNP ID, change \n$1\n to other number if the SNP ID is located in another column, e.g. \n$3\n if the SNP ID is located on the third column)\n\n\nSort the SNP IDs. This will put duplicated SNP IDs next to eachother\n\n\nPrint out any duplicated SNP IDs using the uniq command and print it to the \nduplicated.snp\n file\n\n\n\n\nHow many duplicated SNPs are there?\nThere are a total of \n100\n duplicated SNPs\n\n\n\n\nDuplicated SNPs can then be removed using the \ngrep\n command:\n\ngunzip -c GIANT.height.gz  \n|\n\\\n\ngrep -vf duplicated.snp \n|\n\\\n\ngzip - \n Height.gz\n\n\nThe above script does the following:\n1. Decompress and read the \nGIANT.height.gz\n file \n2. Find if any row contains entries observed in \nduplicated.snp\n and remove them\n3. Compress and write the results to \nHeight.gz\n\n\nFiltering SNPs with low INFO score or MAF\n\n\nSNPs with low minor allele frequency (MAF) or imputation information score (INFO) are more likely to harbor false positives. \nIt is therefore beneficial to remove SNPs with low MAF and INFO.\nThis is acheived by the following:\n\n\ngunzip -c Height.gz \n|\n\\\n\nawk \nNR==1 || ($6 \n 0.05 \n $6 \n 0.95) \n ($10 \n 0.8) {print}\n \n|\n\\\n\ngzip - \n Height.QC.gz\n\n\n\n\n\n\nDecompress and read the \nHeight.gz\n file\n\n\nPrint the header line (\nNR==1\n)\n\n\nPrint any line with MAF above 0.05 and less than 0.95 (\n$6\n because the sixth column of the file contains the MAF information)\n\n\nPrint any line with INFO above 0.8 (\n$10\n because the tenth column of the file contains the INFO information)\n\n\nCompress and write the result to \nHeight.QC.gz\n\n\n\n\nThe \nHeight.QC.gz\n file can then be used for downstream analyses", 
            "title": "1. QC of Summary Statistics"
        }, 
        {
            "location": "/base/#obtaining-the-summary-statistic-file", 
            "text": "You can download the summary statistic file using the following script: curl https://github.com/choishingwan/PRS-Tutorial/raw/master/resources/GIANT.height.gz -L -O  which will create a file call  GIANT.height.gz  in your current directory.   A common problem is that the downloaded file can be corrupted, which can generate various error messages in the \ndown-stream analyses. To avoid un-necessary waste of time, it is generally a good practice to check if the file is\nintact. This can be done by performing the  md5sum  check:    Linux  md5sum GIANT.height.gz   OS X  md5 GIANT.height.gz   if the file is intact,  md5sum  should generate a string of characters:  c79734b099cea663d2808bfde2e9a422 . \nIf a different string is generated, the file is likely corrupted    Note  In most scenarios, a different  md5sum  is generated for different files. Therefore it is a nice simple way of \nchecking whether the file is downloaded correctly.", 
            "title": "Obtaining the summary statistic file"
        }, 
        {
            "location": "/base/#reading-the-summary-statistic-file", 
            "text": "GIANT.height.gz  is compressed. To read its content, you can type:  gunzip -c GIANT.height.gz  |  head  which will shows the first 10 lines of the file   Note  In general, we like to work with compressed files to reduce storage space requirements   The  GIANT.height.gz  file contains the following columns:     SNP  CHR  BP  A1  A2  MAF  SE  P  N  INFO  OR                    With each column corresponds to the following   SNP : SNP ID, usually in the form of RS-ID  CHR : The chromosome of which the SNP resides on  BP : Chromosomal coordinate of the SNP  A1 : The effective alllele of the SNP  A2 : The non-effective allele of the SNP  MAF : The minor allele frequency of the SNP  SE : The standard error of the effect size esimate  P : The P-value of association between the genotype of the SNP and the phenotype of interest  N : Number of samples used to obtain the effect size estimate  INFO : Usually the imputation information score.   OR : The effect size estimate of the SNP. Can also be BETA    Important  Some GWAS results files do not make clear which allele is the effect allele and which the non-effect allele. \nIf the incorrect assumption is made in computing the PRS, then the effect of the PRS in the target data will be in the wrong direction, and so to avoid misleading conclusions it is critical that the effect allele from the base (GWAS) data is known.", 
            "title": "Reading the summary statistic file"
        }, 
        {
            "location": "/base/#removing-duplicated-snps", 
            "text": "While it is raw, duplciated SNPs can sometimes be found in your base file.\nAs most PRS software do not allow duplicated SNPs in the base input, and to avoid confusion, \nit might be beneficial to remove the duplicated SNPs from the base file.   gunzip -c GIANT.height.gz  | \\ \nawk  { print $1}   | \\ \nsort  | \\ \nuniq -d   duplicated.snp  Briefly, the above command does the following:   Decompress and read the  GIANT.height.gz  file  Print out the first column of the file (which contains the SNP ID, change  $1  to other number if the SNP ID is located in another column, e.g.  $3  if the SNP ID is located on the third column)  Sort the SNP IDs. This will put duplicated SNP IDs next to eachother  Print out any duplicated SNP IDs using the uniq command and print it to the  duplicated.snp  file   How many duplicated SNPs are there? There are a total of  100  duplicated SNPs   Duplicated SNPs can then be removed using the  grep  command: gunzip -c GIANT.height.gz   | \\ \ngrep -vf duplicated.snp  | \\ \ngzip -   Height.gz \nThe above script does the following:\n1. Decompress and read the  GIANT.height.gz  file \n2. Find if any row contains entries observed in  duplicated.snp  and remove them\n3. Compress and write the results to  Height.gz", 
            "title": "Removing duplicated SNPs"
        }, 
        {
            "location": "/base/#filtering-snps-with-low-info-score-or-maf", 
            "text": "SNPs with low minor allele frequency (MAF) or imputation information score (INFO) are more likely to harbor false positives. \nIt is therefore beneficial to remove SNPs with low MAF and INFO.\nThis is acheived by the following:  gunzip -c Height.gz  | \\ \nawk  NR==1 || ($6   0.05   $6   0.95)   ($10   0.8) {print}   | \\ \ngzip -   Height.QC.gz   Decompress and read the  Height.gz  file  Print the header line ( NR==1 )  Print any line with MAF above 0.05 and less than 0.95 ( $6  because the sixth column of the file contains the MAF information)  Print any line with INFO above 0.8 ( $10  because the tenth column of the file contains the INFO information)  Compress and write the result to  Height.QC.gz   The  Height.QC.gz  file can then be used for downstream analyses", 
            "title": "Filtering SNPs with low INFO score or MAF"
        }, 
        {
            "location": "/target/", 
            "text": "Next, we'd like to perform basic quality controls (QC) on the target genotype data. \n\n\nIn this tutorial, we've simulated some samples using the 1000 genome european genotypes. \nYou can download the data \nhere\n. \n\n\nUnzip the data as follow:\n\n\nunzip EUR.zip\n\n\n\n\nWhat's the md5sum of the genotype files?\n\n\n\n\n\n\nFile\n\n\nmd5sum\n\n\n\n\n\n\n\n\n\n\nEUR.bed\n\n\n96ce8f494a57114eaee6ef9741676f58\n\n\n\n\n\n\nEUR.bim\n\n\n852d54c9b6d1159f89d4aa758869e72a\n\n\n\n\n\n\nEUR.covariate\n\n\nafff13f8f9e15815f2237a62b8bec00b\n\n\n\n\n\n\nEUR.fam\n\n\n8c6463c0d8f32f975cdc423b1b80a951\n\n\n\n\n\n\nEUR.height\n\n\n052beb4cae32ac7673f1d6b9e854c85b\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nWe assume PLINK is installed in your PATH directory, which allow us to use \nplink\n instead of \n./plink\n.\nIf PLINK is not in your PATH directory, replace all instance of \nplink\n in the tutorial to \n./plink\n assuming\nthe PLINK executable is located within your working directory\n\n\n\n\nGenotype file format\n\n\nBasic filterings\n\n\nThe power and validity of PRS analyses are highly dependent on the quality of the base and target data, therefore \nboth data sets must be quality controlled to the high standards implemented in GWAS studies, e.g. removing SNPs according to low genotyping rate, minor allele frequency and individuals with low genotyping rate (see \nMarees et al\n).\n\n\nThe following \nplink\n command perform some basic filterings\n\n\nplink --bfile EUR \n\\\n\n    --maf \n0\n.05 \n\\\n\n    --hwe 1e-6 \n\\\n\n    --geno \n0\n.01 \n\\\n\n    --mind \n0\n.01 \n\\\n\n    --make-bed \n\\\n\n    --out EUR.QC\n\n\nEach of the parameters corresponds to the following\n\n\n\n\n\n\n\n\nParamter\n\n\nValue\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nbfile\n\n\nEUR\n\n\nInform \nplink\n that the input genotype files should have a prefix of \nEUR\n\n\n\n\n\n\nmaf\n\n\n0.05\n\n\nTry to filter out any SNPs with minor allele frequency less than 0.05. Genotype error are more likely to influence SNPs with low MAF. Large sample size can adapt a lower MAF threshold\n\n\n\n\n\n\nhwe\n\n\n1e-6\n\n\nFiltering SNPs with low p-value from the Hardy-Weinberg exact test. SNPs with significant p-value from the HWE test are more likely to harbor genotyping error or are under selection. Filtering should be performed on the control samples to avoid filtering SNPs that are causal (under selection in cases)\n\n\n\n\n\n\ngeno\n\n\n0.01\n\n\nExclude SNPs that are missing in large proportion of subjects. A two pass filtering is usually performed (see \nMarees et al\n).\n\n\n\n\n\n\nmind\n\n\n0.01\n\n\nExclude individual who have a high rate of genotype missingness. This might indicate problems in the DNA sample. (see \nMarees et al\n for more details).\n\n\n\n\n\n\nmake-bed\n\n\n-\n\n\nInform \nplink\n to generate a binary genotype file\n\n\n\n\n\n\nout\n\n\nEUR\n\n\nInform \nplink\n that all output should have a prefix of \nEUR\n\n\n\n\n\n\n\n\nHow many SNPs were filtered?\nA total of \n266\n SNPs were removed due to Hardy-Weinberg exact test results\n\n\n\n\nFilter related samples\n\n\nRelated samples in the target data might lead to overfitted results, hampering the generalizability of the results. \n\n\nTo remove related samples, we first need to perform prunning to remove highly correlated SNPs:\n\nplink \n\\\n\n    --bfile EUR.QC \n\\\n\n    --indep-pairwise \n200\n \n50\n \n0\n.25 \n\\\n\n    --out EUR.QC\n\n\n\nThis will generate two files 1) \nEUR.QC.prune.in\n and 2) \nEUR.QC.prune.out\n\nThe \nEUR.QC.prune.in\n file contains SNPs that has r2 less than 0.25 between them. \n\n\nSamples with more than third-degree relatedness (pi-hat \n 0.125) can then be removed with \n\n\nplink \n\\\n\n    --bfile EUR.QC \n\\\n\n    --extract EUR.QC.prune.in \n\\\n\n    --rel-cutoff \n0\n.125 \n\\\n\n    --out EUR.QC\n\n\n\n\n\n\nNote\n\n\nNormally, we can generate a new genotype file using the new sample list. However, \nthis will use up a lot of storage space. Using \nplink\n's \n--extract\n, \n--exclude\n, \n--keep\n,\n\n--remove\n functions, we can work solely on the list of samples and SNPs without duplicating the \ngenotype file, therefore reducing the storage space usage.  \n\n\n\n\nRemove samples with abnormal heterozygosity rate\n\n\nIndividual with high or low heterozygosity rate can be contaminated or are inbreed.\nIt is therefore a good idea to remove these samples from our dataset before continuing the analyse.\nHeterozygosity rate can be calculated using \nplink\n after performing prunning. \n\nplink \n\\\n\n    --bfile EUR.QC \n\\\n\n    --extract EUR.QC.prune.in \n\\\n\n    --keep EUR.QC.rel.id \n\\\n\n    --het \n\\\n\n    --out EUR\n\n\nThis will generate the \nEUR.het\n file which contains the F coefficient estimates.\nIt will be easier to filter the samples using \nR\n instead of \nawk\n:\nOpen a \nR\n section by tying \nR\n in your terminal\n\ndat \n-\n read.table\n(\nEUR.het\n,\n header\n=\nT\n)\n \n# Read in the EUR.het file, specify it has header\n\nm \n-\n \nmean\n(\ndat\n$\nF\n)\n \n# Calculate the mean  \n\ns \n-\n sd\n(\ndat\n$\nF\n)\n \n# Calculate the SD\n\nvalid \n-\n \nsubset\n(\ndat\n,\n \nF\n \n=\n m\n+3\n*\ns \n \nF\n \n=\n m\n-3\n*\ns\n)\n \n# Get any samples with F coefficient within 3 SD from the population mean\n\nwrite.table\n(\nvalid\n[,\nc\n(\n1\n,\n2\n)],\n \nEUR.valid.sample\n,\n quote\n=\nF\n,\n row.names\n=\nF\n)\n \n# print FID and IID for valid samples\n\n\n\n\nCheck for mis-matched Sex information\n\n\n\n\nNote\n\n\nAs sex chromosome information are missing from our simulated samples. \nIt is not possible to perform the mis-match sex check. (And we used simulated sex)\nThus, this section is only served as a reference in case your samples contain the \nsex chromosome and sex information which permits checking if there are mis-matched sex information\n\n\n\n\nSometimes, sample mislabeling can occur, which can lead to invalid results. \nA good indication of mislabeled sample is a mismatch between the biological sex and the reported sex. \nIf the biological sex does not match up with the reported sex, it is likely that the sample has been mislabeled.\n\n\nBefore performing sex check, prunning should be performed (see \nhere\n).\nSex check can then easily be carried out using \nplink\n\n\nplink \n\\\n\n    --bfile EUR.QC \n\\\n\n    --extract EUR.QC.prune.in \n\\\n\n    --keep EUR.valid.sample \n\\\n\n    --check-sex \n\\\n\n    --out EUR\n\n\n\nThis will generate a file called \nEUR.sexcheck\n containing the F-statistics for each individual.\nFor male, the F-statistic should be \n 0.8 and Female should have a value \n 0.2.\n\n\nawk \nNR==FNR{a[$1]=$5} \\\n\n\n    NR!=FNR \n a[$1]==1 \n $6 \n 0.8 {print $1,$2} \\\n\n\n    NR!=FNR \n a[$1]==2 \n $6 \n 0.2 {print $1,$2} \n \n\\\n\n    EUR.QC.fam EUR.sexcheck \n EUR.valid.sex \n\n\nHere is a breakdown of the above script\n1. Read in the first file (\nNR==FNR\n) and store the sex (\n$5\n) into a dictionary using the FID (\n$1\n) as the key\n2. Read in the second file (\nNR!=FNR\n), if the individual is a male (\na[$1]==1\n) and the F-statistic (\n$6\n) is larger than 0.8, print its FID and IID\n3. Read in the second file (\nNR!=FNR\n), if the individual is a female (\na[$1]==2\n) and the F-statistic (\n$6\n) is less than 0.2, print its FID and IID\n\n\nThe samples can then be extracted using the \n--keep\n command.", 
            "title": "2. Target Genotype QC"
        }, 
        {
            "location": "/target/#genotype-file-format", 
            "text": "", 
            "title": "Genotype file format"
        }, 
        {
            "location": "/target/#basic-filterings", 
            "text": "The power and validity of PRS analyses are highly dependent on the quality of the base and target data, therefore \nboth data sets must be quality controlled to the high standards implemented in GWAS studies, e.g. removing SNPs according to low genotyping rate, minor allele frequency and individuals with low genotyping rate (see  Marees et al ).  The following  plink  command perform some basic filterings  plink --bfile EUR  \\ \n    --maf  0 .05  \\ \n    --hwe 1e-6  \\ \n    --geno  0 .01  \\ \n    --mind  0 .01  \\ \n    --make-bed  \\ \n    --out EUR.QC \nEach of the parameters corresponds to the following     Paramter  Value  Description      bfile  EUR  Inform  plink  that the input genotype files should have a prefix of  EUR    maf  0.05  Try to filter out any SNPs with minor allele frequency less than 0.05. Genotype error are more likely to influence SNPs with low MAF. Large sample size can adapt a lower MAF threshold    hwe  1e-6  Filtering SNPs with low p-value from the Hardy-Weinberg exact test. SNPs with significant p-value from the HWE test are more likely to harbor genotyping error or are under selection. Filtering should be performed on the control samples to avoid filtering SNPs that are causal (under selection in cases)    geno  0.01  Exclude SNPs that are missing in large proportion of subjects. A two pass filtering is usually performed (see  Marees et al ).    mind  0.01  Exclude individual who have a high rate of genotype missingness. This might indicate problems in the DNA sample. (see  Marees et al  for more details).    make-bed  -  Inform  plink  to generate a binary genotype file    out  EUR  Inform  plink  that all output should have a prefix of  EUR     How many SNPs were filtered? A total of  266  SNPs were removed due to Hardy-Weinberg exact test results", 
            "title": "Basic filterings"
        }, 
        {
            "location": "/target/#filter-related-samples", 
            "text": "Related samples in the target data might lead to overfitted results, hampering the generalizability of the results.   To remove related samples, we first need to perform prunning to remove highly correlated SNPs: plink  \\ \n    --bfile EUR.QC  \\ \n    --indep-pairwise  200   50   0 .25  \\ \n    --out EUR.QC  This will generate two files 1)  EUR.QC.prune.in  and 2)  EUR.QC.prune.out \nThe  EUR.QC.prune.in  file contains SNPs that has r2 less than 0.25 between them.   Samples with more than third-degree relatedness (pi-hat   0.125) can then be removed with   plink  \\ \n    --bfile EUR.QC  \\ \n    --extract EUR.QC.prune.in  \\ \n    --rel-cutoff  0 .125  \\ \n    --out EUR.QC   Note  Normally, we can generate a new genotype file using the new sample list. However, \nthis will use up a lot of storage space. Using  plink 's  --extract ,  --exclude ,  --keep , --remove  functions, we can work solely on the list of samples and SNPs without duplicating the \ngenotype file, therefore reducing the storage space usage.", 
            "title": "Filter related samples"
        }, 
        {
            "location": "/target/#remove-samples-with-abnormal-heterozygosity-rate", 
            "text": "Individual with high or low heterozygosity rate can be contaminated or are inbreed.\nIt is therefore a good idea to remove these samples from our dataset before continuing the analyse.\nHeterozygosity rate can be calculated using  plink  after performing prunning.  plink  \\ \n    --bfile EUR.QC  \\ \n    --extract EUR.QC.prune.in  \\ \n    --keep EUR.QC.rel.id  \\ \n    --het  \\ \n    --out EUR \nThis will generate the  EUR.het  file which contains the F coefficient estimates.\nIt will be easier to filter the samples using  R  instead of  awk :\nOpen a  R  section by tying  R  in your terminal dat  -  read.table ( EUR.het ,  header = T )   # Read in the EUR.het file, specify it has header \nm  -   mean ( dat $ F )   # Calculate the mean   \ns  -  sd ( dat $ F )   # Calculate the SD \nvalid  -   subset ( dat ,   F   =  m +3 * s    F   =  m -3 * s )   # Get any samples with F coefficient within 3 SD from the population mean \nwrite.table ( valid [, c ( 1 , 2 )],   EUR.valid.sample ,  quote = F ,  row.names = F )   # print FID and IID for valid samples", 
            "title": "Remove samples with abnormal heterozygosity rate"
        }, 
        {
            "location": "/target/#check-for-mis-matched-sex-information", 
            "text": "Note  As sex chromosome information are missing from our simulated samples. \nIt is not possible to perform the mis-match sex check. (And we used simulated sex)\nThus, this section is only served as a reference in case your samples contain the \nsex chromosome and sex information which permits checking if there are mis-matched sex information   Sometimes, sample mislabeling can occur, which can lead to invalid results. \nA good indication of mislabeled sample is a mismatch between the biological sex and the reported sex. \nIf the biological sex does not match up with the reported sex, it is likely that the sample has been mislabeled.  Before performing sex check, prunning should be performed (see  here ).\nSex check can then easily be carried out using  plink  plink  \\ \n    --bfile EUR.QC  \\ \n    --extract EUR.QC.prune.in  \\ \n    --keep EUR.valid.sample  \\ \n    --check-sex  \\ \n    --out EUR  This will generate a file called  EUR.sexcheck  containing the F-statistics for each individual.\nFor male, the F-statistic should be   0.8 and Female should have a value   0.2.  awk  NR==FNR{a[$1]=$5} \\      NR!=FNR   a[$1]==1   $6   0.8 {print $1,$2} \\      NR!=FNR   a[$1]==2   $6   0.2 {print $1,$2}    \\ \n    EUR.QC.fam EUR.sexcheck   EUR.valid.sex  \nHere is a breakdown of the above script\n1. Read in the first file ( NR==FNR ) and store the sex ( $5 ) into a dictionary using the FID ( $1 ) as the key\n2. Read in the second file ( NR!=FNR ), if the individual is a male ( a[$1]==1 ) and the F-statistic ( $6 ) is larger than 0.8, print its FID and IID\n3. Read in the second file ( NR!=FNR ), if the individual is a female ( a[$1]==2 ) and the F-statistic ( $6 ) is less than 0.2, print its FID and IID  The samples can then be extracted using the  --keep  command.", 
            "title": "Check for mis-matched Sex information"
        }, 
        {
            "location": "/plink/", 
            "text": "In previous sections, we have generated the following files\n\n\n\n\n\n\n\n\nFile Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nHeight.QC.gz\n\n\nThe post-QCed summary statistic\n\n\n\n\n\n\nEUR.QC.bed\n\n\nThe genotype file after performing some basic filtering\n\n\n\n\n\n\nEUR.QC.bim\n\n\nThis file contains the SNPs that passed the basic filtering\n\n\n\n\n\n\nEUR.QC.fam\n\n\nThis file contains the samples that passed the basic filtering\n\n\n\n\n\n\nEUR.valid.sample\n\n\nThis file contains the samples that passed all the QC\n\n\n\n\n\n\nEUR.height\n\n\nThis file contains the phenotype of the samples\n\n\n\n\n\n\nEUR.covariate\n\n\nThis file contains the covariates of the samples\n\n\n\n\n\n\n\n\nHere, we will try to calculate polygenic risk score using \nplink\n. \n\n\nRemove Ambiguous SNPs\n\n\nIf the base and target data were generated using different genotyping chips and the chromosome strand (+/-) for either is unknown, then it is not possible to match ambiguous SNPs (i.e. those with complementary alleles, either C/G or A/T) across the data sets, because it will be unknown whether the base and target data are referring to the same allele or not. \n\n\nAmbiguous SNPs can be obtained by examining the bim file:\n\nawk \n!( ($5==\nA\n \n $6==\nT\n) || \\\n\n\n        ($5==\nT\n \n $6==\nA\n) || \\\n\n\n        ($5==\nG\n \n $6==\nC\n) || \\\n\n\n        ($5==\nC\n \n $6==\nG\n)) {print}\n \n\\\n\n        EUR.QC.bim \n EUR.unambig.snp \n\n\n\nHow many ambiguous SNPs were there?\nThere are \n17,260\n ambiguous SNPs\n\n\n\n\nStrand Flipping\n\n\nAlternatively, when there is a non-ambiguous mismatch in allele coding between the data sets, such as A/C in the base\nand G/T in the target data, then this can be resolved by \u2018flipping\u2019 the alleles in the target data to their complementary alleles. \nThis has to be done with mulitpe steps\n\n\n\n\nGet the correct A1 alleles for the bim file\n\nbim \n-\n read.table\n(\nEUR.QC.bim\n,\n header\n=\nF\n)\n\n\ncolnames\n(\nbim\n)\n \n-\n \nc\n(\nCHR\n,\n \nSNP\n,\n \nCM\n,\n \nBP\n,\n \nB.A1\n,\n \nB.A2\n)\n\nheight \n-\n read.table\n(\ngzfile\n(\nHeight.QC.gz\n),\n header\n=\nT\n)\n\n\n# Avoid complicated factor problem\n\nheight\n$\nA1 \n-\n \ntoupper\n(\nas.character\n(\nheight\n$\nA1\n))\n\nheight\n$\nA2 \n-\n \ntoupper\n(\nas.character\n(\nheight\n$\nA2\n))\n\nbim\n$\nB.A1 \n-\n \ntoupper\n(\nas.character\n(\nbim\n$\nB.A1\n))\n\nbim\n$\nB.A2 \n-\n \ntoupper\n(\nas.character\n(\nbim\n$\nB.A2\n))\n\ninfo \n-\n \nmerge\n(\nbim\n,\n height\n,\n by\n=\nc\n(\nSNP\n,\n \nCHR\n,\n \nBP\n))\n\n\n\n# Function for calculating the complementary allele\n\ncomplement \n-\n \nfunction\n(\nx\n){\n\n    \nswitch\n \n(\nx\n,\n\n        \nA\n \n=\n \nT\n,\n\n        \nC\n \n=\n \nG\n,\n\n        \nT\n \n=\n \nA\n,\n\n        \nG\n \n=\n \nC\n,\n\n        \nreturn\n(\nNA\n)\n\n    \n)\n\n\n}\n\n\n# Now get SNPs that has exact match between base and target\n\ninfo.match \n-\n \nsubset\n(\ninfo\n,\n A1\n==\nB.A1 \n A2\n==\nB.A2\n)\n\n\n# Check for complementary matchs\n\ninfo\n$\nC.A1 \n-\n \nsapply\n(\ninfo\n$\nB.A1\n,\n complement\n)\n\ninfo\n$\nC.A2 \n-\n \nsapply\n(\ninfo\n$\nB.A2\n,\n complement\n)\n\ninfo.complement \n-\n \nsubset\n(\ninfo\n,\n A1\n==\nC.A1 \n A2\n==\nC.A2\n)\n\n\n# Update these allele coding in the bim file \n\nbim\n[\nbim\n$\nSNP \n%in%\n info.complement\n$\nSNP\n,\n \n]\n$\nB.A1 \n-\n \nsapply\n(\nbim\n[\nbim\n$\nSNP \n%in%\n info.complement\n$\nSNP\n,\n \n]\n$\nB.A1\n,\n complement\n)\n\nbim\n[\nbim\n$\nSNP \n%in%\n info.complement\n$\nSNP\n,\n \n]\n$\nB.A2 \n-\n \nsapply\n(\nbim\n[\nbim\n$\nSNP \n%in%\n info.complement\n$\nSNP\n,\n \n]\n$\nB.A2\n,\n complement\n)\n\n\n# identify SNPs that need flipping \n\ninfo.flip \n-\n \nsubset\n(\ninfo\n,\n A1\n==\nB.A2 \n A2\n==\nB.A1\n)\n\n\n# identify SNPs that need flipping \n complement\n\ninfo.cflip \n-\n \nsubset\n(\ninfo\n,\n A1\n==\nC.A2 \n A2\n==\nC.A1\n)\n\n\n# Update these allele coding in the bim file \n\nbim\n[\nbim\n$\nSNP \n%in%\n info.cflip\n$\nSNP\n,\n \n]\n$\nB.A1 \n-\n \nsapply\n(\nbim\n[\nbim\n$\nSNP \n%in%\n info.cflip\n$\nSNP\n,\n \n]\n$\nB.A1\n,\n complement\n)\n\nbim\n[\nbim\n$\nSNP \n%in%\n info.cflip\n$\nSNP\n,\n \n]\n$\nB.A2 \n-\n \nsapply\n(\nbim\n[\nbim\n$\nSNP \n%in%\n info.cflip\n$\nSNP\n,\n \n]\n$\nB.A2\n,\n complement\n)\n\n\n# Get list of SNPs that need to change the A1 encoding\n\nflip \n-\n \nrbind\n(\ninfo.flip\n,\n info.cflip\n)\n\nflip.snp \n-\n \ndata.frame\n(\nSNP\n=\nflip\n$\nSNP\n,\n A1\n=\nflip\n$\nA1\n)\n\nwrite.table\n(\nflip.snp\n,\n \nEUR.update.a1\n,\n quote\n=\nF\n,\n row.names\n=\nF\n)\n\nwrite.table\n(\nbim\n,\n \nEUR.QC.adj.bim\n,\n quote\n=\nF\n,\n row.names\n=\nF\n,\n col.names\n=\nF\n)\n\n\n# And we want to remove any SNPs that do not match with the base data\n\nmismatch \n-\n bim\n$\nSNP\n[\n!\n(\nbim\n$\nSNP \n%in%\n info.match\n$\nSNP \n|\n bim\n$\nSNP \n%in%\n info.complement\n$\nSNP \n|\n bim\n$\nSNP \n%in%\n flip\n$\nSNP\n)]\n\nwrite.table\n(\nmismatch\n,\n \nEUR.mismatch\n,\n quote\n=\nF\n,\n row.names\n=\nF\n,\n col.names\n=\nF\n)\n\n\n\n\n\n\nThe above script will generate three files: \nEUR.QC.adj.bim\n, \nEUR.update.a1\n and \nEUR.mismatch\n. We want to replace\n\nEUR.QC.bim\n with \nEUR.QC.adj.bim\n:\n\n\n# Make a back up\n\nmv EUR.QC.bim EUR.QC.bim.bk\nln -s EUR.QC.adj.bim EUR.QC.bim\n\n\n\n\nWe can then generate a new genotype file with the correct genetic encodings\n\nplink \n\\\n\n    --bfile EUR.QC \n\\\n\n    --a1-allele EUR.update.a1 \n\\\n\n    --make-bed \n\\\n\n    --keep EUR.valid.sample \n\\\n\n    --extract EUR.unambig.snp \n\\\n\n    --exclude EUR.mismatch \n\\\n\n    --out EUR.QC.flipped\n\n\n\nUpdate Effect Size\n\n\nWhen odd ratios (OR) instead of BETA are provided, the PRS might have to calculated using a multiplicative model.\nTo simplify the calculation, we usually take the natural logarithm of the OR such that an additive model can be applied. \nWe can obtain the transformed summary statistics with \nR\n:\n\n\ndat \n-\n read.table\n(\ngzfile\n(\nHeight.QC.gz\n),\n header\n=\nT\n)\n\ndat\n$\nOR \n-\n \nlog\n(\ndat\n$\nOR\n)\n\nwrite.table\n(\ndat\n,\n \nHeight.QC.Transformed\n,\n quote\n=\nF\n,\n row.names\n=\nF\n)\n\n\n\n\n\n\n\nWarning\n\n\nWhile you can also do the log transformation using \nawk\n, the resulting transformation will only have precision upto 7th digit. \nThe imprecision can accumulate and lead to slightly less accurate results. \nTherefore it is best to do the transformation in \nR\n or allow the PRS software to do the transformation for you. \n\n\n\n\nClumping\n\n\nLinkage disequilibrium introduce a strong correlation structure across the genome, makes identifying the independent\ngenetic effects extremely challenging. \nOne simple method is to perform clumping, which preferentially selects SNPs most\nassociated with the trait under study when removing SNPs in LD. \n\n\nplink \n\\\n\n    --bfile EUR.QC.flipped \n\\\n\n    --clump-p1 \n1\n \n\\\n\n    --clump-r2 \n0\n.1 \n\\\n\n    --clump-kb \n250\n \n\\\n\n    --clump Height.QC.transformed \n\\\n\n    --clump-snp-field SNP \n\\\n\n    --clump-field P \n\\\n\n    --out EUR\n\n\nEach of the new parameters corresponds to the following\n\n\n\n\n\n\n\n\nParamter\n\n\nValue\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nclump-p1\n\n\n1\n\n\nP-value threshold for a SNP to be included as an index SNP. 1 is selected such that all SNPs are include for clumping\n\n\n\n\n\n\nclump-r2\n\n\n0.1\n\n\nSNPs having \n\\(r^2\\)\n higher than 0.1 with the index SNPs will be removed\n\n\n\n\n\n\nclump-kb\n\n\n250\n\n\nSNPs within 250k of the index SNP are considered for clumping\n\n\n\n\n\n\nclump\n\n\nHeight.QC.transformed\n\n\nSummary statistic file containing the p-value information\n\n\n\n\n\n\nclump-snp-field\n\n\nSNP\n\n\nSpecify that the column \nSNP\n contains the SNP IDs\n\n\n\n\n\n\nclump-field\n\n\nP\n\n\nSpecify that the column \nP\n contains the P-value information\n\n\n\n\n\n\n\n\nA more detailed document can be found \nhere\n\n\n\n\nNote\n\n\nThe \n\\(r^2\\)\n values computed by \n--clump\n are based on maximum likelihood haplotype frequency estimates\n\n\n\n\nThis will generate \nEUR.clumped\n, containing the index SNPs after clumping is performed.\nWe can extract the index SNP ID by doing\n\n\nawk \nNR!=1{print $3}\n EUR.clumped \n  EUR.valid.snp\n\n\n\n\n\n\n$3\n because the third column contains the SNP ID\n\n\n\n\n\n\nNote\n\n\nIf your target sample is small (e.g. \n500), you can try using the 1000 Genome samples for the LD calculation.\nMake sure you use the population that best represents your sample.\n\n\n\n\nGenerate PRS\n\n\nplink\n provide a handy function \n--score\n and \n--q-score-range\n for calculating polygenic score.\n\n\nWe will need three files\n\n\n\n\nThe summary statistic file: \nHeight.QC.Transformed\n\n\nA file containing SNP ID and their corresponding p-value (\n$1\n because SNP ID is located at the first column; \n$8\n because P-value is located at the eigth column)\n\nawk \n{print $1,$8}\n Height.QC.Transformed \n SNP.pvalue\n\n\n\nA file containing the P-value thresholds we are testing. Here we will only test a few for illustration purposes\n\necho\n \n0.001 0 0.001\n \n range_list\n\necho\n \n0.05 0 0.05\n \n range_list\n\necho\n \n0.1 0 0.1\n \n range_list\n\necho\n \n0.2 0 0.2\n \n range_list\n\necho\n \n0.3 0 0.3\n \n range_list\n\necho\n \n0.4 0 0.4\n \n range_list\n\necho\n \n0.5 0 0.5\n \n range_list\n\n\nThe format of the \nrange_list\n file should be as follow\n\n\n\n\n\n\n\n\n\n\nName of Threshold\n\n\nLower bound\n\n\nUpper Bound\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nThe boundary are inclusive. For example, for the \n0.05\n threshold, we include all SNPs with P-value from \n\n0\n to \n0.05\n, \nincluding\n any SNPs with P-value equal to \n0.05\n\n\n\n\nWe can then calculate the PRS with the following \nplink\n command:\n\n\nplink \n\\\n\n    --bfile EUR.QC.flipped \n\\\n\n    --extract EUR.valid.snp \n\\\n\n    --score Height.QC.Transformed \n1\n \n4\n \n11\n header \n\\\n\n    --q-score-range range_list SNP.pvalue \n\\\n\n    --out EUR\n\n\nMeaning of the new parameters are as follow\n\n\n\n\n\n\n\n\nParamter\n\n\nValue\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nscore\n\n\nHeight.QC.Transformed 1 4 11 header\n\n\nWe read from the \nHeight.QC.Transformed\n file, assuming the \n1\nst column to be the SNP ID; \n4\nth column to be the effective allele information; \n11\nth column to be the effect size estimate; and the file contains a \nheader\n\n\n\n\n\n\nq-score-range\n\n\nrange_test SNP.pvalue\n\n\nWe want to calculate PRS based on the thresholds defined in \nrange_test\n, where the threshold values (p-values) were stored in \nSNP.pvalue\n\n\n\n\n\n\n\n\nThe above command and range_list will generate 7 files:\n\n\n\n\nEUR.0.5.profile\n\n\nEUR.0.4.profile\n\n\nEUR.0.3.profile\n\n\nEUR.0.2.profile\n\n\nEUR.0.1.profile\n\n\nEUR.0.05.profile\n\n\nEUR.0.001.profile\n\n\n\n\n\n\nNote\n\n\nThe default formular for PRS calculation in PLINK is:\n(Assuming the effect size of SNP \n\\(i\\)\n is \n\\(S_i\\)\n;  the number of effective allele observed in sample \n\\(j\\)\n is \n\\(G_{ij}\\)\n; the ploidy of the sample is \n\\(P\\)\n (It should be 2 for human); the number of samples included in the PRS be \n\\(N\\)\n; and the number of non-missing SNPs observed in sample \n\\(j\\)\n be \n\\(M_j\\)\n)\n$$\nPRS_j =\\frac{ \\sum_i^NS_i*G_{ij}}{P*M_j}\n$$\n\n\nIf sample has a missing genotype for SNP \n\\(i\\)\n, the population minor allele frequency times ploidy (\n\\(MAF_i*P\\)\n) is used inplace of \n\\(G_{ij}\\)\n\n\n\n\nAccounting for Population Stratification\n\n\nPopulation structure is the principal source of confounding in GWAS and are usually accounted for by incorporating the principal components (PCs) as a covariate. \nSimilarly, we can incorporate PCs in our PRS analysis to account for population stratification.\n\n\nAgain, we can calculate the PCs using \nplink\n \n\n# First, we need to perform prunning\n\nplink \n\\\n\n    --bfile EUR.QC.flipped \n\\\n\n    --extract EUR.valid.snp \n\\\n\n    --indep-pairwise \n200\n \n50\n \n0\n.25 \n\\\n\n    --out EUR\n\n# Then we calculate the first 6 PCs\n\nplink \n\\\n\n    --bfile EUR.QC.flipped \n\\\n\n    --extract EUR.prune.in \n\\\n\n    --pca \n6\n \n\\\n\n    --out EUR\n\n\n\n\n\nNote\n\n\nOne way to select the appropriate number of PCs is to perform GWAS on the trait of interest with different number of PCs.\n\nLDSC\n analysis can then be performed on each of the resulted GWAS summary statistics. \nBy observing the estimated intercept, one can select the number of PCs that provide an intercept estimate closer to 1, which might\nsuggest a smaller influence of population stratification.\n\n\n\n\nThe eigen-vector (PCs) are stored in \nEUR.eigenvec\n and can be used as a covariate in the regression model to account for population stratification.\n\n\n\n\nImportant\n\n\nIf the base and target samples are collected from different population (e.g. Caucasian vs African ), the results from PRS analysis will be biased (see \nMartin et al\n).\n\n\n\n\nFinding the \"Best\" P-value threshold\n\n\nThe \"best\" p-value threshold for PRS construction are usually not known. \nTo identify the \"best\" PRS, we can perform a regression between the calculated PRS and the \nsample phenotype and select the PRS that explains most of the phenotypic variation. \nThis can be achieved using \nR\n.\n\n\n\n\n\n\ndetail\n\n\np.threshold \n-\n \nc\n(\n0.001\n,\n0.05\n,\n0.1\n,\n0.2\n,\n0.3\n,\n0.4\n,\n0.5\n)\n\n\n# Read in the phenotype file \n\nphenotype \n-\n read.table\n(\nEUR.height\n,\n header\n=\nT\n)\n\n\n# Read in the PCs\n\npcs \n-\n read.table\n(\nEUR.eigenvec\n,\n header\n=\nF\n)\n\n\n# The default output from plink does not include a header\n\n\n# To make things simple, we will add the appropriate headers\n\n\n# (1:6 because there are 6 PCs)\n\n\ncolnames\n(\npcs\n)\n \n-\n \nc\n(\nFID\n,\n \nIID\n,\n \npaste0\n(\nPC\n,\n1\n:\n6\n))\n \n\n# Read in the covariates (here, it is sex)\n\ncovariate \n-\n read.table\n(\nEUR.covariate\n,\n header\n=\nT\n)\n\n\n# Now merge the files\n\npheno \n-\n \nmerge\n(\nmerge\n(\nphenotype\n,\n covariate\n,\n by\n=\nc\n(\nFID\n,\n \nIID\n)),\n pcs\n,\n by\n=\nc\n(\nFID\n,\nIID\n))\n\n\n# We can then calculate the null model (model with PRS) using a linear regression \n\n\n# (as height is quantitative)\n\nnull.model \n-\n lm\n(\nHeight\n~\n.\n,\n data\n=\npheno\n[,\n!\ncolnames\n(\npheno\n)\n%in%\nc\n(\nFID\n,\nIID\n)])\n\n\n# And the R2 of the null model is \n\nnull.r2 \n-\n \nsummary\n(\nnull.model\n)\n$\nr.squared\nprs.result \n-\n \nNULL\n\n\nfor\n(\ni \nin\n p.threshold\n){\n\n    \n# Go through each p-value threshold\n\n    prs \n-\n read.table\n(\npaste0\n(\nEUR.\n,\ni\n,\n.profile\n),\n header\n=\nT\n)\n\n    \n# Merge the prs with the phenotype matrix\n\n    \n# We only want the FID, IID and PRS from the PRS file, therefore we only select the \n\n    \n# relevant columns\n\n    pheno.prs \n-\n \nmerge\n(\npheno\n,\n prs\n[,\nc\n(\nFID\n,\nIID\n,\n \nSCORE\n)],\n by\n=\nc\n(\nFID\n,\n \nIID\n))\n\n    \n# Now perform a linear regression on Height with PRS and the covariates\n\n    \n# ignoring the FID and IID from our model\n\n    model \n-\n lm\n(\nHeight\n~\n.\n,\n data\n=\npheno.prs\n[,\n!\ncolnames\n(\npheno.prs\n)\n%in%\nc\n(\nFID\n,\nIID\n)])\n\n    \n# model R2 is obtained as \n\n    model.r2 \n-\n \nsummary\n(\nmodel\n)\n$\nr.squared\n    \n# R2 of PRS is simply calculated as the model R2 minus the null R2\n\n    prs.r2 \n-\n model.r2\n-\nnull.r2\n    \n# We can also obtain the coeffcient and p-value of association of PRS as follow\n\n    prs.coef \n-\n \nsummary\n(\nmodel\n)\n$\ncoeff\n[\nSCORE\n,]\n\n    prs.beta \n-\n \nas.numeric\n(\nprs.coef\n[\n1\n])\n\n    prs.se \n-\n \nas.numeric\n(\nprs.coef\n[\n2\n])\n\n    prs.p \n-\n \nas.numeric\n(\nprs.coef\n[\n4\n])\n\n    \n# We can then store the results\n\n    prs.result \n-\n \nrbind\n(\nprs.result\n,\n \ndata.frame\n(\nThreshold\n=\ni\n,\n R2\n=\nprs.r2\n,\n P\n=\nprs.p\n,\n BETA\n=\nprs.beta\n,\nSE\n=\nprs.se\n))\n\n\n}\n\n\n# Best result is:\n\nprs.result\n[\nwhich.max\n(\nprs.result\n$\nR2\n),]\n\n\n\n\n\n\nquick\n\n\np.threshold \n-\n \nc\n(\n0.001\n,\n0.05\n,\n0.1\n,\n0.2\n,\n0.3\n,\n0.4\n,\n0.5\n)\n\nphenotype \n-\n read.table\n(\nEUR.height\n,\n header\n=\nT\n)\n\npcs \n-\n read.table\n(\nEUR.eigenvec\n,\n header\n=\nF\n)\n\n\ncolnames\n(\npcs\n)\n \n-\n \nc\n(\nFID\n,\n \nIID\n,\n \npaste0\n(\nPC\n,\n1\n:\n6\n))\n \ncovariate \n-\n read.table\n(\nEUR.covariate\n,\n header\n=\nT\n)\n\npheno \n-\n \nmerge\n(\nmerge\n(\nphenotype\n,\n covariate\n,\n by\n=\nc\n(\nFID\n,\n \nIID\n)),\n pcs\n,\n by\n=\nc\n(\nFID\n,\nIID\n))\n\nnull.r2 \n-\n \nsummary\n(\nlm\n(\nHeight\n~\n.\n,\n data\n=\npheno\n[,\n!\ncolnames\n(\npheno\n)\n%in%\nc\n(\nFID\n,\nIID\n)]))\n$\nr.squared\nprs.result \n-\n \nNULL\n\n\nfor\n(\ni \nin\n p.threshold\n){\n\n    pheno.prs \n-\n \nmerge\n(\npheno\n,\n \n                        read.table\n(\npaste0\n(\nEUR.\n,\ni\n,\n.profile\n),\n header\n=\nT\n)[,\nc\n(\nFID\n,\nIID\n,\n \nSCORE\n)],\n\n                        by\n=\nc\n(\nFID\n,\n \nIID\n))\n\n    model \n-\n \nsummary\n(\nlm\n(\nHeight\n~\n.\n,\n data\n=\npheno.prs\n[,\n!\ncolnames\n(\npheno.prs\n)\n%in%\nc\n(\nFID\n,\nIID\n)]))\n\n    model.r2 \n-\n model\n$\nr.squared\n    prs.r2 \n-\n model.r2\n-\nnull.r2\n    prs.coef \n-\n model\n$\ncoeff\n[\nSCORE\n,]\n\n    prs.result \n-\n \nrbind\n(\nprs.result\n,\n \n        \ndata.frame\n(\nThreshold\n=\ni\n,\n R2\n=\nprs.r2\n,\n \n                    P\n=\nas.numeric\n(\nprs.coef\n[\n4\n]),\n \n                    BETA\n=\nas.numeric\n(\nprs.coef\n[\n1\n]),\n\n                    SE\n=\nas.numeric\n(\nprs.coef\n[\n2\n])))\n\n\n}\n\n\nprint\n(\nprs.result\n[\nwhich.max\n(\nprs.result\n$\nR2\n),])\n\n\n\n\n\n\nWhich p-value threshold generate the \"best\" PRS?\n0.2\n\n\n\n\nHow much phenotypic variation does the \"best\" PRS explains?\n0.04128065\n\n\n\n\nPlotting the Results\n\n\nThe P-value threshold results can be visualized using \nR\n\n\n\n\nNote\n\n\nWe will be using \nprs.result\n generated in \nprevious section\n\n\n\n\n\n\n\n\nWithout ggplot2\n\n\n# We strongly recommend the use of ggplot2. Only follow this code if you\n\n\n# are desperate.\n\n\n# Specify that we want to generate plot in EUR.height.bar.png\n\npng\n(\nEUR.height.bar.png\n,\n\n      height\n=\n10\n,\n width\n=\n10\n,\n res\n=\n300\n,\n unit\n=\nin\n)\n\n\n# First, obtain the colorings based on the p-value\n\ncol \n-\n \nsuppressWarnings\n(\ncolorRampPalette\n(\nc\n(\ndodgerblue\n,\n \nfirebrick\n)))\n\n\n# We want the color gradient to match the ranking of p-values\n\nprs.result \n-\n prs.result\n[\norder\n(\n-\nlog10\n(\nprs.result\n$\nP\n)),]\n\nprs.result\n$\ncolor \n-\n  \ncol\n(\nnrow\n(\nprs.result\n))\n\nprs.result \n-\n prs.result\n[\norder\n(\nprs.result\n$\nThreshold\n),]\n\n\n# generate a pretty format for p-value output\n\nprs.result\n$\nprint.p \n-\n \nround\n(\nprs.result\n$\nP\n,\n digits \n=\n \n3\n)\n\nprs.result\n$\nprint.p\n[\n!\nis.na\n(\nprs.result\n$\nprint.p\n)\n \n prs.result\n$\nprint.p \n==\n \n0\n \n]\n \n-\n\n    \nformat\n(\nprs.result\n$\nP\n[\n!\nis.na\n(\nprs.result\n$\nprint.p\n)\n \n prs.result\n$\nprint.p \n==\n \n0\n \n],\n digits \n=\n \n2\n)\n\nprs.result\n$\nprint.p \n-\n \nsub\n(\ne\n,\n \n*x*10^\n,\n prs.result\n$\nprint.p\n)\n\n\n# Generate the axis labels\n\nxlab \n-\n \nexpression\n(\nitalic\n(\nP\n)\n \n-\n value \n~\n threshold \n~\n \n(\nitalic\n(\nP\n)[\nT\n]))\n\nylab \n-\n \nexpression\n(\npaste\n(\nPRS model fit:  \n,\n R \n^\n \n2\n))\n\n\n# Setup the drawing area\n\nlayout\n(\nt\n(\n1\n:\n2\n),\n widths\n=\nc\n(\n8.8\n,\n1.2\n))\n\npar\n(\n cex.lab\n=\n1.5\n,\n cex.axis\n=\n1.25\n,\n font.lab\n=\n2\n,\n \n    oma\n=\nc\n(\n0\n,\n0.5\n,\n0\n,\n0\n),\n\n    mar\n=\nc\n(\n4\n,\n6\n,\n0.5\n,\n0.5\n))\n\n\n# Plotting the bars\n\nb\n-\n barplot\n(\nheight\n=\nprs.result\n$\nR2\n,\n \n            col\n=\nprs.result\n$\ncolor\n,\n \n            border\n=\nNA\n,\n \n            ylim\n=\nc\n(\n0\n,\n \nmax\n(\nprs.result\n$\nR2\n)\n*\n1.25\n),\n \n            axes \n=\n \nF\n,\n ann\n=\nF\n)\n\n\n# Plot the axis labels and axis ticks\n\nodd \n-\n \nseq\n(\n0\n,\nnrow\n(\nprs.result\n)\n+1\n,\n2\n)\n\neven \n-\n \nseq\n(\n1\n,\nnrow\n(\nprs.result\n),\n2\n)\n\naxis\n(\nside\n=\n1\n,\n at\n=\nb\n[\nodd\n],\n labels\n=\nprs.result\n$\nThreshold\n[\nodd\n],\n lwd\n=\n2\n)\n\naxis\n(\nside\n=\n1\n,\n at\n=\nb\n[\neven\n],\n labels\n=\nprs.result\n$\nThreshold\n[\neven\n],\nlwd\n=\n2\n)\n\naxis\n(\nside\n=\n1\n,\n at\n=\nc\n(\n0\n,\nb\n[\n1\n],\n2\n*\nb\n[\nlength\n(\nb\n)]\n-\nb\n[\nlength\n(\nb\n)\n-1\n]),\n labels\n=\nc\n(\n,\n,\n),\n lwd\n=\n2\n,\n lwd.tick\n=\n0\n)\n\n\n# Write the p-value on top of each bar\n\ntext\n(\n \nparse\n(\ntext\n=\npaste\n(\n\n    prs.result\n$\nprint.p\n)),\n \n    x \n=\n b\n+0.1\n,\n \n    y \n=\n  prs.result\n$\nR2\n+\n \n(\nmax\n(\nprs.result\n$\nR2\n)\n*\n1.05\n-\nmax\n(\nprs.result\n$\nR2\n)),\n \n    srt \n=\n \n45\n)\n\n\n# Now plot the axis lines\n\nbox\n(\nbty\n=\nL\n,\n lwd\n=\n2\n)\n\naxis\n(\n2\n,\nlas\n=\n2\n,\n lwd\n=\n2\n)\n\n\n# Plot the axis titles\n\ntitle\n(\nylab\n=\nylab\n,\n line\n=\n4\n,\n cex.lab\n=\n1.5\n,\n font\n=\n2\n \n)\n\ntitle\n(\nxlab\n=\nxlab\n,\n line\n=\n2.5\n,\n cex.lab\n=\n1.5\n,\n font\n=\n2\n \n)\n\n\n# Generate plot area for the legend\n\npar\n(\ncex.lab\n=\n1.5\n,\n cex.axis\n=\n1.25\n,\n font.lab\n=\n2\n,\n \n      mar\n=\nc\n(\n20\n,\n0\n,\n20\n,\n4\n))\n\nprs.result \n-\n prs.result\n[\norder\n(\n-\nlog10\n(\nprs.result\n$\nP\n)),]\n\nimage\n(\n1\n,\n \n-\nlog10\n(\nprs.result\n$\nP\n),\n \nt\n(\nseq_along\n(\n-\nlog10\n(\nprs.result\n$\nP\n))),\n col\n=\nprs.result\n$\ncolor\n,\n axes\n=\nF\n,\nann\n=\nF\n)\n\naxis\n(\n4\n,\nlas\n=\n2\n,\nxaxs\n=\nr\n,\nyaxs\n=\nr\n,\n tck\n=\n0.2\n,\n col\n=\nwhite\n)\n\n\n# plot legend title\n\ntitle\n(\nbquote\n(\natop\n(\n-\nlog\n[\n10\n]\n \n~\n model\n,\n italic\n(\nP\n)\n \n-\n value\n),\n \n),\n \n          line\n=\n2\n,\n cex\n=\n1.5\n,\n font\n=\n2\n,\n adj\n=\n0\n)\n\n\n# write the plot to file\n\ndev.off\n()\n\n\n\n\n\n\nggplot2\n\n\n# ggplot2 is a handy package for plotting\n\n\nlibrary\n(\nggplot2\n)\n\n\n# generate a pretty format for p-value output\n\nprs.result\n$\nprint.p \n-\n \nround\n(\nprs.result\n$\nP\n,\n digits \n=\n \n3\n)\n\nprs.result\n$\nprint.p\n[\n!\nis.na\n(\nprs.result\n$\nprint.p\n)\n \n\n                       prs.result\n$\nprint.p \n==\n \n0\n]\n \n-\n\n    \nformat\n(\nprs.result\n$\nP\n[\n!\nis.na\n(\nprs.result\n$\nprint.p\n)\n \n\n                            prs.result\n$\nprint.p \n==\n \n0\n],\n digits \n=\n \n2\n)\n\nprs.result\n$\nprint.p \n-\n \nsub\n(\ne\n,\n \n*x*10^\n,\n prs.result\n$\nprint.p\n)\n\n\n# Initialize ggplot, requiring the threshold as the x-axis (use factor so that it is uniformly distributed)\n\nggplot\n(\ndata \n=\n prs.result\n,\n aes\n(\nx \n=\n \nfactor\n(\nThreshold\n),\n y \n=\n R2\n))\n \n+\n\n    \n# Specify that we want to print p-value on top of the bars\n\n    geom_text\n(\n\n        aes\n(\nlabel \n=\n \npaste\n(\nprint.p\n)),\n\n        vjust \n=\n \n-1.5\n,\n\n        hjust \n=\n \n0\n,\n\n        angle \n=\n \n45\n,\n\n        cex \n=\n \n4\n,\n\n        parse \n=\n \nT\n\n    \n)\n  \n+\n\n    \n# Specify the range of the plot, *1.25 to provide enough space for the p-values\n\n    scale_y_continuous\n(\nlimits \n=\n \nc\n(\n0\n,\n \nmax\n(\nprs.result\n$\nR2\n)\n \n*\n \n1.25\n))\n \n+\n\n    \n# Specify the axis labels\n\n    xlab\n(\nexpression\n(\nitalic\n(\nP\n)\n \n-\n value \n~\n threshold \n~\n \n(\nitalic\n(\nP\n)[\nT\n])))\n \n+\n\n    ylab\n(\nexpression\n(\npaste\n(\nPRS model fit:  \n,\n R \n^\n \n2\n)))\n \n+\n\n    \n# Draw a bar plot\n\n    geom_bar\n(\naes\n(\nfill \n=\n \n-\nlog10\n(\nP\n)),\n stat \n=\n \nidentity\n)\n \n+\n\n    \n# Specify the colors\n\n    scale_fill_gradient2\n(\n\n        low \n=\n \ndodgerblue\n,\n\n        high \n=\n \nfirebrick\n,\n\n        mid \n=\n \ndodgerblue\n,\n\n        midpoint \n=\n \n1e-4\n,\n\n        name \n=\n \nbquote\n(\natop\n(\n-\nlog\n[\n10\n]\n \n~\n model\n,\n italic\n(\nP\n)\n \n-\n value\n),)\n\n    \n)\n \n+\n\n    \n# Some beautification of the plot\n\n    theme_classic\n()\n \n+\n theme\n(\n\n        axis.title \n=\n element_text\n(\nface \n=\n \nbold\n,\n size \n=\n \n18\n),\n\n        axis.text \n=\n element_text\n(\nsize \n=\n \n14\n),\n\n        legend.title \n=\n element_text\n(\nface \n=\n \nbold\n,\n size \n=\n\n                                        \n18\n),\n\n        legend.text \n=\n element_text\n(\nsize \n=\n \n14\n),\n\n        axis.text.x \n=\n element_text\n(\nangle \n=\n \n45\n,\n hjust \n=\n\n                                       \n1\n)\n\n    \n)\n\n\n# save the plot\n\nggsave\n(\nEUR.height.bar.png\n,\n height \n=\n \n7\n,\n width \n=\n \n7\n)\n\n\n\n\n\n\n\n\n\n\nAn example bar plot generated using \nggplot2\n\n\n\n\nIn addition, we can visualize the relationship between the \"best\" PRS and the phenotype of interest, colored by sex\n\n\n\n\n\n\nWithout ggplot2\n\n\n# Read in the files\n\nprs \n-\n read.table\n(\nEUR.0.2.profile\n,\n header\n=\nT\n)\n\nheight \n-\n read.table\n(\nEUR.height\n,\n header\n=\nT\n)\n\nsex \n-\n read.table\n(\nEUR.covariate\n,\n header\n=\nT\n)\n\n\n# Rename the sex\n\nsex\n$\nSex \n-\n \nas.factor\n(\nsex\n$\nSex\n)\n\n\nlevels\n(\nsex\n$\nSex\n)\n \n-\n \nc\n(\nMale\n,\n \nFemale\n)\n\n\n# Merge the files\n\ndat \n-\n \nmerge\n(\nmerge\n(\nprs\n,\n height\n),\n sex\n)\n\n\n# Start plotting\n\nplot\n(\nx\n=\ndat\n$\nSCORE\n,\n y\n=\ndat\n$\nHeight\n,\n col\n=\nwhite\n,\n\n    xlab\n=\nPolygenic Score\n,\n ylab\n=\nHeight\n)\n\n\nwith\n(\nsubset\n(\ndat\n,\n Sex\n==\nMale\n),\n points\n(\nx\n=\nSCORE\n,\n y\n=\nHeight\n,\n col\n=\nred\n))\n\n\nwith\n(\nsubset\n(\ndat\n,\n Sex\n==\nFemale\n),\n points\n(\nx\n=\nSCORE\n,\n y\n=\nHeight\n,\n col\n=\nblue\n))\n\n\n\n\n\n\nggplot2\n\n\nlibrary\n(\nggplot2\n)\n\n\n# Read in the files\n\nprs \n-\n read.table\n(\nEUR.0.2.profile\n,\n header\n=\nT\n)\n\nheight \n-\n read.table\n(\nEUR.height\n,\n header\n=\nT\n)\n\nsex \n-\n read.table\n(\nEUR.covariate\n,\n header\n=\nT\n)\n\n\n# Rename the sex\n\nsex\n$\nSex \n-\n \nas.factor\n(\nsex\n$\nSex\n)\n\n\nlevels\n(\nsex\n$\nSex\n)\n \n-\n \nc\n(\nMale\n,\n \nFemale\n)\n\n\n# Merge the files\n\ndat \n-\n \nmerge\n(\nmerge\n(\nprs\n,\n height\n),\n sex\n)\n\n\n# Start plotting\n\nggplot\n(\ndat\n,\n aes\n(\nx\n=\nSCORE\n,\n y\n=\nHeight\n,\n color\n=\nSex\n))\n+\n\n    geom_point\n()\n+\n\n    theme_classic\n()\n+\n\n    labs\n(\nx\n=\nPolygenic Score\n,\n y\n=\nHeight\n)\n\n\n\n\n\n\n\n\n\n\nAn example scatter plot generated using \nggplot2", 
            "title": "PLINK"
        }, 
        {
            "location": "/plink/#remove-ambiguous-snps", 
            "text": "If the base and target data were generated using different genotyping chips and the chromosome strand (+/-) for either is unknown, then it is not possible to match ambiguous SNPs (i.e. those with complementary alleles, either C/G or A/T) across the data sets, because it will be unknown whether the base and target data are referring to the same allele or not.   Ambiguous SNPs can be obtained by examining the bim file: awk  !( ($5== A    $6== T ) || \\          ($5== T    $6== A ) || \\          ($5== G    $6== C ) || \\          ($5== C    $6== G )) {print}   \\ \n        EUR.QC.bim   EUR.unambig.snp   How many ambiguous SNPs were there? There are  17,260  ambiguous SNPs", 
            "title": "Remove Ambiguous SNPs"
        }, 
        {
            "location": "/plink/#strand-flipping", 
            "text": "Alternatively, when there is a non-ambiguous mismatch in allele coding between the data sets, such as A/C in the base\nand G/T in the target data, then this can be resolved by \u2018flipping\u2019 the alleles in the target data to their complementary alleles. \nThis has to be done with mulitpe steps   Get the correct A1 alleles for the bim file bim  -  read.table ( EUR.QC.bim ,  header = F )  colnames ( bim )   -   c ( CHR ,   SNP ,   CM ,   BP ,   B.A1 ,   B.A2 ) \nheight  -  read.table ( gzfile ( Height.QC.gz ),  header = T )  # Avoid complicated factor problem \nheight $ A1  -   toupper ( as.character ( height $ A1 )) \nheight $ A2  -   toupper ( as.character ( height $ A2 )) \nbim $ B.A1  -   toupper ( as.character ( bim $ B.A1 )) \nbim $ B.A2  -   toupper ( as.character ( bim $ B.A2 )) \ninfo  -   merge ( bim ,  height ,  by = c ( SNP ,   CHR ,   BP ))  # Function for calculating the complementary allele \ncomplement  -   function ( x ){ \n     switch   ( x , \n         A   =   T , \n         C   =   G , \n         T   =   A , \n         G   =   C , \n         return ( NA ) \n     )  }  # Now get SNPs that has exact match between base and target \ninfo.match  -   subset ( info ,  A1 == B.A1   A2 == B.A2 )  # Check for complementary matchs \ninfo $ C.A1  -   sapply ( info $ B.A1 ,  complement ) \ninfo $ C.A2  -   sapply ( info $ B.A2 ,  complement ) \ninfo.complement  -   subset ( info ,  A1 == C.A1   A2 == C.A2 )  # Update these allele coding in the bim file  \nbim [ bim $ SNP  %in%  info.complement $ SNP ,   ] $ B.A1  -   sapply ( bim [ bim $ SNP  %in%  info.complement $ SNP ,   ] $ B.A1 ,  complement ) \nbim [ bim $ SNP  %in%  info.complement $ SNP ,   ] $ B.A2  -   sapply ( bim [ bim $ SNP  %in%  info.complement $ SNP ,   ] $ B.A2 ,  complement )  # identify SNPs that need flipping  \ninfo.flip  -   subset ( info ,  A1 == B.A2   A2 == B.A1 )  # identify SNPs that need flipping   complement \ninfo.cflip  -   subset ( info ,  A1 == C.A2   A2 == C.A1 )  # Update these allele coding in the bim file  \nbim [ bim $ SNP  %in%  info.cflip $ SNP ,   ] $ B.A1  -   sapply ( bim [ bim $ SNP  %in%  info.cflip $ SNP ,   ] $ B.A1 ,  complement ) \nbim [ bim $ SNP  %in%  info.cflip $ SNP ,   ] $ B.A2  -   sapply ( bim [ bim $ SNP  %in%  info.cflip $ SNP ,   ] $ B.A2 ,  complement )  # Get list of SNPs that need to change the A1 encoding \nflip  -   rbind ( info.flip ,  info.cflip ) \nflip.snp  -   data.frame ( SNP = flip $ SNP ,  A1 = flip $ A1 ) \nwrite.table ( flip.snp ,   EUR.update.a1 ,  quote = F ,  row.names = F ) \nwrite.table ( bim ,   EUR.QC.adj.bim ,  quote = F ,  row.names = F ,  col.names = F )  # And we want to remove any SNPs that do not match with the base data \nmismatch  -  bim $ SNP [ ! ( bim $ SNP  %in%  info.match $ SNP  |  bim $ SNP  %in%  info.complement $ SNP  |  bim $ SNP  %in%  flip $ SNP )] \nwrite.table ( mismatch ,   EUR.mismatch ,  quote = F ,  row.names = F ,  col.names = F )    The above script will generate three files:  EUR.QC.adj.bim ,  EUR.update.a1  and  EUR.mismatch . We want to replace EUR.QC.bim  with  EUR.QC.adj.bim :  # Make a back up \nmv EUR.QC.bim EUR.QC.bim.bk\nln -s EUR.QC.adj.bim EUR.QC.bim  We can then generate a new genotype file with the correct genetic encodings plink  \\ \n    --bfile EUR.QC  \\ \n    --a1-allele EUR.update.a1  \\ \n    --make-bed  \\ \n    --keep EUR.valid.sample  \\ \n    --extract EUR.unambig.snp  \\ \n    --exclude EUR.mismatch  \\ \n    --out EUR.QC.flipped", 
            "title": "Strand Flipping"
        }, 
        {
            "location": "/plink/#update-effect-size", 
            "text": "When odd ratios (OR) instead of BETA are provided, the PRS might have to calculated using a multiplicative model.\nTo simplify the calculation, we usually take the natural logarithm of the OR such that an additive model can be applied. \nWe can obtain the transformed summary statistics with  R :  dat  -  read.table ( gzfile ( Height.QC.gz ),  header = T ) \ndat $ OR  -   log ( dat $ OR ) \nwrite.table ( dat ,   Height.QC.Transformed ,  quote = F ,  row.names = F )    Warning  While you can also do the log transformation using  awk , the resulting transformation will only have precision upto 7th digit. \nThe imprecision can accumulate and lead to slightly less accurate results. \nTherefore it is best to do the transformation in  R  or allow the PRS software to do the transformation for you.", 
            "title": "Update Effect Size"
        }, 
        {
            "location": "/plink/#clumping", 
            "text": "Linkage disequilibrium introduce a strong correlation structure across the genome, makes identifying the independent\ngenetic effects extremely challenging. \nOne simple method is to perform clumping, which preferentially selects SNPs most\nassociated with the trait under study when removing SNPs in LD.   plink  \\ \n    --bfile EUR.QC.flipped  \\ \n    --clump-p1  1   \\ \n    --clump-r2  0 .1  \\ \n    --clump-kb  250   \\ \n    --clump Height.QC.transformed  \\ \n    --clump-snp-field SNP  \\ \n    --clump-field P  \\ \n    --out EUR \nEach of the new parameters corresponds to the following     Paramter  Value  Description      clump-p1  1  P-value threshold for a SNP to be included as an index SNP. 1 is selected such that all SNPs are include for clumping    clump-r2  0.1  SNPs having  \\(r^2\\)  higher than 0.1 with the index SNPs will be removed    clump-kb  250  SNPs within 250k of the index SNP are considered for clumping    clump  Height.QC.transformed  Summary statistic file containing the p-value information    clump-snp-field  SNP  Specify that the column  SNP  contains the SNP IDs    clump-field  P  Specify that the column  P  contains the P-value information     A more detailed document can be found  here   Note  The  \\(r^2\\)  values computed by  --clump  are based on maximum likelihood haplotype frequency estimates   This will generate  EUR.clumped , containing the index SNPs after clumping is performed.\nWe can extract the index SNP ID by doing  awk  NR!=1{print $3}  EUR.clumped    EUR.valid.snp   $3  because the third column contains the SNP ID    Note  If your target sample is small (e.g.  500), you can try using the 1000 Genome samples for the LD calculation.\nMake sure you use the population that best represents your sample.", 
            "title": "Clumping"
        }, 
        {
            "location": "/plink/#generate-prs", 
            "text": "plink  provide a handy function  --score  and  --q-score-range  for calculating polygenic score.  We will need three files   The summary statistic file:  Height.QC.Transformed  A file containing SNP ID and their corresponding p-value ( $1  because SNP ID is located at the first column;  $8  because P-value is located at the eigth column) awk  {print $1,$8}  Height.QC.Transformed   SNP.pvalue  A file containing the P-value thresholds we are testing. Here we will only test a few for illustration purposes echo   0.001 0 0.001    range_list echo   0.05 0 0.05    range_list echo   0.1 0 0.1    range_list echo   0.2 0 0.2    range_list echo   0.3 0 0.3    range_list echo   0.4 0 0.4    range_list echo   0.5 0 0.5    range_list \nThe format of the  range_list  file should be as follow      Name of Threshold  Lower bound  Upper Bound             Note  The boundary are inclusive. For example, for the  0.05  threshold, we include all SNPs with P-value from  0  to  0.05 ,  including  any SNPs with P-value equal to  0.05   We can then calculate the PRS with the following  plink  command:  plink  \\ \n    --bfile EUR.QC.flipped  \\ \n    --extract EUR.valid.snp  \\ \n    --score Height.QC.Transformed  1   4   11  header  \\ \n    --q-score-range range_list SNP.pvalue  \\ \n    --out EUR \nMeaning of the new parameters are as follow     Paramter  Value  Description      score  Height.QC.Transformed 1 4 11 header  We read from the  Height.QC.Transformed  file, assuming the  1 st column to be the SNP ID;  4 th column to be the effective allele information;  11 th column to be the effect size estimate; and the file contains a  header    q-score-range  range_test SNP.pvalue  We want to calculate PRS based on the thresholds defined in  range_test , where the threshold values (p-values) were stored in  SNP.pvalue     The above command and range_list will generate 7 files:   EUR.0.5.profile  EUR.0.4.profile  EUR.0.3.profile  EUR.0.2.profile  EUR.0.1.profile  EUR.0.05.profile  EUR.0.001.profile    Note  The default formular for PRS calculation in PLINK is:\n(Assuming the effect size of SNP  \\(i\\)  is  \\(S_i\\) ;  the number of effective allele observed in sample  \\(j\\)  is  \\(G_{ij}\\) ; the ploidy of the sample is  \\(P\\)  (It should be 2 for human); the number of samples included in the PRS be  \\(N\\) ; and the number of non-missing SNPs observed in sample  \\(j\\)  be  \\(M_j\\) )\n$$\nPRS_j =\\frac{ \\sum_i^NS_i*G_{ij}}{P*M_j}\n$$  If sample has a missing genotype for SNP  \\(i\\) , the population minor allele frequency times ploidy ( \\(MAF_i*P\\) ) is used inplace of  \\(G_{ij}\\)", 
            "title": "Generate PRS"
        }, 
        {
            "location": "/plink/#accounting-for-population-stratification", 
            "text": "Population structure is the principal source of confounding in GWAS and are usually accounted for by incorporating the principal components (PCs) as a covariate. \nSimilarly, we can incorporate PCs in our PRS analysis to account for population stratification.  Again, we can calculate the PCs using  plink   # First, we need to perform prunning \nplink  \\ \n    --bfile EUR.QC.flipped  \\ \n    --extract EUR.valid.snp  \\ \n    --indep-pairwise  200   50   0 .25  \\ \n    --out EUR # Then we calculate the first 6 PCs \nplink  \\ \n    --bfile EUR.QC.flipped  \\ \n    --extract EUR.prune.in  \\ \n    --pca  6   \\ \n    --out EUR   Note  One way to select the appropriate number of PCs is to perform GWAS on the trait of interest with different number of PCs. LDSC  analysis can then be performed on each of the resulted GWAS summary statistics. \nBy observing the estimated intercept, one can select the number of PCs that provide an intercept estimate closer to 1, which might\nsuggest a smaller influence of population stratification.   The eigen-vector (PCs) are stored in  EUR.eigenvec  and can be used as a covariate in the regression model to account for population stratification.   Important  If the base and target samples are collected from different population (e.g. Caucasian vs African ), the results from PRS analysis will be biased (see  Martin et al ).", 
            "title": "Accounting for Population Stratification"
        }, 
        {
            "location": "/plink/#finding-the-best-p-value-threshold", 
            "text": "The \"best\" p-value threshold for PRS construction are usually not known. \nTo identify the \"best\" PRS, we can perform a regression between the calculated PRS and the \nsample phenotype and select the PRS that explains most of the phenotypic variation. \nThis can be achieved using  R .    detail  p.threshold  -   c ( 0.001 , 0.05 , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 )  # Read in the phenotype file  \nphenotype  -  read.table ( EUR.height ,  header = T )  # Read in the PCs \npcs  -  read.table ( EUR.eigenvec ,  header = F )  # The default output from plink does not include a header  # To make things simple, we will add the appropriate headers  # (1:6 because there are 6 PCs)  colnames ( pcs )   -   c ( FID ,   IID ,   paste0 ( PC , 1 : 6 ))   # Read in the covariates (here, it is sex) \ncovariate  -  read.table ( EUR.covariate ,  header = T )  # Now merge the files \npheno  -   merge ( merge ( phenotype ,  covariate ,  by = c ( FID ,   IID )),  pcs ,  by = c ( FID , IID ))  # We can then calculate the null model (model with PRS) using a linear regression   # (as height is quantitative) \nnull.model  -  lm ( Height ~ . ,  data = pheno [, ! colnames ( pheno ) %in% c ( FID , IID )])  # And the R2 of the null model is  \nnull.r2  -   summary ( null.model ) $ r.squared\nprs.result  -   NULL  for ( i  in  p.threshold ){ \n     # Go through each p-value threshold \n    prs  -  read.table ( paste0 ( EUR. , i , .profile ),  header = T ) \n     # Merge the prs with the phenotype matrix \n     # We only want the FID, IID and PRS from the PRS file, therefore we only select the  \n     # relevant columns \n    pheno.prs  -   merge ( pheno ,  prs [, c ( FID , IID ,   SCORE )],  by = c ( FID ,   IID )) \n     # Now perform a linear regression on Height with PRS and the covariates \n     # ignoring the FID and IID from our model \n    model  -  lm ( Height ~ . ,  data = pheno.prs [, ! colnames ( pheno.prs ) %in% c ( FID , IID )]) \n     # model R2 is obtained as  \n    model.r2  -   summary ( model ) $ r.squared\n     # R2 of PRS is simply calculated as the model R2 minus the null R2 \n    prs.r2  -  model.r2 - null.r2\n     # We can also obtain the coeffcient and p-value of association of PRS as follow \n    prs.coef  -   summary ( model ) $ coeff [ SCORE ,] \n    prs.beta  -   as.numeric ( prs.coef [ 1 ]) \n    prs.se  -   as.numeric ( prs.coef [ 2 ]) \n    prs.p  -   as.numeric ( prs.coef [ 4 ]) \n     # We can then store the results \n    prs.result  -   rbind ( prs.result ,   data.frame ( Threshold = i ,  R2 = prs.r2 ,  P = prs.p ,  BETA = prs.beta , SE = prs.se ))  }  # Best result is: \nprs.result [ which.max ( prs.result $ R2 ),]    quick  p.threshold  -   c ( 0.001 , 0.05 , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 ) \nphenotype  -  read.table ( EUR.height ,  header = T ) \npcs  -  read.table ( EUR.eigenvec ,  header = F )  colnames ( pcs )   -   c ( FID ,   IID ,   paste0 ( PC , 1 : 6 ))  \ncovariate  -  read.table ( EUR.covariate ,  header = T ) \npheno  -   merge ( merge ( phenotype ,  covariate ,  by = c ( FID ,   IID )),  pcs ,  by = c ( FID , IID )) \nnull.r2  -   summary ( lm ( Height ~ . ,  data = pheno [, ! colnames ( pheno ) %in% c ( FID , IID )])) $ r.squared\nprs.result  -   NULL  for ( i  in  p.threshold ){ \n    pheno.prs  -   merge ( pheno ,  \n                        read.table ( paste0 ( EUR. , i , .profile ),  header = T )[, c ( FID , IID ,   SCORE )], \n                        by = c ( FID ,   IID )) \n    model  -   summary ( lm ( Height ~ . ,  data = pheno.prs [, ! colnames ( pheno.prs ) %in% c ( FID , IID )])) \n    model.r2  -  model $ r.squared\n    prs.r2  -  model.r2 - null.r2\n    prs.coef  -  model $ coeff [ SCORE ,] \n    prs.result  -   rbind ( prs.result ,  \n         data.frame ( Threshold = i ,  R2 = prs.r2 ,  \n                    P = as.numeric ( prs.coef [ 4 ]),  \n                    BETA = as.numeric ( prs.coef [ 1 ]), \n                    SE = as.numeric ( prs.coef [ 2 ])))  }  print ( prs.result [ which.max ( prs.result $ R2 ),])    Which p-value threshold generate the \"best\" PRS? 0.2   How much phenotypic variation does the \"best\" PRS explains? 0.04128065", 
            "title": "Finding the \"Best\" P-value threshold"
        }, 
        {
            "location": "/plink/#plotting-the-results", 
            "text": "The P-value threshold results can be visualized using  R   Note  We will be using  prs.result  generated in  previous section     Without ggplot2  # We strongly recommend the use of ggplot2. Only follow this code if you  # are desperate.  # Specify that we want to generate plot in EUR.height.bar.png \npng ( EUR.height.bar.png , \n      height = 10 ,  width = 10 ,  res = 300 ,  unit = in )  # First, obtain the colorings based on the p-value \ncol  -   suppressWarnings ( colorRampPalette ( c ( dodgerblue ,   firebrick )))  # We want the color gradient to match the ranking of p-values \nprs.result  -  prs.result [ order ( - log10 ( prs.result $ P )),] \nprs.result $ color  -    col ( nrow ( prs.result )) \nprs.result  -  prs.result [ order ( prs.result $ Threshold ),]  # generate a pretty format for p-value output \nprs.result $ print.p  -   round ( prs.result $ P ,  digits  =   3 ) \nprs.result $ print.p [ ! is.na ( prs.result $ print.p )    prs.result $ print.p  ==   0   ]   - \n     format ( prs.result $ P [ ! is.na ( prs.result $ print.p )    prs.result $ print.p  ==   0   ],  digits  =   2 ) \nprs.result $ print.p  -   sub ( e ,   *x*10^ ,  prs.result $ print.p )  # Generate the axis labels \nxlab  -   expression ( italic ( P )   -  value  ~  threshold  ~   ( italic ( P )[ T ])) \nylab  -   expression ( paste ( PRS model fit:   ,  R  ^   2 ))  # Setup the drawing area \nlayout ( t ( 1 : 2 ),  widths = c ( 8.8 , 1.2 )) \npar (  cex.lab = 1.5 ,  cex.axis = 1.25 ,  font.lab = 2 ,  \n    oma = c ( 0 , 0.5 , 0 , 0 ), \n    mar = c ( 4 , 6 , 0.5 , 0.5 ))  # Plotting the bars \nb -  barplot ( height = prs.result $ R2 ,  \n            col = prs.result $ color ,  \n            border = NA ,  \n            ylim = c ( 0 ,   max ( prs.result $ R2 ) * 1.25 ),  \n            axes  =   F ,  ann = F )  # Plot the axis labels and axis ticks \nodd  -   seq ( 0 , nrow ( prs.result ) +1 , 2 ) \neven  -   seq ( 1 , nrow ( prs.result ), 2 ) \naxis ( side = 1 ,  at = b [ odd ],  labels = prs.result $ Threshold [ odd ],  lwd = 2 ) \naxis ( side = 1 ,  at = b [ even ],  labels = prs.result $ Threshold [ even ], lwd = 2 ) \naxis ( side = 1 ,  at = c ( 0 , b [ 1 ], 2 * b [ length ( b )] - b [ length ( b ) -1 ]),  labels = c ( , , ),  lwd = 2 ,  lwd.tick = 0 )  # Write the p-value on top of each bar \ntext (   parse ( text = paste ( \n    prs.result $ print.p )),  \n    x  =  b +0.1 ,  \n    y  =   prs.result $ R2 +   ( max ( prs.result $ R2 ) * 1.05 - max ( prs.result $ R2 )),  \n    srt  =   45 )  # Now plot the axis lines \nbox ( bty = L ,  lwd = 2 ) \naxis ( 2 , las = 2 ,  lwd = 2 )  # Plot the axis titles \ntitle ( ylab = ylab ,  line = 4 ,  cex.lab = 1.5 ,  font = 2   ) \ntitle ( xlab = xlab ,  line = 2.5 ,  cex.lab = 1.5 ,  font = 2   )  # Generate plot area for the legend \npar ( cex.lab = 1.5 ,  cex.axis = 1.25 ,  font.lab = 2 ,  \n      mar = c ( 20 , 0 , 20 , 4 )) \nprs.result  -  prs.result [ order ( - log10 ( prs.result $ P )),] \nimage ( 1 ,   - log10 ( prs.result $ P ),   t ( seq_along ( - log10 ( prs.result $ P ))),  col = prs.result $ color ,  axes = F , ann = F ) \naxis ( 4 , las = 2 , xaxs = r , yaxs = r ,  tck = 0.2 ,  col = white )  # plot legend title \ntitle ( bquote ( atop ( - log [ 10 ]   ~  model ,  italic ( P )   -  value ),   ),  \n          line = 2 ,  cex = 1.5 ,  font = 2 ,  adj = 0 )  # write the plot to file \ndev.off ()    ggplot2  # ggplot2 is a handy package for plotting  library ( ggplot2 )  # generate a pretty format for p-value output \nprs.result $ print.p  -   round ( prs.result $ P ,  digits  =   3 ) \nprs.result $ print.p [ ! is.na ( prs.result $ print.p )   \n                       prs.result $ print.p  ==   0 ]   - \n     format ( prs.result $ P [ ! is.na ( prs.result $ print.p )   \n                            prs.result $ print.p  ==   0 ],  digits  =   2 ) \nprs.result $ print.p  -   sub ( e ,   *x*10^ ,  prs.result $ print.p )  # Initialize ggplot, requiring the threshold as the x-axis (use factor so that it is uniformly distributed) \nggplot ( data  =  prs.result ,  aes ( x  =   factor ( Threshold ),  y  =  R2 ))   + \n     # Specify that we want to print p-value on top of the bars \n    geom_text ( \n        aes ( label  =   paste ( print.p )), \n        vjust  =   -1.5 , \n        hjust  =   0 , \n        angle  =   45 , \n        cex  =   4 , \n        parse  =   T \n     )    + \n     # Specify the range of the plot, *1.25 to provide enough space for the p-values \n    scale_y_continuous ( limits  =   c ( 0 ,   max ( prs.result $ R2 )   *   1.25 ))   + \n     # Specify the axis labels \n    xlab ( expression ( italic ( P )   -  value  ~  threshold  ~   ( italic ( P )[ T ])))   + \n    ylab ( expression ( paste ( PRS model fit:   ,  R  ^   2 )))   + \n     # Draw a bar plot \n    geom_bar ( aes ( fill  =   - log10 ( P )),  stat  =   identity )   + \n     # Specify the colors \n    scale_fill_gradient2 ( \n        low  =   dodgerblue , \n        high  =   firebrick , \n        mid  =   dodgerblue , \n        midpoint  =   1e-4 , \n        name  =   bquote ( atop ( - log [ 10 ]   ~  model ,  italic ( P )   -  value ),) \n     )   + \n     # Some beautification of the plot \n    theme_classic ()   +  theme ( \n        axis.title  =  element_text ( face  =   bold ,  size  =   18 ), \n        axis.text  =  element_text ( size  =   14 ), \n        legend.title  =  element_text ( face  =   bold ,  size  = \n                                         18 ), \n        legend.text  =  element_text ( size  =   14 ), \n        axis.text.x  =  element_text ( angle  =   45 ,  hjust  = \n                                        1 ) \n     )  # save the plot \nggsave ( EUR.height.bar.png ,  height  =   7 ,  width  =   7 )      An example bar plot generated using  ggplot2   In addition, we can visualize the relationship between the \"best\" PRS and the phenotype of interest, colored by sex    Without ggplot2  # Read in the files \nprs  -  read.table ( EUR.0.2.profile ,  header = T ) \nheight  -  read.table ( EUR.height ,  header = T ) \nsex  -  read.table ( EUR.covariate ,  header = T )  # Rename the sex \nsex $ Sex  -   as.factor ( sex $ Sex )  levels ( sex $ Sex )   -   c ( Male ,   Female )  # Merge the files \ndat  -   merge ( merge ( prs ,  height ),  sex )  # Start plotting \nplot ( x = dat $ SCORE ,  y = dat $ Height ,  col = white , \n    xlab = Polygenic Score ,  ylab = Height )  with ( subset ( dat ,  Sex == Male ),  points ( x = SCORE ,  y = Height ,  col = red ))  with ( subset ( dat ,  Sex == Female ),  points ( x = SCORE ,  y = Height ,  col = blue ))    ggplot2  library ( ggplot2 )  # Read in the files \nprs  -  read.table ( EUR.0.2.profile ,  header = T ) \nheight  -  read.table ( EUR.height ,  header = T ) \nsex  -  read.table ( EUR.covariate ,  header = T )  # Rename the sex \nsex $ Sex  -   as.factor ( sex $ Sex )  levels ( sex $ Sex )   -   c ( Male ,   Female )  # Merge the files \ndat  -   merge ( merge ( prs ,  height ),  sex )  # Start plotting \nggplot ( dat ,  aes ( x = SCORE ,  y = Height ,  color = Sex )) + \n    geom_point () + \n    theme_classic () + \n    labs ( x = Polygenic Score ,  y = Height )      An example scatter plot generated using  ggplot2", 
            "title": "Plotting the Results"
        }, 
        {
            "location": "/prsice/", 
            "text": "An alternative to \nplink\n is \nPRSice-2\n, which automates much of the PRS analyses.\n\n\nAssuming we have the following files\n\n\n\n\n\n\n\n\nFile Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nGIANT.height.gz\n\n\nThe original summary statistic. PRSice-2 can directly apply INFO and MAF filtering on the summary statistic\n\n\n\n\n\n\nEUR.QC.bed\n\n\nThe genotype file after performing some basic filtering\n\n\n\n\n\n\nEUR.QC.bim\n\n\nThis file contains the SNPs that passed the basic filtering\n\n\n\n\n\n\nEUR.QC.fam\n\n\nThis file contains the samples that passed the basic filtering\n\n\n\n\n\n\nEUR.valid.sample\n\n\nThis file contains the samples that passed all the QC\n\n\n\n\n\n\nEUR.height\n\n\nThis file contains the phenotype of the samples\n\n\n\n\n\n\nEUR.covariate\n\n\nThis file contains the covariates of the samples\n\n\n\n\n\n\nEUR.eigenvec\n\n\nThis file contains the PCs of the samples\n\n\n\n\n\n\n\n\nAnd \nPRSice-2\n, which can be downloaded from\n\n\n\n\n\n\n\n\nOperating System\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nLinux 64-bit\n\n\nv2.1.11\n\n\n\n\n\n\nOS X 64-bit\n\n\nv2.1.11\n\n\n\n\n\n\nWindows 32-bit\n\n\nv2.1.11\n\n\n\n\n\n\nWindows 64-bit\n\n\nv2.1.11\n\n\n\n\n\n\n\n\nIn this tutorial, you will only need \nPRSice.R\n and \nPRSice_XXX\n where XXX is the operation system\n\n\nRunning PRS analysis\n\n\nIt is simple to run PRSice-2. First, we need a single covariate file. This can be done with \nR\n:\n\n\ncovariate \n-\n read.table\n(\nEUR.covariate\n,\n header\n=\nT\n)\n\npcs \n-\n read.table\n(\nEUR.eigenvec\n,\n header\n=\nF\n)\n\n\ncolnames\n(\npcs\n)\n \n-\n \nc\n(\nFID\n,\nIID\n,\n \npaste0\n(\nPC\n,\n1\n:\n6\n))\n\ncov \n-\n \nmerge\n(\ncovariate\n,\n pcs\n,\n by\n=\nc\n(\nFID\n,\n \nIID\n))\n\nwrite.table\n(\ncov\n,\nEUR.cov\n,\n quote\n=\nF\n,\n row.names\n=\nF\n)\n\n\n\nwhich generates \nEUR.cov\n\n\nPRSice-2 can then be run to obtain the PRS results:\n\n\n\n\n\n\nLinux\n\n\nRscript PRSice.R \n\\\n\n    --prsice PRSice_linux \n\\\n\n    --base Height.QC.gz \n\\\n\n    --target EUR.QC \n\\\n\n    --keep EUR.valid.sample \n\\\n\n    --binary-target F \n\\\n\n    --pheno-file EUR.height \n\\\n\n    --cov-file EUR.cov \n\\\n\n    --maf-base MAF,0.05 \n\\\n\n    --info-base INFO,0.8 \n\\\n\n    --out EUR\n\n\n\n\n\nOS X\n\n\nRscript PRSice.R \n\\\n\n    --prsice PRSice_mac \n\\\n\n    --base Height.QC.gz \n\\\n\n    --target EUR.QC \n\\\n\n    --keep EUR.valid.sample \n\\\n\n    --binary-target F \n\\\n\n    --pheno-file EUR.height \n\\\n\n    --cov-file EUR.cov \n\\\n\n    --maf-base MAF,0.05 \n\\\n\n    --info-base INFO,0.8 \n\\\n\n    --out EUR\n\n\n\n\n\nThis will automatically perform a \"high-resolution scoring\" and generate the \"best\" PRS (in \nEUR.best\n) and relevant graphs", 
            "title": "PRSice-2"
        }, 
        {
            "location": "/prsice/#running-prs-analysis", 
            "text": "It is simple to run PRSice-2. First, we need a single covariate file. This can be done with  R :  covariate  -  read.table ( EUR.covariate ,  header = T ) \npcs  -  read.table ( EUR.eigenvec ,  header = F )  colnames ( pcs )   -   c ( FID , IID ,   paste0 ( PC , 1 : 6 )) \ncov  -   merge ( covariate ,  pcs ,  by = c ( FID ,   IID )) \nwrite.table ( cov , EUR.cov ,  quote = F ,  row.names = F )  \nwhich generates  EUR.cov  PRSice-2 can then be run to obtain the PRS results:    Linux  Rscript PRSice.R  \\ \n    --prsice PRSice_linux  \\ \n    --base Height.QC.gz  \\ \n    --target EUR.QC  \\ \n    --keep EUR.valid.sample  \\ \n    --binary-target F  \\ \n    --pheno-file EUR.height  \\ \n    --cov-file EUR.cov  \\ \n    --maf-base MAF,0.05  \\ \n    --info-base INFO,0.8  \\ \n    --out EUR   OS X  Rscript PRSice.R  \\ \n    --prsice PRSice_mac  \\ \n    --base Height.QC.gz  \\ \n    --target EUR.QC  \\ \n    --keep EUR.valid.sample  \\ \n    --binary-target F  \\ \n    --pheno-file EUR.height  \\ \n    --cov-file EUR.cov  \\ \n    --maf-base MAF,0.05  \\ \n    --info-base INFO,0.8  \\ \n    --out EUR   This will automatically perform a \"high-resolution scoring\" and generate the \"best\" PRS (in  EUR.best ) and relevant graphs", 
            "title": "Running PRS analysis"
        }, 
        {
            "location": "/ldpred/", 
            "text": "Another popular PRS software is \nLDpred\n, which instead of performing p-value thresholding,\ninfers the posterior mean effect size of each marker by using a prior on effect sizes and LD information from an external reference panel, \nthus allow for a better \n\\(R^2\\)\n.\n\n\n\n\nNote\n\n\nPython 3 and other packages need to be installed before running LDpred. Please refer\nto the github for instructions of installation\n\n\n\n\n\n\nNote\n\n\nCurrent script is based on version 1.0.0\n\n\n\n\nAssuming we have the following files\n\n\n\n\n\n\n\n\nFile Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nHeight.QC.gz\n\n\nThe post-QCed summary statistic\n\n\n\n\n\n\nEUR.QC.bed\n\n\nThe genotype file after performing some basic filtering\n\n\n\n\n\n\nEUR.QC.bim\n\n\nThis file contains the SNPs that passed the basic filtering\n\n\n\n\n\n\nEUR.QC.fam\n\n\nThis file contains the samples that passed the basic filtering\n\n\n\n\n\n\nEUR.valid.sample\n\n\nThis file contains the samples that passed all the QC\n\n\n\n\n\n\nEUR.height\n\n\nThis file contains the phenotype of the samples\n\n\n\n\n\n\nEUR.covariate\n\n\nThis file contains the covariates of the samples\n\n\n\n\n\n\nEUR.eigenvec\n\n\nThis file contains the PCs of the samples\n\n\n\n\n\n\n\n\nRunning PRS analysis\n\n\nLDpred does not support in place filtering of sample and SNPs, therefore we need to generate a new QCed genotype file using \nplink\n\n\n# We also add the height phenotype for convenience\n\nplink \n\\\n\n    --bfile EUR.QC \n\\\n\n    --pheno EUR.height \n\\\n\n    --keep EUR.valid.sample \n\\\n\n    --make-bed \n\\\n\n    --out EUR.ldpred\n\n\n\n\nLDpred can then performs PRS analysis in three steps\n\n\n\n\n\n\nPreprocessing the summary statistic file\n\n# There are 253,288 samples in the Height GWAS\n\npython LDpred.py coord \n\\\n\n    --rs SNP \n\\\n\n    --A1 A1 \n\\\n\n    --A2 A2 \n\\\n\n    --pos BP \n\\\n\n    --chr CHR \n\\\n\n    --pval P \n\\\n\n    --eff OR \n\\\n\n    --ssf-format CUSTOM \n\\\n\n    --N \n253288\n \n\\\n\n    --ssf Height.QC.gz \n\\\n\n    --out EUR.coord \n\\\n\n    --gf EUR.ldpred\n\n\n\n\n\n\n\nAdjust the effect size\n\n# LDpred recommend radius to be Total number of SNPs in target / 3000\n\n python LDpred.py gibbs \n\\\n\n    --cf EUR.coord \n\\\n\n    --ldr \n183\n \n\\\n\n    --ldf EUR.ld \n\\\n\n    --out EUR.weight \n\\\n\n    --N \n253288\n;\n\n\n\n\n\n\n\n\nCalculate the PRS\n\npython LDpred.py score \n\\\n\n    --gf EUR.ldpred \n\\\n\n    --rf EUR.weight \n\\\n\n    --out EUR.score \n\\\n\n    --pf EUR.height \n\\\n\n    --pf-format LSTANDARD \n\n\n\n\n\n\n\n\n\nNote\n\n\nTo obtain the \n\\(R^2\\)\n of PRS obtained from different parameters, and / or \nadjust for covariate, you might need to use \nR\n (see \nhere\n)", 
            "title": "LDpred"
        }, 
        {
            "location": "/ldpred/#running-prs-analysis", 
            "text": "LDpred does not support in place filtering of sample and SNPs, therefore we need to generate a new QCed genotype file using  plink  # We also add the height phenotype for convenience \nplink  \\ \n    --bfile EUR.QC  \\ \n    --pheno EUR.height  \\ \n    --keep EUR.valid.sample  \\ \n    --make-bed  \\ \n    --out EUR.ldpred  LDpred can then performs PRS analysis in three steps    Preprocessing the summary statistic file # There are 253,288 samples in the Height GWAS \npython LDpred.py coord  \\ \n    --rs SNP  \\ \n    --A1 A1  \\ \n    --A2 A2  \\ \n    --pos BP  \\ \n    --chr CHR  \\ \n    --pval P  \\ \n    --eff OR  \\ \n    --ssf-format CUSTOM  \\ \n    --N  253288   \\ \n    --ssf Height.QC.gz  \\ \n    --out EUR.coord  \\ \n    --gf EUR.ldpred    Adjust the effect size # LDpred recommend radius to be Total number of SNPs in target / 3000 \n python LDpred.py gibbs  \\ \n    --cf EUR.coord  \\ \n    --ldr  183   \\ \n    --ldf EUR.ld  \\ \n    --out EUR.weight  \\ \n    --N  253288 ;     Calculate the PRS python LDpred.py score  \\ \n    --gf EUR.ldpred  \\ \n    --rf EUR.weight  \\ \n    --out EUR.score  \\ \n    --pf EUR.height  \\ \n    --pf-format LSTANDARD      Note  To obtain the  \\(R^2\\)  of PRS obtained from different parameters, and / or \nadjust for covariate, you might need to use  R  (see  here )", 
            "title": "Running PRS analysis"
        }, 
        {
            "location": "/lassosum/", 
            "text": "lassosum\n is an \nR\n package for PRS calculation. \nIt uses LASSO/Elastic Net estimates rather than p-value thresholding to generate PRS and are \nexpected to provide a higher \n\\(R^2\\)\n when compared to p-value thresholding.\n\n\nYou can install \nlassosum\n and its dependencies in \nR\n with the following\n\n\ninstall.packages\n(\nc\n(\ndevtools\n,\nRcppArmadillo\n,\n \ndata.table\n,\n \nMatrix\n),\n dependencies\n=\nTRUE\n)\n\ninstall_github\n(\ntshmak/lassosum\n)\n\n\n\n\n\nAssuming we have the following files\n\n\n\n\n\n\n\n\nFile Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nHeight.QC.gz\n\n\nThe post-QCed summary statistic\n\n\n\n\n\n\nEUR.QC.bed\n\n\nThe genotype file after performing some basic filtering\n\n\n\n\n\n\nEUR.QC.bim\n\n\nThis file contains the SNPs that passed the basic filtering\n\n\n\n\n\n\nEUR.QC.fam\n\n\nThis file contains the samples that passed the basic filtering\n\n\n\n\n\n\nEUR.valid.sample\n\n\nThis file contains the samples that passed all the QC\n\n\n\n\n\n\nEUR.height\n\n\nThis file contains the phenotype of the samples\n\n\n\n\n\n\nEUR.covariate\n\n\nThis file contains the covariates of the samples\n\n\n\n\n\n\nEUR.eigenvec\n\n\nThis file contains the PCs of the samples\n\n\n\n\n\n\n\n\nRunning PRS analysis\n\n\nWe can run lassosum as follow\n\n\nlibrary\n(\nlassosum\n)\n\n\n# Prefer to work with data.table as it speeds up file reading\n\n\nlibrary\n(\ndata.table\n)\n\n\nlibrary\n(\nmethods\n)\n\n\n# We like to use dplyr for it makes codes much more readable\n\n\nlibrary\n(\ndplyr\n)\n\nsum.stat \n-\n \nHeight.QC.gz\n\nref.bfile \n-\n \nEUR.QC\n\nbfile \n-\n \nEUR.QC\n\n\n# Read in and process the covariates\n\ncovariate \n-\n read.table\n(\nEUR.covariate\n,\n header\n=\nT\n)\n\npcs \n-\n read.table\n(\nEUR.eigenvec\n,\n header\n=\nF\n)\n\n\ncolnames\n(\npcs\n)\n \n-\n \nc\n(\nFID\n,\nIID\n,\n \npaste0\n(\nPC\n,\n1\n:\n6\n))\n\ncov \n-\n \nmerge\n(\ncovariate\n,\n pcs\n,\n by\n=\nc\n(\nFID\n,\n \nIID\n))\n\n\n\n# We will need the EUR.hg19 file provided by lassosum \n\n\n# which are LD regions defined in Berisa and Pickrell (2015) for the European population and the hg19 genome.\n\nld.file \n-\n  \nEUR.hg19\n \n\n# Number of sample in base\n\nsize \n-\n \n253288\n\n\n# output prefix\n\nprefix \n-\n \nEUR\n\n\n# Read in the target phenotype file\n\nfread\n(\nEUR.height\n,\n data.table \n=\n \nF\n)\n \n%\n%\n\n    select\n(\nFID\n,\n IID\n,\n Pheno\n)\n \n-\n target.pheno\n\n# Read in samples to include in the analysis\n\nfread\n(\nEUR.valid.sample\n,\n data.table\n=\nF\n)\n%\n%\n\n    select\n(\nFID\n,\n IID\n)\n \n-\n target.keep\n\n# Read in the summary statistics\n\nss \n-\n fread\n(\nsum.stat\n)\n\n\n# Remove P-value = 0, which causes problem in the transformation\n\nss \n-\n ss\n[\n!\nP \n==\n \n0\n,\n \n]\n\n\n# Read in the LD blocks\n\nld \n-\n fread\n(\nld.file\n)\n\n\n# Transform the P-values into correlation\n\ncor \n-\n p2cor\n(\np \n=\n ss\n$\nP\n,\n\n        n \n=\n size\n,\n\n        sign \n=\n \nlog\n(\nss\n$\nOR\n)\n\n        \n)\n\n\n# Run the lassosum pipeline\n\nout \n-\n lassosum.pipeline\n(\n\n    cor \n=\n cor\n,\n\n    chr \n=\n ss\n$\nCHR\n,\n\n    pos \n=\n ss\n$\nBP\n,\n\n    A1 \n=\n ss\n$\nA1\n,\n\n    A2 \n=\n ss\n$\nA2\n,\n\n    ref.bfile \n=\n ref.bfile\n,\n\n    keep.ref \n=\n target.keep\n,\n\n    test.bfile \n=\n bfile\n,\n\n    keep.test \n=\n target.keep\n,\n\n    LDblocks \n=\n ld\n,\n\n    trace \n=\n \n2\n\n\n)\n\n\n# Store the R2 results\n\ntarget.res \n-\n validate\n(\nout\n,\n pheno \n=\n target.pheno\n,\n covar\n=\ncov\n)\n\n\n# Get the maximum R2\n\nr2 \n-\n \nmax\n(\ntarget.res\n$\nvalidation.table\n$\nvalue\n)\n^\n2", 
            "title": "lassosum"
        }, 
        {
            "location": "/lassosum/#running-prs-analysis", 
            "text": "We can run lassosum as follow  library ( lassosum )  # Prefer to work with data.table as it speeds up file reading  library ( data.table )  library ( methods )  # We like to use dplyr for it makes codes much more readable  library ( dplyr ) \nsum.stat  -   Height.QC.gz \nref.bfile  -   EUR.QC \nbfile  -   EUR.QC  # Read in and process the covariates \ncovariate  -  read.table ( EUR.covariate ,  header = T ) \npcs  -  read.table ( EUR.eigenvec ,  header = F )  colnames ( pcs )   -   c ( FID , IID ,   paste0 ( PC , 1 : 6 )) \ncov  -   merge ( covariate ,  pcs ,  by = c ( FID ,   IID ))  # We will need the EUR.hg19 file provided by lassosum   # which are LD regions defined in Berisa and Pickrell (2015) for the European population and the hg19 genome. \nld.file  -    EUR.hg19   # Number of sample in base \nsize  -   253288  # output prefix \nprefix  -   EUR  # Read in the target phenotype file \nfread ( EUR.height ,  data.table  =   F )   % % \n    select ( FID ,  IID ,  Pheno )   -  target.pheno # Read in samples to include in the analysis \nfread ( EUR.valid.sample ,  data.table = F ) % % \n    select ( FID ,  IID )   -  target.keep # Read in the summary statistics \nss  -  fread ( sum.stat )  # Remove P-value = 0, which causes problem in the transformation \nss  -  ss [ ! P  ==   0 ,   ]  # Read in the LD blocks \nld  -  fread ( ld.file )  # Transform the P-values into correlation \ncor  -  p2cor ( p  =  ss $ P , \n        n  =  size , \n        sign  =   log ( ss $ OR ) \n         )  # Run the lassosum pipeline \nout  -  lassosum.pipeline ( \n    cor  =  cor , \n    chr  =  ss $ CHR , \n    pos  =  ss $ BP , \n    A1  =  ss $ A1 , \n    A2  =  ss $ A2 , \n    ref.bfile  =  ref.bfile , \n    keep.ref  =  target.keep , \n    test.bfile  =  bfile , \n    keep.test  =  target.keep , \n    LDblocks  =  ld , \n    trace  =   2  )  # Store the R2 results \ntarget.res  -  validate ( out ,  pheno  =  target.pheno ,  covar = cov )  # Get the maximum R2 \nr2  -   max ( target.res $ validation.table $ value ) ^ 2", 
            "title": "Running PRS analysis"
        }
    ]
}