{
    "docs": [
        {
            "location": "/", 
            "text": "Overview\n\n\nThis tutorial provides a step-by-step guide to performing basic polygenic risk score (PRS) analyses and accompanies our \nPRS Guide paper\n. The aim of this tutorial is to help those new to PRS to get started on PRS analyses and to provide existing users with a better understanding of the processes and implemention underlying popular PRS software.\n\n\nThe tutorial is separated into four main sections:\n\n\n\n\nQC of Base GWAS Summary Data\n\n\nQC of Target Individual-Level Data\n\n\nRunning PRS Analyses\n\n\nVisualizing PRS Results\n\n\n\n\nWe provide examples of performing PRS analyses using four software for polygenic risk score analyses: \nPLINK\n, \nPRSice-2\n, \nLDpred\n and \nlassosum\n\n\nIf you are only interested in how to perform PRS on previously QC'ed data then you can directly skip to \nStep 3\n. Links to download the required data are provided under each section.\n\n\n\n\nNote\n\n\nThis tutorial is written for Linux and OS X operating systems. \nWindows users will need to change some commands accordingly.\n\n\n\n\n\n\nNote\n\n\nThroughout the tutorial you will see tabs above some of the code:\n\n\n```bash tab=\"A\"\necho \"Tab A\"\n\n```bash tab=\nB\n\necho \nTab B\n\n\n\n\nYou can click on the tab to change to an alternative code (eg. to a different operation system)\n\n\n\n\nDatasets\n\n\n\n\nBase data\n: Modified summary statistic file from GIANT\n\n\nTarget data\n: Simulated data based on 1000 genome European samples\n\n\n\n\nRequirements\n\n\nTo follow the tutorial, you will need the following programs installed:\n\n\n\n\nR\n (\nversion 3.2.3+\n)\n\n\nPLINK 1.9\n\n\n\n\nCitation\n\n\nIf you find this tutorial helpful for a publication, then please consider citing:\n\n\n\n\nCitation\n\n\nChoi SW, Mak TSH, O'Reilly PF.  A guide to performing Polygenic Risk Score analyses. \nbioRxiv 416545 (2018). https://doi.org/10.1101/416545", 
            "title": "Overview"
        }, 
        {
            "location": "/#overview", 
            "text": "This tutorial provides a step-by-step guide to performing basic polygenic risk score (PRS) analyses and accompanies our  PRS Guide paper . The aim of this tutorial is to help those new to PRS to get started on PRS analyses and to provide existing users with a better understanding of the processes and implemention underlying popular PRS software.  The tutorial is separated into four main sections:   QC of Base GWAS Summary Data  QC of Target Individual-Level Data  Running PRS Analyses  Visualizing PRS Results   We provide examples of performing PRS analyses using four software for polygenic risk score analyses:  PLINK ,  PRSice-2 ,  LDpred  and  lassosum  If you are only interested in how to perform PRS on previously QC'ed data then you can directly skip to  Step 3 . Links to download the required data are provided under each section.   Note  This tutorial is written for Linux and OS X operating systems. \nWindows users will need to change some commands accordingly.    Note  Throughout the tutorial you will see tabs above some of the code:  ```bash tab=\"A\"\necho \"Tab A\" ```bash tab= B \necho  Tab B   You can click on the tab to change to an alternative code (eg. to a different operation system)", 
            "title": "Overview"
        }, 
        {
            "location": "/#datasets", 
            "text": "Base data : Modified summary statistic file from GIANT  Target data : Simulated data based on 1000 genome European samples", 
            "title": "Datasets"
        }, 
        {
            "location": "/#requirements", 
            "text": "To follow the tutorial, you will need the following programs installed:   R  ( version 3.2.3+ )  PLINK 1.9", 
            "title": "Requirements"
        }, 
        {
            "location": "/#citation", 
            "text": "If you find this tutorial helpful for a publication, then please consider citing:   Citation  Choi SW, Mak TSH, O'Reilly PF.  A guide to performing Polygenic Risk Score analyses. \nbioRxiv 416545 (2018). https://doi.org/10.1101/416545", 
            "title": "Citation"
        }, 
        {
            "location": "/base/", 
            "text": "First step in Polygenic Risk Score (PRS) analyses is to obtain the GWAS summary statistics. \n\n\nIn this example, we will use a modified version of the Height GWAS summary statistics generated by the \nGIANT consortium\n\n\nObtaining the summary statistic file\n\n\nYou can download the summary statistic file \nhere\n or use the following script:\n\ncurl https://github.com/choishingwan/PRS-Tutorial/raw/master/resources/GIANT.height.gz -L -O\n\n\n\nwhich will create a file call \nGIANT.height.gz\n in your current directory. \n\n\nA common problem is that the downloaded file can be corrupted, \nwhich can generate various error messages in the down-stream analyses. \nTo avoid un-necessary waste of time, it is generally a good practice to \ncheck if the file is intact. If the \nmd5sum\n hash is provided for the \noriginal file, you can check the file integrity by performing the \n\nmd5sum\n check:\n\n\n```bash tab=\"Linux\"\nmd5sum GIANT.height.gz\n\n```bash tab=\nOS X\n\nmd5 GIANT.height.gz\n\n\n\nif the file is intact, \nmd5sum\n should generate a string of characters: \n88413472f72823ee294f0916a36505d9\n. \nIf a different string is generated, the file is corrupted \n\n\nReading the summary statistic file\n\n\nGIANT.height.gz\n is compressed. To read its content, you can type:\n\n\ngunzip -c GIANT.height.gz \n|\n head\n\n\n\n\nwhich will shows the first 10 lines of the file\n\n\n\n\nNote\n\n\nWorking with compressed files reduces the storage space requirements\n\n\n\n\nThe \nGIANT.height.gz\n file contains the following columns:\n\n\n\n\n\n\n\n\nSNP\n\n\nCHR\n\n\nBP\n\n\nA1\n\n\nA2\n\n\nMAF\n\n\nSE\n\n\nP\n\n\nN\n\n\nINFO\n\n\nOR\n\n\n\n\n\n\n\n\n\n\nrs2073813\n\n\n1\n\n\n753541\n\n\nA\n\n\nG\n\n\n0.125\n\n\n0.0083\n\n\n0.68\n\n\n69852\n\n\n0.866425782879888\n\n\n0.996605773454898\n\n\n\n\n\n\nrs12562034\n\n\n1\n\n\n768448\n\n\nA\n\n\nG\n\n\n0.092\n\n\n0.0088\n\n\n0.55\n\n\n88015\n\n\n0.917520990188678\n\n\n0.994714020220009\n\n\n\n\n\n\nrs2980319\n\n\n1\n\n\n777122\n\n\nA\n\n\nT\n\n\n0.125\n\n\n0.006\n\n\n0.65\n\n\n148975\n\n\n0.847126999058955\n\n\n0.997303641721713\n\n\n\n\n\n\n\n\nWith each column corresponds to the following\n\n\n\n\nSNP\n: SNP ID, usually in the form of RS-ID\n\n\nCHR\n: The chromosome of which the SNP resides on\n\n\nBP\n: Chromosomal coordinate of the SNP\n\n\nA1\n: The effective alllele of the SNP\n\n\nA2\n: The non-effective allele of the SNP\n\n\nMAF\n: The minor allele frequency of the SNP\n\n\nSE\n: The standard error of the effect size esimate\n\n\nP\n: The P-value of association between the genotype of the SNP and the phenotype of interest\n\n\nN\n: Number of samples used to obtain the effect size estimate\n\n\nINFO\n: Usually the imputation information score. \n\n\nOR\n: The effect size estimate of the SNP. Can also be BETA\n\n\n\n\n\n\nImportant\n\n\nSome GWAS results files do not make clear which allele is the effect allele and which the non-effect allele. \nIf the incorrect assumption is made in computing the PRS, then the effect of the PRS in the target data will be in the wrong direction.\n\n\nTo avoid misleading conclusions it is critical that the effect allele from the base (GWAS) data is known.\n\n\n\n\nRemoving duplicated SNPs\n\n\nWhile it is rare, duplciated SNPs can sometimes be found in your base file.\nMost PRS software do not allow duplicated SNPs in the base input, therefore it\nis beneficial to remove the duplicated SNPs from the base file. \n\n\ngunzip -c GIANT.height.gz \n|\n\\\n\nawk \n{ print $1}\n \n|\n\\\n\nsort \n|\n\\\n\nuniq -d \n duplicated.snp\n\n\n\n\nBriefly, the above command does the following:\n\n\n\n\nDecompress and read the \nGIANT.height.gz\n file\n\n\nPrint out the first column of the file (which contains the SNP ID, change \n$1\n to other number if the SNP ID is located in another column, e.g. \n$3\n if the SNP ID is located on the third column)\n\n\nSort the SNP IDs. This will put duplicated SNP IDs next to eachother\n\n\nPrint out any duplicated SNP IDs using the uniq command and print it to the \nduplicated.snp\n file\n\n\n\n\nHow many duplicated SNPs are there?\nThere are a total of \n13\n duplicated SNPs\nDuplicated SNPs can then be removed using the \ngrep\n command:\n\ngunzip -c GIANT.height.gz  \n|\n\\\n\ngrep -vf duplicated.snp \n|\n\\\n\ngzip - \n Height.gz\n\n\n\nThe above script does the following:\n\n\n\n\nDecompress and read the \nGIANT.height.gz\n file \n\n\nFind if any row contains entries observed in \nduplicated.snp\n and remove them\n\n\nCompress and write the results to \nHeight.gz\n\n\n\n\nFiltering SNPs with low INFO score or MAF\n\n\nSNPs with low minor allele frequency (MAF) or imputation information score (INFO) are more likely to harbor false positives. \nIt is therefore beneficial to remove SNPs with low MAF and INFO.\nThis can be acheived using the following code:\n\n\ngunzip -c Height.gz \n|\n\\\n\nawk \nNR==1 || ($6 \n 0.05 \n $6 \n 0.95) \n ($10 \n 0.8) {print}\n \n|\n\\\n\ngzip  \n Height.QC.gz\n\n\n\n\n\n\nDecompress and read the \nHeight.gz\n file\n\n\nPrint the header line (\nNR==1\n)\n\n\nPrint any line with MAF above 0.05 and less than 0.95 (\n$6\n because the sixth column of the file contains the MAF information)\n\n\nPrint any line with INFO above 0.8 (\n$10\n because the tenth column of the file contains the INFO information)\n\n\nCompress and write the result to \nHeight.QC.gz\n\n\n\n\nThe \nHeight.QC.gz\n file can then be used for downstream analyses", 
            "title": "Base"
        }, 
        {
            "location": "/base/#obtaining-the-summary-statistic-file", 
            "text": "You can download the summary statistic file  here  or use the following script: curl https://github.com/choishingwan/PRS-Tutorial/raw/master/resources/GIANT.height.gz -L -O  which will create a file call  GIANT.height.gz  in your current directory.   A common problem is that the downloaded file can be corrupted, \nwhich can generate various error messages in the down-stream analyses. \nTo avoid un-necessary waste of time, it is generally a good practice to \ncheck if the file is intact. If the  md5sum  hash is provided for the \noriginal file, you can check the file integrity by performing the  md5sum  check:  ```bash tab=\"Linux\"\nmd5sum GIANT.height.gz ```bash tab= OS X \nmd5 GIANT.height.gz  if the file is intact,  md5sum  should generate a string of characters:  88413472f72823ee294f0916a36505d9 . \nIf a different string is generated, the file is corrupted", 
            "title": "Obtaining the summary statistic file"
        }, 
        {
            "location": "/base/#reading-the-summary-statistic-file", 
            "text": "GIANT.height.gz  is compressed. To read its content, you can type:  gunzip -c GIANT.height.gz  |  head  which will shows the first 10 lines of the file   Note  Working with compressed files reduces the storage space requirements   The  GIANT.height.gz  file contains the following columns:     SNP  CHR  BP  A1  A2  MAF  SE  P  N  INFO  OR      rs2073813  1  753541  A  G  0.125  0.0083  0.68  69852  0.866425782879888  0.996605773454898    rs12562034  1  768448  A  G  0.092  0.0088  0.55  88015  0.917520990188678  0.994714020220009    rs2980319  1  777122  A  T  0.125  0.006  0.65  148975  0.847126999058955  0.997303641721713     With each column corresponds to the following   SNP : SNP ID, usually in the form of RS-ID  CHR : The chromosome of which the SNP resides on  BP : Chromosomal coordinate of the SNP  A1 : The effective alllele of the SNP  A2 : The non-effective allele of the SNP  MAF : The minor allele frequency of the SNP  SE : The standard error of the effect size esimate  P : The P-value of association between the genotype of the SNP and the phenotype of interest  N : Number of samples used to obtain the effect size estimate  INFO : Usually the imputation information score.   OR : The effect size estimate of the SNP. Can also be BETA    Important  Some GWAS results files do not make clear which allele is the effect allele and which the non-effect allele. \nIf the incorrect assumption is made in computing the PRS, then the effect of the PRS in the target data will be in the wrong direction.  To avoid misleading conclusions it is critical that the effect allele from the base (GWAS) data is known.", 
            "title": "Reading the summary statistic file"
        }, 
        {
            "location": "/base/#removing-duplicated-snps", 
            "text": "While it is rare, duplciated SNPs can sometimes be found in your base file.\nMost PRS software do not allow duplicated SNPs in the base input, therefore it\nis beneficial to remove the duplicated SNPs from the base file.   gunzip -c GIANT.height.gz  | \\ \nawk  { print $1}   | \\ \nsort  | \\ \nuniq -d   duplicated.snp  Briefly, the above command does the following:   Decompress and read the  GIANT.height.gz  file  Print out the first column of the file (which contains the SNP ID, change  $1  to other number if the SNP ID is located in another column, e.g.  $3  if the SNP ID is located on the third column)  Sort the SNP IDs. This will put duplicated SNP IDs next to eachother  Print out any duplicated SNP IDs using the uniq command and print it to the  duplicated.snp  file   How many duplicated SNPs are there? There are a total of  13  duplicated SNPs Duplicated SNPs can then be removed using the  grep  command: gunzip -c GIANT.height.gz   | \\ \ngrep -vf duplicated.snp  | \\ \ngzip -   Height.gz  The above script does the following:   Decompress and read the  GIANT.height.gz  file   Find if any row contains entries observed in  duplicated.snp  and remove them  Compress and write the results to  Height.gz", 
            "title": "Removing duplicated SNPs"
        }, 
        {
            "location": "/base/#filtering-snps-with-low-info-score-or-maf", 
            "text": "SNPs with low minor allele frequency (MAF) or imputation information score (INFO) are more likely to harbor false positives. \nIt is therefore beneficial to remove SNPs with low MAF and INFO.\nThis can be acheived using the following code:  gunzip -c Height.gz  | \\ \nawk  NR==1 || ($6   0.05   $6   0.95)   ($10   0.8) {print}   | \\ \ngzip    Height.QC.gz   Decompress and read the  Height.gz  file  Print the header line ( NR==1 )  Print any line with MAF above 0.05 and less than 0.95 ( $6  because the sixth column of the file contains the MAF information)  Print any line with INFO above 0.8 ( $10  because the tenth column of the file contains the INFO information)  Compress and write the result to  Height.QC.gz   The  Height.QC.gz  file can then be used for downstream analyses", 
            "title": "Filtering SNPs with low INFO score or MAF"
        }, 
        {
            "location": "/lassosum/", 
            "text": "lassosum\n is an \nR\n package for PRS calculation. \nIt uses LASSO/Elastic Net estimates rather than p-value thresholding to generate PRS and are \nexpected to provide a higher \n\\(R^2\\)\n when compared to p-value thresholding.\n\n\nYou can install \nlassosum\n and its dependencies in \nR\n with the following\n\n\ninstall.packages\n(\nc\n(\ndevtools\n,\nRcppArmadillo\n,\n \ndata.table\n,\n \nMatrix\n),\n dependencies\n=\nTRUE\n)\n\n\nlibrary\n(\ndevtools\n)\n\ninstall_github\n(\ntshmak/lassosum\n)\n\n\n\n\n\nAssuming we have the following files\n\n\n\n\n\n\n\n\nFile Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nHeight.QC.gz\n\n\nThe post-QCed summary statistic\n\n\n\n\n\n\nEUR.QC.bed\n\n\nThe genotype file after performing some basic filtering\n\n\n\n\n\n\nEUR.QC.bim\n\n\nThis file contains the SNPs that passed the basic filtering\n\n\n\n\n\n\nEUR.QC.fam\n\n\nThis file contains the samples that passed the basic filtering\n\n\n\n\n\n\nEUR.valid.sample\n\n\nThis file contains the samples that passed all the QC\n\n\n\n\n\n\nEUR.height\n\n\nThis file contains the phenotype of the samples\n\n\n\n\n\n\nEUR.covariate\n\n\nThis file contains the covariates of the samples\n\n\n\n\n\n\nEUR.eigenvec\n\n\nThis file contains the PCs of the samples\n\n\n\n\n\n\n\n\nRunning PRS analysis\n\n\nWe can run lassosum as follow\n\n\nlibrary\n(\nlassosum\n)\n\n\n# Prefer to work with data.table as it speeds up file reading\n\n\nlibrary\n(\ndata.table\n)\n\n\nlibrary\n(\nmethods\n)\n\n\n# We like to use dplyr for it makes codes much more readable\n\n\nlibrary\n(\ndplyr\n)\n\nsum.stat \n-\n \nHeight.QC.gz\n\nbfile \n-\n \nEUR.QC\n\n\n# Read in and process the covariates\n\ncovariate \n-\n fread\n(\nEUR.covariate\n)\n\npcs \n-\n fread\n(\nEUR.eigenvec\n)\n\n\ncolnames\n(\npcs\n)\n \n-\n \nc\n(\nFID\n,\nIID\n,\n \npaste0\n(\nPC\n,\n1\n:\n6\n))\n\n\n# Need as.data.frame here as lassosum doesn\nt handle data.table \n\n\n# covariates very well\n\ncov \n-\n \nas.data.frame\n(\nmerge\n(\ncovariate\n,\n pcs\n,\n by\n=\nc\n(\nFID\n,\n \nIID\n)))\n\n\n\n# We will need the EUR.hg19 file provided by lassosum \n\n\n# which are LD regions defined in Berisa and Pickrell (2015) for the European population and the hg19 genome.\n\nld.file \n-\n \nsystem.file\n(\ndata\n,\n \nBerisa.EUR.hg19.bed\n,\npackage\n=\nlassosum\n)\n\n\n# output prefix\n\nprefix \n-\n \nEUR\n\n\n# Read in the target phenotype file\n\ntarget.pheno \n-\n \nas.data.frame\n(\nfread\n(\nEUR.height\n)[,\nc\n(\nFID\n,\n \nIID\n,\n \nHeight\n)])\n\n\n# Read in samples to include in the analysis\n\ntarget.keep \n-\n fread\n(\nEUR.valid.sample\n)[,\nc\n(\nFID\n,\n \nIID\n)]\n\n\n# Read in the summary statistics\n\nss \n-\n fread\n(\nsum.stat\n)\n\n\n# Number of sample in base\n\nsize \n-\n \n253288\n\n\n# Remove P-value = 0, which causes problem in the transformation\n\nss \n-\n ss\n[\n!\nP \n==\n \n0\n]\n\n\n# Read in the LD blocks\n\nld \n-\n fread\n(\nld.file\n)\n\n\n# Transform the P-values into correlation\n\ncor \n-\n p2cor\n(\np \n=\n ss\n$\nP\n,\n\n        n \n=\n size\n,\n\n        sign \n=\n \nlog\n(\nss\n$\nOR\n)\n\n        \n)\n\n\n# Because FID of our samples are all 0, we might encounter problem with lassosum\n\n\n# we need to provide a T/F vector instead of the target.keep file\n\ntarget.keep\n[,\n ID\n:=\ndo.call\n(\npaste\n,\n \nc\n(\n.\nSD\n,\n sep\n=\n:\n)),\n.\nSDcols\n=\nc\n(\n1\n:\n2\n)]\n\nfam \n-\n fread\n(\npaste0\n(\nbfile\n,\n \n.fam\n))\n\nfam\n[,\nID\n:=\ndo.call\n(\npaste\n,\n \nc\n(\n.\nSD\n,\n sep\n=\n:\n)),\n.\nSDcols\n=\nc\n(\n1\n:\n2\n)]\n\n\nkeep \n-\n fam\n$\nID \n%in%\n target.keep\n$\nID\n\n# Run the lassosum pipeline\n\nout \n-\n lassosum.pipeline\n(\n\n    cor \n=\n cor\n,\n\n    chr \n=\n ss\n$\nCHR\n,\n\n    pos \n=\n ss\n$\nBP\n,\n\n    A1 \n=\n ss\n$\nA1\n,\n\n    A2 \n=\n ss\n$\nA2\n,\n\n    ref.bfile \n=\n bfile\n,\n\n    keep.ref \n=\n keep\n,\n\n    test.bfile \n=\n bfile\n,\n\n    keep.test \n=\n keep\n,\n\n    LDblocks \n=\n ld\n,\n\n    trace \n=\n \n2\n\n\n)\n\n\n# Store the R2 results\n\ntarget.res \n-\n validate\n(\nout\n,\n pheno \n=\n target.pheno\n,\n covar\n=\ncov\n)\n\n\n# Get the maximum R2\n\nr2 \n-\n \nmax\n(\ntarget.res\n$\nvalidation.table\n$\nvalue\n)\n^\n2", 
            "title": "Lassosum"
        }, 
        {
            "location": "/lassosum/#running-prs-analysis", 
            "text": "We can run lassosum as follow  library ( lassosum )  # Prefer to work with data.table as it speeds up file reading  library ( data.table )  library ( methods )  # We like to use dplyr for it makes codes much more readable  library ( dplyr ) \nsum.stat  -   Height.QC.gz \nbfile  -   EUR.QC  # Read in and process the covariates \ncovariate  -  fread ( EUR.covariate ) \npcs  -  fread ( EUR.eigenvec )  colnames ( pcs )   -   c ( FID , IID ,   paste0 ( PC , 1 : 6 ))  # Need as.data.frame here as lassosum doesn t handle data.table   # covariates very well \ncov  -   as.data.frame ( merge ( covariate ,  pcs ,  by = c ( FID ,   IID )))  # We will need the EUR.hg19 file provided by lassosum   # which are LD regions defined in Berisa and Pickrell (2015) for the European population and the hg19 genome. \nld.file  -   system.file ( data ,   Berisa.EUR.hg19.bed , package = lassosum )  # output prefix \nprefix  -   EUR  # Read in the target phenotype file \ntarget.pheno  -   as.data.frame ( fread ( EUR.height )[, c ( FID ,   IID ,   Height )])  # Read in samples to include in the analysis \ntarget.keep  -  fread ( EUR.valid.sample )[, c ( FID ,   IID )]  # Read in the summary statistics \nss  -  fread ( sum.stat )  # Number of sample in base \nsize  -   253288  # Remove P-value = 0, which causes problem in the transformation \nss  -  ss [ ! P  ==   0 ]  # Read in the LD blocks \nld  -  fread ( ld.file )  # Transform the P-values into correlation \ncor  -  p2cor ( p  =  ss $ P , \n        n  =  size , \n        sign  =   log ( ss $ OR ) \n         )  # Because FID of our samples are all 0, we might encounter problem with lassosum  # we need to provide a T/F vector instead of the target.keep file \ntarget.keep [,  ID := do.call ( paste ,   c ( . SD ,  sep = : )), . SDcols = c ( 1 : 2 )] \nfam  -  fread ( paste0 ( bfile ,   .fam )) \nfam [, ID := do.call ( paste ,   c ( . SD ,  sep = : )), . SDcols = c ( 1 : 2 )] \n\nkeep  -  fam $ ID  %in%  target.keep $ ID # Run the lassosum pipeline \nout  -  lassosum.pipeline ( \n    cor  =  cor , \n    chr  =  ss $ CHR , \n    pos  =  ss $ BP , \n    A1  =  ss $ A1 , \n    A2  =  ss $ A2 , \n    ref.bfile  =  bfile , \n    keep.ref  =  keep , \n    test.bfile  =  bfile , \n    keep.test  =  keep , \n    LDblocks  =  ld , \n    trace  =   2  )  # Store the R2 results \ntarget.res  -  validate ( out ,  pheno  =  target.pheno ,  covar = cov )  # Get the maximum R2 \nr2  -   max ( target.res $ validation.table $ value ) ^ 2", 
            "title": "Running PRS analysis"
        }, 
        {
            "location": "/ldpred/", 
            "text": "Another popular PRS software is \nLDpred\n, which instead of performing p-value thresholding,\ninfers the posterior mean effect size of each marker by using a prior on effect sizes and LD information from an external reference panel, \nthus allow for a better \n\\(R^2\\)\n.\n\n\n\n\nNote\n\n\nPython 3 and other packages need to be installed before running LDpred. \nPlease refer to their website for instructions of installation.\n\n\nIf you have Python installed, you might be able to install LDpred with\n\npip install ldpred\n\n\n\n\n\n\n\nNote\n\n\nCurrent script is based on version 1.0.6\n\n\n\n\nAssuming we have the following files\n\n\n\n\n\n\n\n\nFile Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nHeight.QC.gz\n\n\nThe post-QCed summary statistic\n\n\n\n\n\n\nEUR.QC.bed\n\n\nThe genotype file after performing some basic filtering\n\n\n\n\n\n\nEUR.QC.bim\n\n\nThis file contains the SNPs that passed the basic filtering\n\n\n\n\n\n\nEUR.QC.fam\n\n\nThis file contains the samples that passed the basic filtering\n\n\n\n\n\n\nEUR.valid.sample\n\n\nThis file contains the samples that passed all the QC\n\n\n\n\n\n\nEUR.height\n\n\nThis file contains the phenotype of the samples\n\n\n\n\n\n\nEUR.covariate\n\n\nThis file contains the covariates of the samples\n\n\n\n\n\n\nEUR.eigenvec\n\n\nThis file contains the PCs of the samples\n\n\n\n\n\n\n\n\nRunning PRS analysis\n\n\nLDpred does not support in place filtering of sample and SNPs, therefore we need to generate a new QCed genotype file using \nplink\n\n\n# We also add the height phenotype for convenience\n\nplink \n\\\n\n    --bfile EUR.QC \n\\\n\n    --pheno EUR.height \n\\\n\n    --keep EUR.valid.sample \n\\\n\n    --make-bed \n\\\n\n    --out EUR.ldpred\n\n\n\n\nLDpred can then performs PRS analysis in three steps\n\n\n\n\n\n\nPreprocessing the summary statistic file\n\n# There are 253,288 samples in the Height GWAS\n\npython LDpred.py coord \n\\\n\n    --rs SNP \n\\\n\n    --A1 A1 \n\\\n\n    --A2 A2 \n\\\n\n    --pos BP \n\\\n\n    --chr CHR \n\\\n\n    --pval P \n\\\n\n    --eff OR \n\\\n\n    --ssf-format CUSTOM \n\\\n\n    --N \n253288\n \n\\\n\n    --ssf Height.QC.gz \n\\\n\n    --out EUR.coord \n\\\n\n    --gf EUR.ldpred\n\n\n\n\n\n\n\nAdjust the effect size\n\n# LDpred recommend radius to be Total number of SNPs in target / 3000\n\n python LDpred.py gibbs \n\\\n\n    --cf EUR.coord \n\\\n\n    --ldr \n183\n \n\\\n\n    --ldf EUR.ld \n\\\n\n    --out EUR.weight \n\\\n\n    --N \n253288\n\n\n\n\n\n\n\n\nCalculate the PRS\n\npython LDpred.py score \n\\\n\n    --gf EUR.ldpred \n\\\n\n    --rf EUR.weight \n\\\n\n    --out EUR.score \n\\\n\n    --pf EUR.height \n\\\n\n    --pf-format LSTANDARD \n\n\n\n\n\n\n\n\n\nNote\n\n\nTo obtain the \n\\(R^2\\)\n of PRS obtained from different parameters, and / or \nadjust for covariate, you might need to use \nR\n (see \nhere\n)", 
            "title": "Ldpred"
        }, 
        {
            "location": "/ldpred/#running-prs-analysis", 
            "text": "LDpred does not support in place filtering of sample and SNPs, therefore we need to generate a new QCed genotype file using  plink  # We also add the height phenotype for convenience \nplink  \\ \n    --bfile EUR.QC  \\ \n    --pheno EUR.height  \\ \n    --keep EUR.valid.sample  \\ \n    --make-bed  \\ \n    --out EUR.ldpred  LDpred can then performs PRS analysis in three steps    Preprocessing the summary statistic file # There are 253,288 samples in the Height GWAS \npython LDpred.py coord  \\ \n    --rs SNP  \\ \n    --A1 A1  \\ \n    --A2 A2  \\ \n    --pos BP  \\ \n    --chr CHR  \\ \n    --pval P  \\ \n    --eff OR  \\ \n    --ssf-format CUSTOM  \\ \n    --N  253288   \\ \n    --ssf Height.QC.gz  \\ \n    --out EUR.coord  \\ \n    --gf EUR.ldpred    Adjust the effect size # LDpred recommend radius to be Total number of SNPs in target / 3000 \n python LDpred.py gibbs  \\ \n    --cf EUR.coord  \\ \n    --ldr  183   \\ \n    --ldf EUR.ld  \\ \n    --out EUR.weight  \\ \n    --N  253288     Calculate the PRS python LDpred.py score  \\ \n    --gf EUR.ldpred  \\ \n    --rf EUR.weight  \\ \n    --out EUR.score  \\ \n    --pf EUR.height  \\ \n    --pf-format LSTANDARD      Note  To obtain the  \\(R^2\\)  of PRS obtained from different parameters, and / or \nadjust for covariate, you might need to use  R  (see  here )", 
            "title": "Running PRS analysis"
        }, 
        {
            "location": "/plink/", 
            "text": "Background\n\n\nIn this section, we will try to calculate polygenic risk score using \nplink\n to illustrate some common procedure\nperformed by PRS software.\n\n\nRequired Data\n\n\nIn previous sections, we have generated the following files\n\n\n\n\n\n\n\n\nFile Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nHeight.QC.gz\n\n\nThe post-QCed summary statistic\n\n\n\n\n\n\nEUR.QC.bed\n\n\nThe genotype file after performing some basic filtering\n\n\n\n\n\n\nEUR.QC.bim\n\n\nThis file contains the SNPs that passed the basic filtering\n\n\n\n\n\n\nEUR.QC.fam\n\n\nThis file contains the samples that passed the basic filtering\n\n\n\n\n\n\nEUR.valid.sample\n\n\nThis file contains the samples that passed all the QC\n\n\n\n\n\n\nEUR.height\n\n\nThis file contains the phenotype of the samples\n\n\n\n\n\n\nEUR.covariate\n\n\nThis file contains the covariates of the samples\n\n\n\n\n\n\n\n\nRemove Ambiguous SNPs\n\n\nIf the base and target data were generated using different genotyping chips and the chromosome strand (+/-) for either is unknown, then it is not possible to match ambiguous SNPs (i.e. those with complementary alleles, either C/G or A/T) across the data sets, because it will be unknown whether the base and target data are referring to the same allele or not. \n\n\nAmbiguous SNPs can be obtained by examining the bim file:\n\nawk \n!( ($5==\nA\n \n $6==\nT\n) || \\\n\n\n        ($5==\nT\n \n $6==\nA\n) || \\\n\n\n        ($5==\nG\n \n $6==\nC\n) || \\\n\n\n        ($5==\nC\n \n $6==\nG\n)) {print}\n \n\\\n\n        EUR.QC.bim \n EUR.unambig.snp \n\n\n\nHow many ambiguous SNPs were there?\nThere are \n330,818\n ambiguous SNPs\nStrand Flipping\n\n\nIn addition, when there are non-ambiguous mismatch in allele \ncoding between the data sets, such as A/C in the base\nand G/T in the target data, then this can be resolved by \n\u2018flipping\u2019 the alleles in the target data to their complementary alleles. \nThis has to be done with mulitpe steps\n\n\n\n\nGet the correct A1 alleles for the bim file\n\n\n\n\n```R tab=\"Without data.table\"\nbim \n- read.table(\"EUR.QC.bim\", header = F, stringsAsFactors = F)\ncolnames(bim) \n- c(\"CHR\", \"SNP\", \"CM\", \"BP\", \"B.A1\", \"B.A2\")\nheight \n-\n    read.table(gzfile(\"Height.QC.gz\"),\n               header = T,\n               stringsAsFactors = F)\n\n\nChange all alleles to upper case for easy comparison\n\n\nheight\n\\(A1 \n- toupper(height\\)\nA1)\nheight\n\\(A2 \n- toupper(height\\)\nA2)\nbim\n\\(B.A1 \n- toupper(bim\\)\nB.A1)\nbim\n\\(B.A2 \n- toupper(bim\\)\nB.A2)\ninfo \n- merge(bim, height, by = c(\"SNP\", \"CHR\", \"BP\"))\n\n\nFunction for finding the complementary allele\n\n\ncomplement \n- function(x) {\n    switch (\n        x,\n        \"A\" = \"T\",\n        \"C\" = \"G\",\n        \"T\" = \"A\",\n        \"G\" = \"C\",\n        return(NA)\n    )\n}\n\n\nGet SNPs that has the same alleles across base and target\n\n\ninfo.match \n- subset(info, A1 == B.A1 \n A2 == B.A2)\n\n\nIdentify SNPs that are complementary between base and target\n\n\ninfo\n\\(C.A1 \n- sapply(info\\)\nB.A1, complement)\ninfo\n\\(C.A2 \n- sapply(info\\)\nB.A2, complement)\ninfo.complement \n- subset(info, A1 == C.A1 \n A2 == C.A2)\n\n\nUpdate these allele coding in the bim file\n\n\nbim[bim\n\\(SNP %in% info.complement\\)\nSNP,]\n\\(B.A1 \n-\n    sapply(bim[bim\\)\nSNP %in% info.complement\n\\(SNP,]\\)\nB.A1, complement)\nbim[bim\n\\(SNP %in% info.complement\\)\nSNP,]\n\\(B.A2 \n-\n    sapply(bim[bim\\)\nSNP %in% info.complement\n\\(SNP,]\\)\nB.A2, complement)\n\n\nidentify SNPs that need flipping\n\n\ninfo.flip \n- subset(info, A1 == B.A2 \n A2 == B.A1)\n\n\nidentify SNPs that need flipping \n complement\n\n\ninfo.cflip \n- subset(info, A1 == C.A2 \n A2 == C.A1)\n\n\nUpdate these allele coding in the bim file\n\n\ncom.snps \n- bim\n\\(SNP %in% info.cflip\\)\nSNP\nbim[com.snps,]\n\\(B.A1 \n- sapply(bim[com.snps,]\\)\nB.A1, complement)\nbim[com.snps,]\n\\(B.A2 \n- sapply(bim[com.snps,]\\)\nB.A2, complement)\n\n\nGet list of SNPs that need to change the A1 encoding\n\n\nflip \n- rbind(info.flip, info.cflip)\nflip.snp \n- data.frame(SNP = flip\n\\(SNP, A1 = flip\\)\nA1)\nwrite.table(flip.snp,\n            \"EUR.update.a1\",\n            quote = F,\n            row.names = F)\nwrite.table(\n    bim,\n    \"EUR.QC.adj.bim\",\n    quote = F,\n    row.names = F,\n    col.names = F\n)\n\n\nAnd we want to remove any SNPs that do not match with the base data\n\n\nmismatch \n-\n    bim\n\\(SNP[!(bim\\)\nSNP %in% info.match\n\\(SNP |\n                  bim\\)\nSNP %in% info.complement\n\\(SNP | \n                  bim\\)\nSNP %in% flip$SNP)]\nwrite.table(\n    mismatch,\n    \"EUR.mismatch\",\n    quote = F,\n    row.names = F,\n    col.names = F\n)\n\n``\n`R tab\n=\nWith data.table\n\n\nlibrary\n(\ndata.table\n)\n\nbim \n-\n fread\n(\nEUR.QC.bim\n)\n\nbim.col \n-\n \nc\n(\nCHR\n,\n \nSNP\n,\n \nCM\n,\n \nBP\n,\n \nB.A1\n,\n \nB.A2\n)\n\nsetnames\n(\nbim\n,\n \ncolnames\n(\nbim\n),\n bim.col\n)\n\nheight \n-\n fread\n(\nHeight.QC.gz\n)\n\n\n# Change all alleles to upper case for easy comparison\n\nheight\n[,\nc\n(\nA1\n,\nA2\n)\n:=\nlist\n(\ntoupper\n(\nA1\n),\n \ntoupper\n(\nA2\n))]\n\nbim\n[,\nc\n(\nB.A1\n,\nB.A2\n)\n:=\nlist\n(\ntoupper\n(\nB.A1\n),\n \ntoupper\n(\nB.A2\n))]\n\ninfo \n-\n \nmerge\n(\nbim\n,\n height\n,\n by\n=\nc\n(\nSNP\n,\n \nCHR\n,\n \nBP\n))\n\n\n# Function for calculating the complementary allele\n\ncomplement \n-\n \nfunction\n(\nx\n){\n\n    \nswitch\n \n(\nx\n,\n\n        \nA\n \n=\n \nT\n,\n\n        \nC\n \n=\n \nG\n,\n\n        \nT\n \n=\n \nA\n,\n\n        \nG\n \n=\n \nC\n,\n\n        \nreturn\n(\nNA\n)\n\n    \n)\n\n\n}\n\n\n# Identify SNPs that are complementary between base and target\n\ncom.snps \n-\n info\n[\nsapply\n(\nB.A1\n,\n complement\n)\n \n==\n A1 \n\n                     \nsapply\n(\nB.A2\n,\n complement\n)\n \n==\n A2\n,\n SNP\n]\n\n\n# Now update the bim file\n\nbim\n[\nSNP \n%in%\n com.snps\n,\n \nc\n(\nB.A1\n,\n \nB.A2\n)\n \n:=\n\n        \nlist\n(\nsapply\n(\nB.A1\n,\n complement\n),\n\n             \nsapply\n(\nB.A2\n,\n complement\n))]\n\n\n# identify SNPs that need flipping \n complement\n\ncom.flip \n-\n info\n[\nsapply\n(\nB.A1\n,\n complement\n)\n \n==\n A2 \n\n                     \nsapply\n(\nB.A2\n,\n complement\n)\n \n==\n A1\n,\n SNP\n]\n\n\n# Now update the bim file\n\nbim\n[\nSNP \n%in%\n com.flip\n,\n \nc\n(\nB.A1\n,\n \nB.A2\n)\n \n:=\n\n        \nlist\n(\nsapply\n(\nB.A1\n,\n complement\n),\n\n             \nsapply\n(\nB.A2\n,\n complement\n))]\n\n\n# Obtain list of SNPs that require flipping\n\nflip \n-\n info\n[\nB.A1\n==\nA2 \n B.A2\n==\nA1\n]\n\n\n# Now generate file for PLINK \n\nfwrite\n(\nflip\n[,\nc\n(\nSNP\n,\n \nA1\n)],\n \nEUR.update.a1\n,\n sep\n=\n\\t\n)\n\n\n# Write the updated bim file\n\nfwrite\n(\nbim\n,\n \nEUR.QC.adj.bim\n,\n col.names\n=\nF\n,\n sep\n=\n\\t\n)\n\n\n# We can then remove all mismatch SNPs\n\nmatched \n-\n info\n[(\nA1 \n==\n B.A1 \n A2 \n==\n B.A2\n)\n \n|\n\n                    \n(\nA1 \n==\n B.A2 \n A2 \n==\n B.A1\n)\n \n|\n\n                    \n(\nA1 \n==\n \nsapply\n(\nB.A1\n,\n complement\n)\n \n\n                         A2 \n==\n \nsapply\n(\nB.A2\n,\n complement\n))\n \n|\n\n                    \n(\nA1 \n==\n \nsapply\n(\nB.A2\n,\n complement\n)\n \n\n                         A2 \n==\n \nsapply\n(\nB.A1\n,\n complement\n))]\n\nmismatch \n-\n bim\n[\n!\nSNP\n%in%\nmatched\n$\nSNP\n,\n SNP\n]\n\nwrite.table\n(\nmismatch\n,\n \nEUR.mismatch\n,\n quote\n=\nF\n,\n row.names\n=\nF\n,\n col.names\n=\nF\n)\n\n\n\n\nThe above script will generate three files: \nEUR.QC.adj.bim\n, \nEUR.update.a1\n and \nEUR.mismatch\n. We want to replace\n\nEUR.QC.bim\n with \nEUR.QC.adj.bim\n:\n\n\n# Make a back up\n\nmv EUR.QC.bim EUR.QC.bim.bk\nln -s EUR.QC.adj.bim EUR.QC.bim\n\n\n\n\nWe can then generate a new genotype file with the correct genetic encodings\n\nplink \n\\\n\n    --bfile EUR.QC \n\\\n\n    --a1-allele EUR.update.a1 \n\\\n\n    --make-bed \n\\\n\n    --keep EUR.valid.sample \n\\\n\n    --extract EUR.unambig.snp \n\\\n\n    --exclude EUR.mismatch \n\\\n\n    --out EUR.QC.flipped\n\n\n\nUpdate Effect Size\n\n\nWhen odd ratios (OR) instead of BETA are provided, the PRS might have to calculated using a multiplicative model.\nTo simplify the calculation, we usually take the natural logarithm of the OR such that an additive model can be applied. \nWe can obtain the transformed summary statistics with \nR\n:\n\n\n```R tab=\"Without data.table\"\ndat \n- read.table(gzfile(\"Height.QC.gz\"), header=T)\ndat\n\\(OR \n- log(dat\\)\nOR)\nwrite.table(dat, \"Height.QC.Transformed\", quote=F, row.names=F)\n\n``\n`R tab\n=\nWith data.table\n\n\nlibrary\n(\ndata.table\n)\n\ndat \n-\n fread\n(\nHeight.QC.gz\n)\n\nfwrite\n(\ndat\n[,\nOR\n:=\nlog\n(\nOR\n)],\n \nHeight.QC.Transformed\n,\n sep\n=\n\\t\n)\n\n\n\n\n\n\nWarning\n\n\nIt might be tempting to perform the log transofrmation using \nawk\n.\nHowever, due to a lower arithmetic precision of \nawk\n, less accurate results\nmight be obtained. \nTherefore it is best to do the transformation in \nR\n or allow the PRS software to perform the transformation directly. \n\n\n\n\nClumping\n\n\nLinkage disequilibrium introduce a strong correlation structure across the genome, makes identifying the independent\ngenetic effects extremely challenging. \nOne simple method is to perform clumping, which preferentially selects SNPs most\nassociated with the trait under study when removing SNPs in LD. \n\n\nplink \n\\\n\n    --bfile EUR.QC.flipped \n\\\n\n    --clump-p1 \n1\n \n\\\n\n    --clump-r2 \n0\n.1 \n\\\n\n    --clump-kb \n250\n \n\\\n\n    --clump Height.QC.transformed \n\\\n\n    --clump-snp-field SNP \n\\\n\n    --clump-field P \n\\\n\n    --out EUR\n\n\nEach of the new parameters corresponds to the following\n\n\n\n\n\n\n\n\nParamter\n\n\nValue\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nclump-p1\n\n\n1\n\n\nP-value threshold for a SNP to be included as an index SNP. 1 is selected such that all SNPs are include for clumping\n\n\n\n\n\n\nclump-r2\n\n\n0.1\n\n\nSNPs having \n\\(r^2\\)\n higher than 0.1 with the index SNPs will be removed\n\n\n\n\n\n\nclump-kb\n\n\n250\n\n\nSNPs within 250k of the index SNP are considered for clumping\n\n\n\n\n\n\nclump\n\n\nHeight.QC.transformed\n\n\nSummary statistic file containing the p-value information\n\n\n\n\n\n\nclump-snp-field\n\n\nSNP\n\n\nSpecify that the column \nSNP\n contains the SNP IDs\n\n\n\n\n\n\nclump-field\n\n\nP\n\n\nSpecify that the column \nP\n contains the P-value information\n\n\n\n\n\n\n\n\nA more detailed document can be found \nhere\n\n\n\n\nNote\n\n\nThe \n\\(r^2\\)\n values computed by \n--clump\n are based on maximum likelihood haplotype frequency estimates\n\n\n\n\nThis will generate \nEUR.clumped\n, containing the index SNPs after clumping is performed.\nWe can extract the index SNP ID by doing\n\n\nawk \nNR!=1{print $3}\n EUR.clumped \n  EUR.valid.snp\n\n\n\n\n\n\n$3\n because the third column contains the SNP ID\n\n\n\n\n\n\nNote\n\n\nIf your target sample is small (e.g. \n500), you can try using the 1000 Genome samples for the LD calculation.\nMake sure you use the population that best represents your sample.\n\n\n\n\nGenerate PRS\n\n\nplink\n provide a handy function \n--score\n and \n--q-score-range\n for calculating polygenic score.\n\n\nWe will need three files\n\n\n\n\nThe summary statistic file: \nHeight.QC.Transformed\n\n\nA file containing SNP ID and their corresponding p-value (\n$1\n because SNP ID is located at the first column; \n$8\n because P-value is located at the eigth column)\n\nawk \n{print $1,$8}\n Height.QC.Transformed \n SNP.pvalue\n\n\n\nA file containing the P-value thresholds we are testing. Here we will only test a few for illustration purposes\n\necho\n \n0.001 0 0.001\n \n range_list\n\necho\n \n0.05 0 0.05\n \n range_list\n\necho\n \n0.1 0 0.1\n \n range_list\n\necho\n \n0.2 0 0.2\n \n range_list\n\necho\n \n0.3 0 0.3\n \n range_list\n\necho\n \n0.4 0 0.4\n \n range_list\n\necho\n \n0.5 0 0.5\n \n range_list\n\n\nThe format of the \nrange_list\n file should be as follow\n\n\n\n\n\n\n\n\n\n\nName of Threshold\n\n\nLower bound\n\n\nUpper Bound\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nThe boundary are inclusive. For example, for the \n0.05\n threshold, we include all SNPs with P-value from \n\n0\n to \n0.05\n, \nincluding\n any SNPs with P-value equal to \n0.05\n\n\n\n\nWe can then calculate the PRS with the following \nplink\n command:\n\n\nplink \n\\\n\n    --bfile EUR.QC.flipped \n\\\n\n    --extract EUR.valid.snp \n\\\n\n    --score Height.QC.Transformed \n1\n \n4\n \n11\n header \n\\\n\n    --q-score-range range_list SNP.pvalue \n\\\n\n    --out EUR\n\n\nMeaning of the new parameters are as follow\n\n\n\n\n\n\n\n\nParamter\n\n\nValue\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nscore\n\n\nHeight.QC.Transformed 1 4 11 header\n\n\nWe read from the \nHeight.QC.Transformed\n file, assuming the \n1\nst column to be the SNP ID; \n4\nth column to be the effective allele information; \n11\nth column to be the effect size estimate; and the file contains a \nheader\n\n\n\n\n\n\nq-score-range\n\n\nrange_test SNP.pvalue\n\n\nWe want to calculate PRS based on the thresholds defined in \nrange_test\n, where the threshold values (p-values) were stored in \nSNP.pvalue\n\n\n\n\n\n\n\n\nThe above command and range_list will generate 7 files:\n\n\n\n\nEUR.0.5.profile\n\n\nEUR.0.4.profile\n\n\nEUR.0.3.profile\n\n\nEUR.0.2.profile\n\n\nEUR.0.1.profile\n\n\nEUR.0.05.profile\n\n\nEUR.0.001.profile\n\n\n\n\n\n\nNote\n\n\nThe default formular for PRS calculation in PLINK is:\n(Assuming the effect size of SNP \n\\(i\\)\n is \n\\(S_i\\)\n;  the number of effective allele observed in sample \n\\(j\\)\n is \n\\(G_{ij}\\)\n; the ploidy of the sample is \n\\(P\\)\n (It should be 2 for human); the number of samples included in the PRS be \n\\(N\\)\n; and the number of non-missing SNPs observed in sample \n\\(j\\)\n be \n\\(M_j\\)\n)\n$$\nPRS_j =\\frac{ \\sum_i^NS_i*G_{ij}}{P*M_j}\n$$\n\n\nIf sample has a missing genotype for SNP \n\\(i\\)\n, the population minor allele frequency times ploidy (\n\\(MAF_i*P\\)\n) is used inplace of \n\\(G_{ij}\\)\n\n\n\n\nAccounting for Population Stratification\n\n\nPopulation structure is the principal source of confounding in GWAS and are usually accounted for by incorporating the principal components (PCs) as a covariate. \nSimilarly, we can incorporate PCs in our PRS analysis to account for population stratification.\n\n\nAgain, we can calculate the PCs using \nplink\n \n\n# First, we need to perform prunning\n\nplink \n\\\n\n    --bfile EUR.QC.flipped \n\\\n\n    --extract EUR.valid.snp \n\\\n\n    --indep-pairwise \n200\n \n50\n \n0\n.25 \n\\\n\n    --out EUR\n\n# Then we calculate the first 6 PCs\n\nplink \n\\\n\n    --bfile EUR.QC.flipped \n\\\n\n    --extract EUR.prune.in \n\\\n\n    --pca \n6\n \n\\\n\n    --out EUR\n\n\n\n\n\nNote\n\n\nOne way to select the appropriate number of PCs is to perform GWAS on the trait of interest with different number of PCs.\n\nLDSC\n analysis can then be performed on each of the resulted GWAS summary statistics. \nBy observing the estimated intercept, one can select the number of PCs that provide an intercept estimate closer to 1, which might\nsuggest a smaller influence of population stratification.\n\n\n\n\nThe eigen-vector (PCs) are stored in \nEUR.eigenvec\n and can be used as a covariate in the regression model to account for population stratification.\n\n\n\n\nImportant\n\n\nIf the base and target samples are collected from different population (e.g. Caucasian vs African ), the results from PRS analysis will be biased (see \nMartin et al\n).\n\n\n\n\nFinding the \"Best\" P-value threshold\n\n\nThe \"best\" p-value threshold for PRS construction are usually not known. \nTo identify the \"best\" PRS, we can perform a regression between the calculated PRS and the \nsample phenotype and select the PRS that explains most of the phenotypic variation. \nThis can be achieved using \nR\n.\n\n\n```R tab=\"detail\"\np.threshold \n- c(0.001,0.05,0.1,0.2,0.3,0.4,0.5)\n\n\nRead in the phenotype file\n\n\nphenotype \n- read.table(\"EUR.height\", header=T)\n\n\nRead in the PCs\n\n\npcs \n- read.table(\"EUR.eigenvec\", header=F)\n\n\nThe default output from plink does not include a header\n\n\nTo make things simple, we will add the appropriate headers\n\n\n(1:6 because there are 6 PCs)\n\n\ncolnames(pcs) \n- c(\"FID\", \"IID\", paste0(\"PC\",1:6)) \n\n\nRead in the covariates (here, it is sex)\n\n\ncovariate \n- read.table(\"EUR.covariate\", header=T)\n\n\nNow merge the files\n\n\npheno \n- merge(merge(phenotype, covariate, by=c(\"FID\", \"IID\")), pcs, by=c(\"FID\",\"IID\"))\n\n\nWe can then calculate the null model (model with PRS) using a linear regression\n\n\n(as height is quantitative)\n\n\nnull.model \n- lm(Height~., data=pheno[,!colnames(pheno)%in%c(\"FID\",\"IID\")])\n\n\nAnd the R2 of the null model is\n\n\nnull.r2 \n- summary(null.model)\n\\(r.squared\nprs.result \n- NULL\nfor(i in p.threshold){\n    # Go through each p-value threshold\n    prs \n- read.table(paste0(\"EUR.\",i,\".profile\"), header=T)\n    # Merge the prs with the phenotype matrix\n    # We only want the FID, IID and PRS from the PRS file, therefore we only select the \n    # relevant columns\n    pheno.prs \n- merge(pheno, prs[,c(\"FID\",\"IID\", \"SCORE\")], by=c(\"FID\", \"IID\"))\n    # Now perform a linear regression on Height with PRS and the covariates\n    # ignoring the FID and IID from our model\n    model \n- lm(Height~., data=pheno.prs[,!colnames(pheno.prs)%in%c(\"FID\",\"IID\")])\n    # model R2 is obtained as \n    model.r2 \n- summary(model)\\)\nr.squared\n    # R2 of PRS is simply calculated as the model R2 minus the null R2\n    prs.r2 \n- model.r2-null.r2\n    # We can also obtain the coeffcient and p-value of association of PRS as follow\n    prs.coef \n- summary(model)$coeff[\"SCORE\",]\n    prs.beta \n- as.numeric(prs.coef[1])\n    prs.se \n- as.numeric(prs.coef[2])\n    prs.p \n- as.numeric(prs.coef[4])\n    # We can then store the results\n    prs.result \n- rbind(prs.result, data.frame(Threshold=i, R2=prs.r2, P=prs.p, BETA=prs.beta,SE=prs.se))\n}\n\n\nBest result is:\n\n\nprs.result[which.max(prs.result$R2),]\n\n```\nR\n \ntab\n=\nquick\n\n\np\n.\nthreshold\n \n-\n \nc\n(\n0.001\n,\n0.05\n,\n0.1\n,\n0.2\n,\n0.3\n,\n0.4\n,\n0.5\n)\n\n\nphenotype\n \n-\n \nread\n.\ntable\n(\nEUR.height\n,\n \nheader\n=\nT\n)\n\n\npcs\n \n-\n \nread\n.\ntable\n(\nEUR.eigenvec\n,\n \nheader\n=\nF\n)\n\n\ncolnames\n(\npcs\n)\n \n-\n \nc\n(\nFID\n,\n \nIID\n,\n \npaste0\n(\nPC\n,\n1\n:\n6\n))\n \n\ncovariate\n \n-\n \nread\n.\ntable\n(\nEUR.covariate\n,\n \nheader\n=\nT\n)\n\n\npheno\n \n-\n \nmerge\n(\nmerge\n(\nphenotype\n,\n \ncovariate\n,\n \nby\n=\nc\n(\nFID\n,\n \nIID\n)),\n \npcs\n,\n \nby\n=\nc\n(\nFID\n,\nIID\n))\n\n\nnull\n.\nr2\n \n-\n \nsummary\n(\nlm\n(\nHeight\n~\n.,\n \ndata\n=\npheno\n[,\n!\ncolnames\n(\npheno\n)\n%\nin\n%\nc\n(\nFID\n,\nIID\n)]))\n$\nr\n.\nsquared\n\n\nprs\n.\nresult\n \n-\n \nNULL\n\n\nfor\n(\ni\n \nin\n \np\n.\nthreshold\n){\n\n    \npheno\n.\nprs\n \n-\n \nmerge\n(\npheno\n,\n \n                        \nread\n.\ntable\n(\npaste0\n(\nEUR.\n,\ni\n,\n.profile\n),\n \nheader\n=\nT\n)[,\nc\n(\nFID\n,\nIID\n,\n \nSCORE\n)],\n\n                        \nby\n=\nc\n(\nFID\n,\n \nIID\n))\n\n    \nmodel\n \n-\n \nsummary\n(\nlm\n(\nHeight\n~\n.,\n \ndata\n=\npheno\n.\nprs\n[,\n!\ncolnames\n(\npheno\n.\nprs\n)\n%\nin\n%\nc\n(\nFID\n,\nIID\n)]))\n\n    \nmodel\n.\nr2\n \n-\n \nmodel\n$\nr\n.\nsquared\n\n    \nprs\n.\nr2\n \n-\n \nmodel\n.\nr2\n-\nnull\n.\nr2\n\n    \nprs\n.\ncoef\n \n-\n \nmodel\n$\ncoeff\n[\nSCORE\n,]\n\n    \nprs\n.\nresult\n \n-\n \nrbind\n(\nprs\n.\nresult\n,\n \n        \ndata\n.\nframe\n(\nThreshold\n=\ni\n,\n \nR2\n=\nprs\n.\nr2\n,\n \n                    \nP\n=\nas\n.\nnumeric\n(\nprs\n.\ncoef\n[\n4\n]),\n \n                    \nBETA\n=\nas\n.\nnumeric\n(\nprs\n.\ncoef\n[\n1\n]),\n\n                    \nSE\n=\nas\n.\nnumeric\n(\nprs\n.\ncoef\n[\n2\n])))\n\n\n}\n\n\nprint\n(\nprs\n.\nresult\n[\nwhich\n.\nmax\n(\nprs\n.\nresult\n$\nR2\n),])\n\n\n\n\nWhich p-value threshold generate the \"best\" PRS?\n0.05\nHow much phenotypic variation does the \"best\" PRS explains?\n0.03921047", 
            "title": "Background"
        }, 
        {
            "location": "/plink/#background", 
            "text": "In this section, we will try to calculate polygenic risk score using  plink  to illustrate some common procedure\nperformed by PRS software.", 
            "title": "Background"
        }, 
        {
            "location": "/plink/#required-data", 
            "text": "In previous sections, we have generated the following files     File Name  Description      Height.QC.gz  The post-QCed summary statistic    EUR.QC.bed  The genotype file after performing some basic filtering    EUR.QC.bim  This file contains the SNPs that passed the basic filtering    EUR.QC.fam  This file contains the samples that passed the basic filtering    EUR.valid.sample  This file contains the samples that passed all the QC    EUR.height  This file contains the phenotype of the samples    EUR.covariate  This file contains the covariates of the samples", 
            "title": "Required Data"
        }, 
        {
            "location": "/plink/#remove-ambiguous-snps", 
            "text": "If the base and target data were generated using different genotyping chips and the chromosome strand (+/-) for either is unknown, then it is not possible to match ambiguous SNPs (i.e. those with complementary alleles, either C/G or A/T) across the data sets, because it will be unknown whether the base and target data are referring to the same allele or not.   Ambiguous SNPs can be obtained by examining the bim file: awk  !( ($5== A    $6== T ) || \\          ($5== T    $6== A ) || \\          ($5== G    $6== C ) || \\          ($5== C    $6== G )) {print}   \\ \n        EUR.QC.bim   EUR.unambig.snp   How many ambiguous SNPs were there? There are  330,818  ambiguous SNPs", 
            "title": "Remove Ambiguous SNPs"
        }, 
        {
            "location": "/plink/#strand-flipping", 
            "text": "In addition, when there are non-ambiguous mismatch in allele \ncoding between the data sets, such as A/C in the base\nand G/T in the target data, then this can be resolved by \n\u2018flipping\u2019 the alleles in the target data to their complementary alleles. \nThis has to be done with mulitpe steps   Get the correct A1 alleles for the bim file   ```R tab=\"Without data.table\"\nbim  - read.table(\"EUR.QC.bim\", header = F, stringsAsFactors = F)\ncolnames(bim)  - c(\"CHR\", \"SNP\", \"CM\", \"BP\", \"B.A1\", \"B.A2\")\nheight  -\n    read.table(gzfile(\"Height.QC.gz\"),\n               header = T,\n               stringsAsFactors = F)", 
            "title": "Strand Flipping"
        }, 
        {
            "location": "/plink/#change-all-alleles-to-upper-case-for-easy-comparison", 
            "text": "height \\(A1  - toupper(height\\) A1)\nheight \\(A2  - toupper(height\\) A2)\nbim \\(B.A1  - toupper(bim\\) B.A1)\nbim \\(B.A2  - toupper(bim\\) B.A2)\ninfo  - merge(bim, height, by = c(\"SNP\", \"CHR\", \"BP\"))", 
            "title": "Change all alleles to upper case for easy comparison"
        }, 
        {
            "location": "/plink/#function-for-finding-the-complementary-allele", 
            "text": "complement  - function(x) {\n    switch (\n        x,\n        \"A\" = \"T\",\n        \"C\" = \"G\",\n        \"T\" = \"A\",\n        \"G\" = \"C\",\n        return(NA)\n    )\n}", 
            "title": "Function for finding the complementary allele"
        }, 
        {
            "location": "/plink/#get-snps-that-has-the-same-alleles-across-base-and-target", 
            "text": "info.match  - subset(info, A1 == B.A1   A2 == B.A2)", 
            "title": "Get SNPs that has the same alleles across base and target"
        }, 
        {
            "location": "/plink/#identify-snps-that-are-complementary-between-base-and-target", 
            "text": "info \\(C.A1  - sapply(info\\) B.A1, complement)\ninfo \\(C.A2  - sapply(info\\) B.A2, complement)\ninfo.complement  - subset(info, A1 == C.A1   A2 == C.A2)", 
            "title": "Identify SNPs that are complementary between base and target"
        }, 
        {
            "location": "/plink/#update-these-allele-coding-in-the-bim-file", 
            "text": "bim[bim \\(SNP %in% info.complement\\) SNP,] \\(B.A1  -\n    sapply(bim[bim\\) SNP %in% info.complement \\(SNP,]\\) B.A1, complement)\nbim[bim \\(SNP %in% info.complement\\) SNP,] \\(B.A2  -\n    sapply(bim[bim\\) SNP %in% info.complement \\(SNP,]\\) B.A2, complement)", 
            "title": "Update these allele coding in the bim file"
        }, 
        {
            "location": "/plink/#identify-snps-that-need-flipping", 
            "text": "info.flip  - subset(info, A1 == B.A2   A2 == B.A1)", 
            "title": "identify SNPs that need flipping"
        }, 
        {
            "location": "/plink/#identify-snps-that-need-flipping-complement", 
            "text": "info.cflip  - subset(info, A1 == C.A2   A2 == C.A1)", 
            "title": "identify SNPs that need flipping &amp; complement"
        }, 
        {
            "location": "/plink/#update-these-allele-coding-in-the-bim-file_1", 
            "text": "com.snps  - bim \\(SNP %in% info.cflip\\) SNP\nbim[com.snps,] \\(B.A1  - sapply(bim[com.snps,]\\) B.A1, complement)\nbim[com.snps,] \\(B.A2  - sapply(bim[com.snps,]\\) B.A2, complement)", 
            "title": "Update these allele coding in the bim file"
        }, 
        {
            "location": "/plink/#get-list-of-snps-that-need-to-change-the-a1-encoding", 
            "text": "flip  - rbind(info.flip, info.cflip)\nflip.snp  - data.frame(SNP = flip \\(SNP, A1 = flip\\) A1)\nwrite.table(flip.snp,\n            \"EUR.update.a1\",\n            quote = F,\n            row.names = F)\nwrite.table(\n    bim,\n    \"EUR.QC.adj.bim\",\n    quote = F,\n    row.names = F,\n    col.names = F\n)", 
            "title": "Get list of SNPs that need to change the A1 encoding"
        }, 
        {
            "location": "/plink/#and-we-want-to-remove-any-snps-that-do-not-match-with-the-base-data", 
            "text": "mismatch  -\n    bim \\(SNP[!(bim\\) SNP %in% info.match \\(SNP |\n                  bim\\) SNP %in% info.complement \\(SNP | \n                  bim\\) SNP %in% flip$SNP)]\nwrite.table(\n    mismatch,\n    \"EUR.mismatch\",\n    quote = F,\n    row.names = F,\n    col.names = F\n) `` `R tab = With data.table  library ( data.table ) \nbim  -  fread ( EUR.QC.bim ) \nbim.col  -   c ( CHR ,   SNP ,   CM ,   BP ,   B.A1 ,   B.A2 ) \nsetnames ( bim ,   colnames ( bim ),  bim.col ) \nheight  -  fread ( Height.QC.gz )  # Change all alleles to upper case for easy comparison \nheight [, c ( A1 , A2 ) := list ( toupper ( A1 ),   toupper ( A2 ))] \nbim [, c ( B.A1 , B.A2 ) := list ( toupper ( B.A1 ),   toupper ( B.A2 ))] \ninfo  -   merge ( bim ,  height ,  by = c ( SNP ,   CHR ,   BP ))  # Function for calculating the complementary allele \ncomplement  -   function ( x ){ \n     switch   ( x , \n         A   =   T , \n         C   =   G , \n         T   =   A , \n         G   =   C , \n         return ( NA ) \n     )  }  # Identify SNPs that are complementary between base and target \ncom.snps  -  info [ sapply ( B.A1 ,  complement )   ==  A1  \n                      sapply ( B.A2 ,  complement )   ==  A2 ,  SNP ]  # Now update the bim file \nbim [ SNP  %in%  com.snps ,   c ( B.A1 ,   B.A2 )   := \n         list ( sapply ( B.A1 ,  complement ), \n              sapply ( B.A2 ,  complement ))]  # identify SNPs that need flipping   complement \ncom.flip  -  info [ sapply ( B.A1 ,  complement )   ==  A2  \n                      sapply ( B.A2 ,  complement )   ==  A1 ,  SNP ]  # Now update the bim file \nbim [ SNP  %in%  com.flip ,   c ( B.A1 ,   B.A2 )   := \n         list ( sapply ( B.A1 ,  complement ), \n              sapply ( B.A2 ,  complement ))]  # Obtain list of SNPs that require flipping \nflip  -  info [ B.A1 == A2   B.A2 == A1 ]  # Now generate file for PLINK  \nfwrite ( flip [, c ( SNP ,   A1 )],   EUR.update.a1 ,  sep = \\t )  # Write the updated bim file \nfwrite ( bim ,   EUR.QC.adj.bim ,  col.names = F ,  sep = \\t )  # We can then remove all mismatch SNPs \nmatched  -  info [( A1  ==  B.A1   A2  ==  B.A2 )   | \n                     ( A1  ==  B.A2   A2  ==  B.A1 )   | \n                     ( A1  ==   sapply ( B.A1 ,  complement )   \n                         A2  ==   sapply ( B.A2 ,  complement ))   | \n                     ( A1  ==   sapply ( B.A2 ,  complement )   \n                         A2  ==   sapply ( B.A1 ,  complement ))] \nmismatch  -  bim [ ! SNP %in% matched $ SNP ,  SNP ] \nwrite.table ( mismatch ,   EUR.mismatch ,  quote = F ,  row.names = F ,  col.names = F )   The above script will generate three files:  EUR.QC.adj.bim ,  EUR.update.a1  and  EUR.mismatch . We want to replace EUR.QC.bim  with  EUR.QC.adj.bim :  # Make a back up \nmv EUR.QC.bim EUR.QC.bim.bk\nln -s EUR.QC.adj.bim EUR.QC.bim  We can then generate a new genotype file with the correct genetic encodings plink  \\ \n    --bfile EUR.QC  \\ \n    --a1-allele EUR.update.a1  \\ \n    --make-bed  \\ \n    --keep EUR.valid.sample  \\ \n    --extract EUR.unambig.snp  \\ \n    --exclude EUR.mismatch  \\ \n    --out EUR.QC.flipped", 
            "title": "And we want to remove any SNPs that do not match with the base data"
        }, 
        {
            "location": "/plink/#update-effect-size", 
            "text": "When odd ratios (OR) instead of BETA are provided, the PRS might have to calculated using a multiplicative model.\nTo simplify the calculation, we usually take the natural logarithm of the OR such that an additive model can be applied. \nWe can obtain the transformed summary statistics with  R :  ```R tab=\"Without data.table\"\ndat  - read.table(gzfile(\"Height.QC.gz\"), header=T)\ndat \\(OR  - log(dat\\) OR)\nwrite.table(dat, \"Height.QC.Transformed\", quote=F, row.names=F) `` `R tab = With data.table  library ( data.table ) \ndat  -  fread ( Height.QC.gz ) \nfwrite ( dat [, OR := log ( OR )],   Height.QC.Transformed ,  sep = \\t )    Warning  It might be tempting to perform the log transofrmation using  awk .\nHowever, due to a lower arithmetic precision of  awk , less accurate results\nmight be obtained. \nTherefore it is best to do the transformation in  R  or allow the PRS software to perform the transformation directly.", 
            "title": "Update Effect Size"
        }, 
        {
            "location": "/plink/#clumping", 
            "text": "Linkage disequilibrium introduce a strong correlation structure across the genome, makes identifying the independent\ngenetic effects extremely challenging. \nOne simple method is to perform clumping, which preferentially selects SNPs most\nassociated with the trait under study when removing SNPs in LD.   plink  \\ \n    --bfile EUR.QC.flipped  \\ \n    --clump-p1  1   \\ \n    --clump-r2  0 .1  \\ \n    --clump-kb  250   \\ \n    --clump Height.QC.transformed  \\ \n    --clump-snp-field SNP  \\ \n    --clump-field P  \\ \n    --out EUR \nEach of the new parameters corresponds to the following     Paramter  Value  Description      clump-p1  1  P-value threshold for a SNP to be included as an index SNP. 1 is selected such that all SNPs are include for clumping    clump-r2  0.1  SNPs having  \\(r^2\\)  higher than 0.1 with the index SNPs will be removed    clump-kb  250  SNPs within 250k of the index SNP are considered for clumping    clump  Height.QC.transformed  Summary statistic file containing the p-value information    clump-snp-field  SNP  Specify that the column  SNP  contains the SNP IDs    clump-field  P  Specify that the column  P  contains the P-value information     A more detailed document can be found  here   Note  The  \\(r^2\\)  values computed by  --clump  are based on maximum likelihood haplotype frequency estimates   This will generate  EUR.clumped , containing the index SNPs after clumping is performed.\nWe can extract the index SNP ID by doing  awk  NR!=1{print $3}  EUR.clumped    EUR.valid.snp   $3  because the third column contains the SNP ID    Note  If your target sample is small (e.g.  500), you can try using the 1000 Genome samples for the LD calculation.\nMake sure you use the population that best represents your sample.", 
            "title": "Clumping"
        }, 
        {
            "location": "/plink/#generate-prs", 
            "text": "plink  provide a handy function  --score  and  --q-score-range  for calculating polygenic score.  We will need three files   The summary statistic file:  Height.QC.Transformed  A file containing SNP ID and their corresponding p-value ( $1  because SNP ID is located at the first column;  $8  because P-value is located at the eigth column) awk  {print $1,$8}  Height.QC.Transformed   SNP.pvalue  A file containing the P-value thresholds we are testing. Here we will only test a few for illustration purposes echo   0.001 0 0.001    range_list echo   0.05 0 0.05    range_list echo   0.1 0 0.1    range_list echo   0.2 0 0.2    range_list echo   0.3 0 0.3    range_list echo   0.4 0 0.4    range_list echo   0.5 0 0.5    range_list \nThe format of the  range_list  file should be as follow      Name of Threshold  Lower bound  Upper Bound             Note  The boundary are inclusive. For example, for the  0.05  threshold, we include all SNPs with P-value from  0  to  0.05 ,  including  any SNPs with P-value equal to  0.05   We can then calculate the PRS with the following  plink  command:  plink  \\ \n    --bfile EUR.QC.flipped  \\ \n    --extract EUR.valid.snp  \\ \n    --score Height.QC.Transformed  1   4   11  header  \\ \n    --q-score-range range_list SNP.pvalue  \\ \n    --out EUR \nMeaning of the new parameters are as follow     Paramter  Value  Description      score  Height.QC.Transformed 1 4 11 header  We read from the  Height.QC.Transformed  file, assuming the  1 st column to be the SNP ID;  4 th column to be the effective allele information;  11 th column to be the effect size estimate; and the file contains a  header    q-score-range  range_test SNP.pvalue  We want to calculate PRS based on the thresholds defined in  range_test , where the threshold values (p-values) were stored in  SNP.pvalue     The above command and range_list will generate 7 files:   EUR.0.5.profile  EUR.0.4.profile  EUR.0.3.profile  EUR.0.2.profile  EUR.0.1.profile  EUR.0.05.profile  EUR.0.001.profile    Note  The default formular for PRS calculation in PLINK is:\n(Assuming the effect size of SNP  \\(i\\)  is  \\(S_i\\) ;  the number of effective allele observed in sample  \\(j\\)  is  \\(G_{ij}\\) ; the ploidy of the sample is  \\(P\\)  (It should be 2 for human); the number of samples included in the PRS be  \\(N\\) ; and the number of non-missing SNPs observed in sample  \\(j\\)  be  \\(M_j\\) )\n$$\nPRS_j =\\frac{ \\sum_i^NS_i*G_{ij}}{P*M_j}\n$$  If sample has a missing genotype for SNP  \\(i\\) , the population minor allele frequency times ploidy ( \\(MAF_i*P\\) ) is used inplace of  \\(G_{ij}\\)", 
            "title": "Generate PRS"
        }, 
        {
            "location": "/plink/#accounting-for-population-stratification", 
            "text": "Population structure is the principal source of confounding in GWAS and are usually accounted for by incorporating the principal components (PCs) as a covariate. \nSimilarly, we can incorporate PCs in our PRS analysis to account for population stratification.  Again, we can calculate the PCs using  plink   # First, we need to perform prunning \nplink  \\ \n    --bfile EUR.QC.flipped  \\ \n    --extract EUR.valid.snp  \\ \n    --indep-pairwise  200   50   0 .25  \\ \n    --out EUR # Then we calculate the first 6 PCs \nplink  \\ \n    --bfile EUR.QC.flipped  \\ \n    --extract EUR.prune.in  \\ \n    --pca  6   \\ \n    --out EUR   Note  One way to select the appropriate number of PCs is to perform GWAS on the trait of interest with different number of PCs. LDSC  analysis can then be performed on each of the resulted GWAS summary statistics. \nBy observing the estimated intercept, one can select the number of PCs that provide an intercept estimate closer to 1, which might\nsuggest a smaller influence of population stratification.   The eigen-vector (PCs) are stored in  EUR.eigenvec  and can be used as a covariate in the regression model to account for population stratification.   Important  If the base and target samples are collected from different population (e.g. Caucasian vs African ), the results from PRS analysis will be biased (see  Martin et al ).", 
            "title": "Accounting for Population Stratification"
        }, 
        {
            "location": "/plink/#finding-the-best-p-value-threshold", 
            "text": "The \"best\" p-value threshold for PRS construction are usually not known. \nTo identify the \"best\" PRS, we can perform a regression between the calculated PRS and the \nsample phenotype and select the PRS that explains most of the phenotypic variation. \nThis can be achieved using  R .  ```R tab=\"detail\"\np.threshold  - c(0.001,0.05,0.1,0.2,0.3,0.4,0.5)", 
            "title": "Finding the \"Best\" P-value threshold"
        }, 
        {
            "location": "/plink/#read-in-the-phenotype-file", 
            "text": "phenotype  - read.table(\"EUR.height\", header=T)", 
            "title": "Read in the phenotype file"
        }, 
        {
            "location": "/plink/#read-in-the-pcs", 
            "text": "pcs  - read.table(\"EUR.eigenvec\", header=F)", 
            "title": "Read in the PCs"
        }, 
        {
            "location": "/plink/#the-default-output-from-plink-does-not-include-a-header", 
            "text": "", 
            "title": "The default output from plink does not include a header"
        }, 
        {
            "location": "/plink/#to-make-things-simple-we-will-add-the-appropriate-headers", 
            "text": "", 
            "title": "To make things simple, we will add the appropriate headers"
        }, 
        {
            "location": "/plink/#16-because-there-are-6-pcs", 
            "text": "colnames(pcs)  - c(\"FID\", \"IID\", paste0(\"PC\",1:6))", 
            "title": "(1:6 because there are 6 PCs)"
        }, 
        {
            "location": "/plink/#read-in-the-covariates-here-it-is-sex", 
            "text": "covariate  - read.table(\"EUR.covariate\", header=T)", 
            "title": "Read in the covariates (here, it is sex)"
        }, 
        {
            "location": "/plink/#now-merge-the-files", 
            "text": "pheno  - merge(merge(phenotype, covariate, by=c(\"FID\", \"IID\")), pcs, by=c(\"FID\",\"IID\"))", 
            "title": "Now merge the files"
        }, 
        {
            "location": "/plink/#we-can-then-calculate-the-null-model-model-with-prs-using-a-linear-regression", 
            "text": "", 
            "title": "We can then calculate the null model (model with PRS) using a linear regression"
        }, 
        {
            "location": "/plink/#as-height-is-quantitative", 
            "text": "null.model  - lm(Height~., data=pheno[,!colnames(pheno)%in%c(\"FID\",\"IID\")])", 
            "title": "(as height is quantitative)"
        }, 
        {
            "location": "/plink/#and-the-r2-of-the-null-model-is", 
            "text": "null.r2  - summary(null.model) \\(r.squared\nprs.result  - NULL\nfor(i in p.threshold){\n    # Go through each p-value threshold\n    prs  - read.table(paste0(\"EUR.\",i,\".profile\"), header=T)\n    # Merge the prs with the phenotype matrix\n    # We only want the FID, IID and PRS from the PRS file, therefore we only select the \n    # relevant columns\n    pheno.prs  - merge(pheno, prs[,c(\"FID\",\"IID\", \"SCORE\")], by=c(\"FID\", \"IID\"))\n    # Now perform a linear regression on Height with PRS and the covariates\n    # ignoring the FID and IID from our model\n    model  - lm(Height~., data=pheno.prs[,!colnames(pheno.prs)%in%c(\"FID\",\"IID\")])\n    # model R2 is obtained as \n    model.r2  - summary(model)\\) r.squared\n    # R2 of PRS is simply calculated as the model R2 minus the null R2\n    prs.r2  - model.r2-null.r2\n    # We can also obtain the coeffcient and p-value of association of PRS as follow\n    prs.coef  - summary(model)$coeff[\"SCORE\",]\n    prs.beta  - as.numeric(prs.coef[1])\n    prs.se  - as.numeric(prs.coef[2])\n    prs.p  - as.numeric(prs.coef[4])\n    # We can then store the results\n    prs.result  - rbind(prs.result, data.frame(Threshold=i, R2=prs.r2, P=prs.p, BETA=prs.beta,SE=prs.se))\n}", 
            "title": "And the R2 of the null model is"
        }, 
        {
            "location": "/plink/#best-result-is", 
            "text": "prs.result[which.max(prs.result$R2),] ``` R   tab = quick  p . threshold   -   c ( 0.001 , 0.05 , 0.1 , 0.2 , 0.3 , 0.4 , 0.5 )  phenotype   -   read . table ( EUR.height ,   header = T )  pcs   -   read . table ( EUR.eigenvec ,   header = F )  colnames ( pcs )   -   c ( FID ,   IID ,   paste0 ( PC , 1 : 6 ))   covariate   -   read . table ( EUR.covariate ,   header = T )  pheno   -   merge ( merge ( phenotype ,   covariate ,   by = c ( FID ,   IID )),   pcs ,   by = c ( FID , IID ))  null . r2   -   summary ( lm ( Height ~ .,   data = pheno [, ! colnames ( pheno ) % in % c ( FID , IID )])) $ r . squared  prs . result   -   NULL  for ( i   in   p . threshold ){ \n     pheno . prs   -   merge ( pheno ,  \n                         read . table ( paste0 ( EUR. , i , .profile ),   header = T )[, c ( FID , IID ,   SCORE )], \n                         by = c ( FID ,   IID )) \n     model   -   summary ( lm ( Height ~ .,   data = pheno . prs [, ! colnames ( pheno . prs ) % in % c ( FID , IID )])) \n     model . r2   -   model $ r . squared \n     prs . r2   -   model . r2 - null . r2 \n     prs . coef   -   model $ coeff [ SCORE ,] \n     prs . result   -   rbind ( prs . result ,  \n         data . frame ( Threshold = i ,   R2 = prs . r2 ,  \n                     P = as . numeric ( prs . coef [ 4 ]),  \n                     BETA = as . numeric ( prs . coef [ 1 ]), \n                     SE = as . numeric ( prs . coef [ 2 ])))  }  print ( prs . result [ which . max ( prs . result $ R2 ),])   Which p-value threshold generate the \"best\" PRS? 0.05 How much phenotypic variation does the \"best\" PRS explains? 0.03921047", 
            "title": "Best result is:"
        }, 
        {
            "location": "/plink_visual/", 
            "text": "Plotting the Results\n\n\nThe P-value threshold results can be visualized using \nR\n\n\n\n\nNote\n\n\nWe will be using \nprs.result\n generated in \nprevious section\n\n\n\n\n```R tab=\"Without ggplot2\"\n\n\nWe strongly recommend the use of ggplot2. Only follow this code if you\n\n\nare desperate.\n\n\nSpecify that we want to generate plot in EUR.height.bar.png\n\n\npng(\"EUR.height.bar.png\",\n      height=10, width=10, res=300, unit=\"in\")\n\n\nFirst, obtain the colorings based on the p-value\n\n\ncol \n- suppressWarnings(colorRampPalette(c(\"dodgerblue\", \"firebrick\")))\n\n\nWe want the color gradient to match the ranking of p-values\n\n\nprs.result \n- prs.result[order(-log10(prs.result\n\\(P)),]\nprs.result\\)\ncolor \n-  col(nrow(prs.result))\nprs.result \n- prs.result[order(prs.result$Threshold),]\n\n\ngenerate a pretty format for p-value output\n\n\nprs.result\n\\(print.p \n- round(prs.result\\)\nP, digits = 3)\nprs.result\n\\(print.p[!is.na(prs.result\\)\nprint.p) \n prs.result\n\\(print.p == 0 ] \n-\n    format(prs.result\\)\nP[!is.na(prs.result\n\\(print.p) \n prs.result\\)\nprint.p == 0 ], digits = 2)\nprs.result\n\\(print.p \n- sub(\"e\", \"*x*10^\", prs.result\\)\nprint.p)\n\n\nGenerate the axis labels\n\n\nxlab \n- expression(italic(P) - value ~ threshold ~ (italic(P)[T]))\nylab \n- expression(paste(\"PRS model fit:  \", R ^ 2))\n\n\nSetup the drawing area\n\n\nlayout(t(1:2), widths=c(8.8,1.2))\npar( cex.lab=1.5, cex.axis=1.25, font.lab=2, \n    oma=c(0,0.5,0,0),\n    mar=c(4,6,0.5,0.5))\n\n\nPlotting the bars\n\n\nb\n- barplot(height=prs.result\n\\(R2, \n            col=prs.result\\)\ncolor, \n            border=NA, \n            ylim=c(0, max(prs.result$R2)*1.25), \n            axes = F, ann=F)\n\n\nPlot the axis labels and axis ticks\n\n\nodd \n- seq(0,nrow(prs.result)+1,2)\neven \n- seq(1,nrow(prs.result),2)\naxis(side=1, at=b[odd], labels=prs.result\n\\(Threshold[odd], lwd=2)\naxis(side=1, at=b[even], labels=prs.result\\)\nThreshold[even],lwd=2)\naxis(side=1, at=c(0,b[1],2*b[length(b)]-b[length(b)-1]), labels=c(\"\",\"\",\"\"), lwd=2, lwd.tick=0)\n\n\nWrite the p-value on top of each bar\n\n\ntext( parse(text=paste(\n    prs.result\n\\(print.p)), \n    x = b+0.1, \n    y =  prs.result\\)\nR2+ (max(prs.result\n\\(R2)*1.05-max(prs.result\\)\nR2)), \n    srt = 45)\n\n\nNow plot the axis lines\n\n\nbox(bty='L', lwd=2)\naxis(2,las=2, lwd=2)\n\n\nPlot the axis titles\n\n\ntitle(ylab=ylab, line=4, cex.lab=1.5, font=2 )\ntitle(xlab=xlab, line=2.5, cex.lab=1.5, font=2 )\n\n\nGenerate plot area for the legend\n\n\npar(cex.lab=1.5, cex.axis=1.25, font.lab=2, \n      mar=c(20,0,20,4))\nprs.result \n- prs.result[order(-log10(prs.result\n\\(P)),]\nimage(1, -log10(prs.result\\)\nP), t(seq_along(-log10(prs.result\n\\(P))), col=prs.result\\)\ncolor, axes=F,ann=F)\naxis(4,las=2,xaxs='r',yaxs='r', tck=0.2, col=\"white\")\n\n\nplot legend title\n\n\ntitle(bquote(atop(-log[10] ~ model, italic(P) - value), ), \n          line=2, cex=1.5, font=2, adj=0)\n\n\nwrite the plot to file\n\n\ndev.off()\n\n``\n`R tab\n=\nggplot2\n\n\n# ggplot2 is a handy package for plotting\n\n\nlibrary\n(\nggplot2\n)\n\n\n# generate a pretty format for p-value output\n\nprs.result\n$\nprint.p \n-\n \nround\n(\nprs.result\n$\nP\n,\n digits \n=\n \n3\n)\n\nprs.result\n$\nprint.p\n[\n!\nis.na\n(\nprs.result\n$\nprint.p\n)\n \n\n                       prs.result\n$\nprint.p \n==\n \n0\n]\n \n-\n\n    \nformat\n(\nprs.result\n$\nP\n[\n!\nis.na\n(\nprs.result\n$\nprint.p\n)\n \n\n                            prs.result\n$\nprint.p \n==\n \n0\n],\n digits \n=\n \n2\n)\n\nprs.result\n$\nprint.p \n-\n \nsub\n(\ne\n,\n \n*x*10^\n,\n prs.result\n$\nprint.p\n)\n\n\n# Initialize ggplot, requiring the threshold as the x-axis (use factor so that it is uniformly distributed)\n\nggplot\n(\ndata \n=\n prs.result\n,\n aes\n(\nx \n=\n \nfactor\n(\nThreshold\n),\n y \n=\n R2\n))\n \n+\n\n    \n# Specify that we want to print p-value on top of the bars\n\n    geom_text\n(\n\n        aes\n(\nlabel \n=\n \npaste\n(\nprint.p\n)),\n\n        vjust \n=\n \n-1.5\n,\n\n        hjust \n=\n \n0\n,\n\n        angle \n=\n \n45\n,\n\n        cex \n=\n \n4\n,\n\n        parse \n=\n \nT\n\n    \n)\n  \n+\n\n    \n# Specify the range of the plot, *1.25 to provide enough space for the p-values\n\n    scale_y_continuous\n(\nlimits \n=\n \nc\n(\n0\n,\n \nmax\n(\nprs.result\n$\nR2\n)\n \n*\n \n1.25\n))\n \n+\n\n    \n# Specify the axis labels\n\n    xlab\n(\nexpression\n(\nitalic\n(\nP\n)\n \n-\n value \n~\n threshold \n~\n \n(\nitalic\n(\nP\n)[\nT\n])))\n \n+\n\n    ylab\n(\nexpression\n(\npaste\n(\nPRS model fit:  \n,\n R \n^\n \n2\n)))\n \n+\n\n    \n# Draw a bar plot\n\n    geom_bar\n(\naes\n(\nfill \n=\n \n-\nlog10\n(\nP\n)),\n stat \n=\n \nidentity\n)\n \n+\n\n    \n# Specify the colors\n\n    scale_fill_gradient2\n(\n\n        low \n=\n \ndodgerblue\n,\n\n        high \n=\n \nfirebrick\n,\n\n        mid \n=\n \ndodgerblue\n,\n\n        midpoint \n=\n \n1e-4\n,\n\n        name \n=\n \nbquote\n(\natop\n(\n-\nlog\n[\n10\n]\n \n~\n model\n,\n italic\n(\nP\n)\n \n-\n value\n),)\n\n    \n)\n \n+\n\n    \n# Some beautification of the plot\n\n    theme_classic\n()\n \n+\n theme\n(\n\n        axis.title \n=\n element_text\n(\nface \n=\n \nbold\n,\n size \n=\n \n18\n),\n\n        axis.text \n=\n element_text\n(\nsize \n=\n \n14\n),\n\n        legend.title \n=\n element_text\n(\nface \n=\n \nbold\n,\n size \n=\n\n                                        \n18\n),\n\n        legend.text \n=\n element_text\n(\nsize \n=\n \n14\n),\n\n        axis.text.x \n=\n element_text\n(\nangle \n=\n \n45\n,\n hjust \n=\n\n                                       \n1\n)\n\n    \n)\n\n\n# save the plot\n\nggsave\n(\nEUR.height.bar.png\n,\n height \n=\n \n7\n,\n width \n=\n \n7\n)\n\n\n\n\n\n\n\n\nAn example bar plot generated using \nggplot2\n\n\n\n\nIn addition, we can visualize the relationship between the \"best\" PRS and the phenotype of interest, colored by sex\n\n\n```R tab=\"Without ggplot2\"\n\n\nRead in the files\n\n\nprs \n- read.table(\"EUR.0.2.profile\", header=T)\nheight \n- read.table(\"EUR.height\", header=T)\nsex \n- read.table(\"EUR.covariate\", header=T)\n\n\nRename the sex\n\n\nsex\n\\(Sex \n- as.factor(sex\\)\nSex)\nlevels(sex$Sex) \n- c(\"Male\", \"Female\")\n\n\nMerge the files\n\n\ndat \n- merge(merge(prs, height), sex)\n\n\nStart plotting\n\n\nplot(x=dat\n\\(SCORE, y=dat\\)\nHeight, col=\"white\",\n    xlab=\"Polygenic Score\", ylab=\"Height\")\nwith(subset(dat, Sex==\"Male\"), points(x=SCORE, y=Height, col=\"red\"))\nwith(subset(dat, Sex==\"Female\"), points(x=SCORE, y=Height, col=\"blue\"))\n\n``\n`R tab\n=\nggplot2\n\n\nlibrary\n(\nggplot2\n)\n\n\n# Read in the files\n\nprs \n-\n read.table\n(\nEUR.0.2.profile\n,\n header\n=\nT\n)\n\nheight \n-\n read.table\n(\nEUR.height\n,\n header\n=\nT\n)\n\nsex \n-\n read.table\n(\nEUR.covariate\n,\n header\n=\nT\n)\n\n\n# Rename the sex\n\nsex\n$\nSex \n-\n \nas.factor\n(\nsex\n$\nSex\n)\n\n\nlevels\n(\nsex\n$\nSex\n)\n \n-\n \nc\n(\nMale\n,\n \nFemale\n)\n\n\n# Merge the files\n\ndat \n-\n \nmerge\n(\nmerge\n(\nprs\n,\n height\n),\n sex\n)\n\n\n# Start plotting\n\nggplot\n(\ndat\n,\n aes\n(\nx\n=\nSCORE\n,\n y\n=\nHeight\n,\n color\n=\nSex\n))\n+\n\n    geom_point\n()\n+\n\n    theme_classic\n()\n+\n\n    labs\n(\nx\n=\nPolygenic Score\n,\n y\n=\nHeight\n)\n\n\n\n\n\n\n\n\nAn example scatter plot generated using \nggplot2", 
            "title": "Plotting the Results"
        }, 
        {
            "location": "/plink_visual/#plotting-the-results", 
            "text": "The P-value threshold results can be visualized using  R   Note  We will be using  prs.result  generated in  previous section   ```R tab=\"Without ggplot2\"", 
            "title": "Plotting the Results"
        }, 
        {
            "location": "/plink_visual/#we-strongly-recommend-the-use-of-ggplot2-only-follow-this-code-if-you", 
            "text": "", 
            "title": "We strongly recommend the use of ggplot2. Only follow this code if you"
        }, 
        {
            "location": "/plink_visual/#are-desperate", 
            "text": "", 
            "title": "are desperate."
        }, 
        {
            "location": "/plink_visual/#specify-that-we-want-to-generate-plot-in-eurheightbarpng", 
            "text": "png(\"EUR.height.bar.png\",\n      height=10, width=10, res=300, unit=\"in\")", 
            "title": "Specify that we want to generate plot in EUR.height.bar.png"
        }, 
        {
            "location": "/plink_visual/#first-obtain-the-colorings-based-on-the-p-value", 
            "text": "col  - suppressWarnings(colorRampPalette(c(\"dodgerblue\", \"firebrick\")))", 
            "title": "First, obtain the colorings based on the p-value"
        }, 
        {
            "location": "/plink_visual/#we-want-the-color-gradient-to-match-the-ranking-of-p-values", 
            "text": "prs.result  - prs.result[order(-log10(prs.result \\(P)),]\nprs.result\\) color  -  col(nrow(prs.result))\nprs.result  - prs.result[order(prs.result$Threshold),]", 
            "title": "We want the color gradient to match the ranking of p-values"
        }, 
        {
            "location": "/plink_visual/#generate-a-pretty-format-for-p-value-output", 
            "text": "prs.result \\(print.p  - round(prs.result\\) P, digits = 3)\nprs.result \\(print.p[!is.na(prs.result\\) print.p)   prs.result \\(print.p == 0 ]  -\n    format(prs.result\\) P[!is.na(prs.result \\(print.p)   prs.result\\) print.p == 0 ], digits = 2)\nprs.result \\(print.p  - sub(\"e\", \"*x*10^\", prs.result\\) print.p)", 
            "title": "generate a pretty format for p-value output"
        }, 
        {
            "location": "/plink_visual/#generate-the-axis-labels", 
            "text": "xlab  - expression(italic(P) - value ~ threshold ~ (italic(P)[T]))\nylab  - expression(paste(\"PRS model fit:  \", R ^ 2))", 
            "title": "Generate the axis labels"
        }, 
        {
            "location": "/plink_visual/#setup-the-drawing-area", 
            "text": "layout(t(1:2), widths=c(8.8,1.2))\npar( cex.lab=1.5, cex.axis=1.25, font.lab=2, \n    oma=c(0,0.5,0,0),\n    mar=c(4,6,0.5,0.5))", 
            "title": "Setup the drawing area"
        }, 
        {
            "location": "/plink_visual/#plotting-the-bars", 
            "text": "b - barplot(height=prs.result \\(R2, \n            col=prs.result\\) color, \n            border=NA, \n            ylim=c(0, max(prs.result$R2)*1.25), \n            axes = F, ann=F)", 
            "title": "Plotting the bars"
        }, 
        {
            "location": "/plink_visual/#plot-the-axis-labels-and-axis-ticks", 
            "text": "odd  - seq(0,nrow(prs.result)+1,2)\neven  - seq(1,nrow(prs.result),2)\naxis(side=1, at=b[odd], labels=prs.result \\(Threshold[odd], lwd=2)\naxis(side=1, at=b[even], labels=prs.result\\) Threshold[even],lwd=2)\naxis(side=1, at=c(0,b[1],2*b[length(b)]-b[length(b)-1]), labels=c(\"\",\"\",\"\"), lwd=2, lwd.tick=0)", 
            "title": "Plot the axis labels and axis ticks"
        }, 
        {
            "location": "/plink_visual/#write-the-p-value-on-top-of-each-bar", 
            "text": "text( parse(text=paste(\n    prs.result \\(print.p)), \n    x = b+0.1, \n    y =  prs.result\\) R2+ (max(prs.result \\(R2)*1.05-max(prs.result\\) R2)), \n    srt = 45)", 
            "title": "Write the p-value on top of each bar"
        }, 
        {
            "location": "/plink_visual/#now-plot-the-axis-lines", 
            "text": "box(bty='L', lwd=2)\naxis(2,las=2, lwd=2)", 
            "title": "Now plot the axis lines"
        }, 
        {
            "location": "/plink_visual/#plot-the-axis-titles", 
            "text": "title(ylab=ylab, line=4, cex.lab=1.5, font=2 )\ntitle(xlab=xlab, line=2.5, cex.lab=1.5, font=2 )", 
            "title": "Plot the axis titles"
        }, 
        {
            "location": "/plink_visual/#generate-plot-area-for-the-legend", 
            "text": "par(cex.lab=1.5, cex.axis=1.25, font.lab=2, \n      mar=c(20,0,20,4))\nprs.result  - prs.result[order(-log10(prs.result \\(P)),]\nimage(1, -log10(prs.result\\) P), t(seq_along(-log10(prs.result \\(P))), col=prs.result\\) color, axes=F,ann=F)\naxis(4,las=2,xaxs='r',yaxs='r', tck=0.2, col=\"white\")", 
            "title": "Generate plot area for the legend"
        }, 
        {
            "location": "/plink_visual/#plot-legend-title", 
            "text": "title(bquote(atop(-log[10] ~ model, italic(P) - value), ), \n          line=2, cex=1.5, font=2, adj=0)", 
            "title": "plot legend title"
        }, 
        {
            "location": "/plink_visual/#write-the-plot-to-file", 
            "text": "dev.off() `` `R tab = ggplot2  # ggplot2 is a handy package for plotting  library ( ggplot2 )  # generate a pretty format for p-value output \nprs.result $ print.p  -   round ( prs.result $ P ,  digits  =   3 ) \nprs.result $ print.p [ ! is.na ( prs.result $ print.p )   \n                       prs.result $ print.p  ==   0 ]   - \n     format ( prs.result $ P [ ! is.na ( prs.result $ print.p )   \n                            prs.result $ print.p  ==   0 ],  digits  =   2 ) \nprs.result $ print.p  -   sub ( e ,   *x*10^ ,  prs.result $ print.p )  # Initialize ggplot, requiring the threshold as the x-axis (use factor so that it is uniformly distributed) \nggplot ( data  =  prs.result ,  aes ( x  =   factor ( Threshold ),  y  =  R2 ))   + \n     # Specify that we want to print p-value on top of the bars \n    geom_text ( \n        aes ( label  =   paste ( print.p )), \n        vjust  =   -1.5 , \n        hjust  =   0 , \n        angle  =   45 , \n        cex  =   4 , \n        parse  =   T \n     )    + \n     # Specify the range of the plot, *1.25 to provide enough space for the p-values \n    scale_y_continuous ( limits  =   c ( 0 ,   max ( prs.result $ R2 )   *   1.25 ))   + \n     # Specify the axis labels \n    xlab ( expression ( italic ( P )   -  value  ~  threshold  ~   ( italic ( P )[ T ])))   + \n    ylab ( expression ( paste ( PRS model fit:   ,  R  ^   2 )))   + \n     # Draw a bar plot \n    geom_bar ( aes ( fill  =   - log10 ( P )),  stat  =   identity )   + \n     # Specify the colors \n    scale_fill_gradient2 ( \n        low  =   dodgerblue , \n        high  =   firebrick , \n        mid  =   dodgerblue , \n        midpoint  =   1e-4 , \n        name  =   bquote ( atop ( - log [ 10 ]   ~  model ,  italic ( P )   -  value ),) \n     )   + \n     # Some beautification of the plot \n    theme_classic ()   +  theme ( \n        axis.title  =  element_text ( face  =   bold ,  size  =   18 ), \n        axis.text  =  element_text ( size  =   14 ), \n        legend.title  =  element_text ( face  =   bold ,  size  = \n                                         18 ), \n        legend.text  =  element_text ( size  =   14 ), \n        axis.text.x  =  element_text ( angle  =   45 ,  hjust  = \n                                        1 ) \n     )  # save the plot \nggsave ( EUR.height.bar.png ,  height  =   7 ,  width  =   7 )     An example bar plot generated using  ggplot2   In addition, we can visualize the relationship between the \"best\" PRS and the phenotype of interest, colored by sex  ```R tab=\"Without ggplot2\"", 
            "title": "write the plot to file"
        }, 
        {
            "location": "/plink_visual/#read-in-the-files", 
            "text": "prs  - read.table(\"EUR.0.2.profile\", header=T)\nheight  - read.table(\"EUR.height\", header=T)\nsex  - read.table(\"EUR.covariate\", header=T)", 
            "title": "Read in the files"
        }, 
        {
            "location": "/plink_visual/#rename-the-sex", 
            "text": "sex \\(Sex  - as.factor(sex\\) Sex)\nlevels(sex$Sex)  - c(\"Male\", \"Female\")", 
            "title": "Rename the sex"
        }, 
        {
            "location": "/plink_visual/#merge-the-files", 
            "text": "dat  - merge(merge(prs, height), sex)", 
            "title": "Merge the files"
        }, 
        {
            "location": "/plink_visual/#start-plotting", 
            "text": "plot(x=dat \\(SCORE, y=dat\\) Height, col=\"white\",\n    xlab=\"Polygenic Score\", ylab=\"Height\")\nwith(subset(dat, Sex==\"Male\"), points(x=SCORE, y=Height, col=\"red\"))\nwith(subset(dat, Sex==\"Female\"), points(x=SCORE, y=Height, col=\"blue\")) `` `R tab = ggplot2  library ( ggplot2 )  # Read in the files \nprs  -  read.table ( EUR.0.2.profile ,  header = T ) \nheight  -  read.table ( EUR.height ,  header = T ) \nsex  -  read.table ( EUR.covariate ,  header = T )  # Rename the sex \nsex $ Sex  -   as.factor ( sex $ Sex )  levels ( sex $ Sex )   -   c ( Male ,   Female )  # Merge the files \ndat  -   merge ( merge ( prs ,  height ),  sex )  # Start plotting \nggplot ( dat ,  aes ( x = SCORE ,  y = Height ,  color = Sex )) + \n    geom_point () + \n    theme_classic () + \n    labs ( x = Polygenic Score ,  y = Height )     An example scatter plot generated using  ggplot2", 
            "title": "Start plotting"
        }, 
        {
            "location": "/prsice/", 
            "text": "An alternative to \nplink\n is \nPRSice-2\n, which automates much of the PRS analyses.\n\n\nAssuming we have the following files\n\n\n\n\n\n\n\n\nFile Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nGIANT.height.gz\n\n\nThe original summary statistic. PRSice-2 can directly apply INFO and MAF filtering on the summary statistic\n\n\n\n\n\n\nEUR.QC.bed\n\n\nThe genotype file after performing some basic filtering\n\n\n\n\n\n\nEUR.QC.bim\n\n\nThis file contains the SNPs that passed the basic filtering\n\n\n\n\n\n\nEUR.QC.fam\n\n\nThis file contains the samples that passed the basic filtering\n\n\n\n\n\n\nEUR.valid.sample\n\n\nThis file contains the samples that passed all the QC\n\n\n\n\n\n\nEUR.height\n\n\nThis file contains the phenotype of the samples\n\n\n\n\n\n\nEUR.covariate\n\n\nThis file contains the covariates of the samples\n\n\n\n\n\n\nEUR.eigenvec\n\n\nThis file contains the PCs of the samples\n\n\n\n\n\n\n\n\nAnd \nPRSice-2\n, which can be downloaded from\n\n\n\n\n\n\n\n\nOperating System\n\n\nLink\n\n\n\n\n\n\n\n\n\n\nLinux 64-bit\n\n\nv2.2.5\n\n\n\n\n\n\nOS X 64-bit\n\n\nv2.2.5\n\n\n\n\n\n\nWindows 32-bit\n\n\nv2.2.5\n\n\n\n\n\n\nWindows 64-bit\n\n\nv2.2.5\n\n\n\n\n\n\n\n\nIn this tutorial, you will only need \nPRSice.R\n and \nPRSice_XXX\n where XXX is the operation system\n\n\nRunning PRS analysis\n\n\nIt is simple to run PRSice-2. First, we need a single covariate file. This can be done with \nR\n:\n\n\ncovariate \n-\n read.table\n(\nEUR.covariate\n,\n header\n=\nT\n)\n\npcs \n-\n read.table\n(\nEUR.eigenvec\n,\n header\n=\nF\n)\n\n\ncolnames\n(\npcs\n)\n \n-\n \nc\n(\nFID\n,\nIID\n,\n \npaste0\n(\nPC\n,\n1\n:\n6\n))\n\ncov \n-\n \nmerge\n(\ncovariate\n,\n pcs\n,\n by\n=\nc\n(\nFID\n,\n \nIID\n))\n\nwrite.table\n(\ncov\n,\nEUR.cov\n,\n quote\n=\nF\n,\n row.names\n=\nF\n)\n\n\n\nwhich generates \nEUR.cov\n\n\nPRSice-2 can then be run to obtain the PRS results:\n\n\n```bash tab=\"Linux\"\nRscript PRSice.R \\\n    --prsice PRSice_linux \\\n    --base Height.QC.gz \\\n    --target EUR.QC \\\n    --keep EUR.valid.sample \\\n    --binary-target F \\\n    --pheno-file EUR.height \\\n    --cov-file EUR.cov \\\n    --maf-base MAF,0.05 \\\n    --info-base INFO,0.8 \\\n    --out EUR\n\n```bash tab=\nOS X\n\nRscript PRSice.R \\\n    --prsice PRSice_mac \\\n    --base Height.QC.gz \\\n    --target EUR.QC \\\n    --keep EUR.valid.sample \\\n    --binary-target F \\\n    --pheno-file EUR.height \\\n    --cov-file EUR.cov \\\n    --maf-base MAF,0.05 \\\n    --info-base INFO,0.8 \\\n    --out EUR\n\n\n\nbash tab=\"Windows\"\nRscript PRSice.R ^\n    --prsice PRSice_win64.exe ^\n    --base Height.QC.gz ^\n    --target EUR.QC ^\n    --keep EUR.valid.sample ^\n    --binary-target F ^\n    --pheno-file EUR.height ^\n    --cov-file EUR.cov ^\n    --maf-base MAF,0.05 ^\n    --info-base INFO,0.8 ^\n    --out EUR\n\n\nThis will automatically perform a \"high-resolution scoring\" and generate the \"best\" PRS (in \nEUR.best\n) and relevant graphs", 
            "title": "Prsice"
        }, 
        {
            "location": "/prsice/#running-prs-analysis", 
            "text": "It is simple to run PRSice-2. First, we need a single covariate file. This can be done with  R :  covariate  -  read.table ( EUR.covariate ,  header = T ) \npcs  -  read.table ( EUR.eigenvec ,  header = F )  colnames ( pcs )   -   c ( FID , IID ,   paste0 ( PC , 1 : 6 )) \ncov  -   merge ( covariate ,  pcs ,  by = c ( FID ,   IID )) \nwrite.table ( cov , EUR.cov ,  quote = F ,  row.names = F )  \nwhich generates  EUR.cov  PRSice-2 can then be run to obtain the PRS results:  ```bash tab=\"Linux\"\nRscript PRSice.R \\\n    --prsice PRSice_linux \\\n    --base Height.QC.gz \\\n    --target EUR.QC \\\n    --keep EUR.valid.sample \\\n    --binary-target F \\\n    --pheno-file EUR.height \\\n    --cov-file EUR.cov \\\n    --maf-base MAF,0.05 \\\n    --info-base INFO,0.8 \\\n    --out EUR ```bash tab= OS X \nRscript PRSice.R \\\n    --prsice PRSice_mac \\\n    --base Height.QC.gz \\\n    --target EUR.QC \\\n    --keep EUR.valid.sample \\\n    --binary-target F \\\n    --pheno-file EUR.height \\\n    --cov-file EUR.cov \\\n    --maf-base MAF,0.05 \\\n    --info-base INFO,0.8 \\\n    --out EUR  bash tab=\"Windows\"\nRscript PRSice.R ^\n    --prsice PRSice_win64.exe ^\n    --base Height.QC.gz ^\n    --target EUR.QC ^\n    --keep EUR.valid.sample ^\n    --binary-target F ^\n    --pheno-file EUR.height ^\n    --cov-file EUR.cov ^\n    --maf-base MAF,0.05 ^\n    --info-base INFO,0.8 ^\n    --out EUR  This will automatically perform a \"high-resolution scoring\" and generate the \"best\" PRS (in  EUR.best ) and relevant graphs", 
            "title": "Running PRS analysis"
        }, 
        {
            "location": "/target/", 
            "text": "Next, we'd like to perform basic quality controls (QC) on the target genotype data. \n\n\nIn this tutorial, we've simulated some samples using the 1000 genome european genotypes. \nYou can download the data \nhere\n. \n\n\nOr you can download using the following script:\n\ncurl https://github.com/choishingwan/PRS-Tutorial/raw/master/resources/EUR.zip -L -O\n\n\n\nUnzip the data as follow:\n\n\nunzip EUR.zip\n\n\n\n\nWhat's the md5sum of the genotype files?\nFile\nmd5sum\nEUR.bed\n940f5a760b41270662eba6264b262a2d\nEUR.bim\na528020cc2448aa04a7499f13bf9f16a\nEUR.covariate\nafff13f8f9e15815f2237a62b8bec00b\nEUR.fam\n17e8184fb03c690db6980bb7499d4982\nEUR.height\n052beb4cae32ac7673f1d6b9e854c85b\n\n\nNote\n\n\nWe assume PLINK is installed in your PATH directory, which allow us to use \nplink\n instead of \n./plink\n.\nIf PLINK is not in your PATH directory, replace all instance of \nplink\n in the tutorial to \n./plink\n assuming\nthe PLINK executable is located within your working directory\n\n\n\n\nGenotype file format\n\n\nBasic filterings\n\n\nThe power and validity of PRS analyses are highly dependent on \nthe quality of the base and target data, therefore \nboth data sets must be quality controlled to the high standards \nimplemented in GWAS studies, e.g. removing SNPs with low genotyping rate, \nlow minor allele frequency, violates the Hardy-Weinberg Equilibrium and\nindividuals with low genotyping rate \n(see \nMarees et al\n).\n\n\nThe following \nplink\n command perform some basic filterings\n\n\nplink \n\\\n\n    --bfile EUR \n\\\n\n    --maf \n0\n.05 \n\\\n\n    --hwe 1e-6 \n\\\n\n    --geno \n0\n.01 \n\\\n\n    --mind \n0\n.01 \n\\\n\n    --write-snplist \n\\\n\n    --make-just-fam \n\\\n\n    --out EUR.QC\n\n\nEach of the parameters corresponds to the following\n\n\n\n\n\n\n\n\nParamter\n\n\nValue\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nbfile\n\n\nEUR\n\n\nInform \nplink\n that the input genotype files should have a prefix of \nEUR\n\n\n\n\n\n\nmaf\n\n\n0.05\n\n\nFilter out any SNPs with minor allele frequency less than 0.05. Genotype error are more likely to influence SNPs with low MAF. Large sample size can adapt a lower MAF threshold\n\n\n\n\n\n\nhwe\n\n\n1e-6\n\n\nFiltering SNPs with low p-value from the Hardy-Weinberg exact test. SNPs with significant p-value from the HWE test are more likely to harbor genotyping error or are under selection. Filtering should be performed on the control samples to avoid filtering SNPs that are causal (under selection in cases)\n\n\n\n\n\n\ngeno\n\n\n0.01\n\n\nExclude SNPs that are missing in large proportion of subjects. A two pass filtering is usually performed (see \nMarees et al\n).\n\n\n\n\n\n\nmind\n\n\n0.01\n\n\nExclude individual who have a high rate of genotype missingness. This might indicate problems in the DNA sample. (see \nMarees et al\n for more details).\n\n\n\n\n\n\nmake-just-fam\n\n\n-\n\n\nInform \nplink\n to only generate the QCed sample name to avoid generating the .bed file.\n\n\n\n\n\n\nwrite-snplist\n\n\n-\n\n\nInform \nplink\n to only generate the QCed SNP list to avoid generating the .bed file.\n\n\n\n\n\n\nout\n\n\nEUR\n\n\nInform \nplink\n that all output should have a prefix of \nEUR\n\n\n\n\n\n\n\n\nHow many SNPs and samples were filtered?\n5\n samples removed due to high rate of genotype missingness\n1\n SNP removed due missing genotype data\n872\n SNPs were removed due to Hardy-Weinberg exact test results\n242,459\n SNPs were removed due to minor allele frequency\n\n\nNote\n\n\nNormally, we can generate a new genotype file using the new sample list.\nHowever,  this will use up a lot of storage space. Using \nplink\n's\n\n--extract\n, \n--exclude\n, \n--keep\n, \n--remove\n, \n--make-just-fam\n and \n--write-snplist\n functions, we can work \nsolely on the list of samples and SNPs without duplicating the \ngenotype file, therefore reducing the storage space usage.  \n\n\n\n\nFilter related samples\n\n\nRelated samples in the target data might lead to overfitted results, \nhampering the generalizability of the results. \n\n\nTo remove related samples, we first need to perform prunning to remove highly correlated SNPs:\n\nplink \n\\\n\n    --bfile EUR \n\\\n\n    --keep EUR.QC.fam \n\\\n\n    --extract EUR.QC.snplist \n\\\n\n    --indep-pairwise \n200\n \n50\n \n0\n.25 \n\\\n\n    --out EUR.QC\n\n\n\nThis will generate two files 1) \nEUR.QC.prune.in\n and 2) \nEUR.QC.prune.out\n\nAll SNPs within \nEUR.QC.prune.in\n has a pairwise \n\\(r^2 \n 0.25\\)\n\n\nSamples with more than third-degree relatedness (\n\\(\\text{pi-hat} \n 0.125\\)\n) can then be removed with \n\n\nplink \n\\\n\n    --bfile EUR \n\\\n\n    --extract EUR.QC.prune.in \n\\\n\n    --keep EUR.QC.fam \n\\\n\n    --rel-cutoff \n0\n.125 \n\\\n\n    --out EUR.QC\n\n\n\n\nHow many related samples were excluded?\n2\n samples were excluded\n\n\nNote\n\n\nA greedy algorithm is used to remove the related samples. Which depending\non the random seed used, might generate different results. To reproduce\nthe same result, you might need to specify the random seed usage. \n\n\nPLINK's related sample removal does not take into account of the sample \nphenotype. If one would like to minimize lost of cases for example, \na software called\n\nGreedyRelated\n can be used.\n\n\n\n\nRemove samples with abnormal heterozygosity rate\n\n\nIndividual with high or low heterozygosity rate can be contaminated or are inbreed.\nIt is therefore a good idea to remove these samples from our dataset before continuing the analyse.\nHeterozygosity rate can be calculated using \nplink\n after performing prunning. \n\nplink \n\\\n\n    --bfile EUR \n\\\n\n    --extract EUR.QC.prune.in \n\\\n\n    --keep EUR.QC.rel.id \n\\\n\n    --het \n\\\n\n    --out EUR.QC\n\n\n\nThis will generate the \nEUR.QC.het\n file which contains the F coefficient estimates.\nIt will be easier to filter the samples using \nR\n instead of \nawk\n:\nOpen a \nR\n section by tying \nR\n in your terminal\n\n\n```R tab=\"Without library\"\ndat \n- read.table(\"EUR.QC.het\", header=T) # Read in the EUR.het file, specify it has header\nm \n- mean(dat\n\\(F) # Calculate the mean  \ns \n- sd(dat\\)\nF) # Calculate the SD\nvalid \n- subset(dat, F \n= m+3*s \n F \n= m-3*s) # Get any samples with F coefficient within 3 SD of the population mean\nwrite.table(valid[,c(1,2)], \"EUR.valid.sample\", quote=F, row.names=F) # print FID and IID for valid samples\n\n``\n`R tab\n=\nWith data.table\n\n\nlibrary\n(\ndata.table\n)\n\n\n# Read in file\n\ndat \n-\n fread\n(\nEUR.QC.het\n)\n\n\n# Get samples with F coefficient within 3 SD of the population mean\n\nvalid \n-\n dat\n[\nF\n=\nmean\n(\nF\n)\n+3\n*\nsd\n(\nF\n)\n \n \nF\n=\nmean\n(\nF\n)\n-3\n*\nsd\n(\nF\n)]\n \n\n# print FID and IID for valid samples\n\nfwrite\n(\nvalid\n[,\nc\n(\nFID\n,\nIID\n)],\n \nEUR.valid.sample\n,\n sep\n=\n\\t\n)\n \n\n\n\nHow many samples were excluded due to high heterozygosity rate?\n7\n samples were excluded\nCheck for mis-matched Sex information\n\n\nSometimes, sample mislabeling can occur and will lead to invalid results. \nA good indication of mislabeled sample is a mismatch between the biological sex and the reported sex. \nIf the biological sex does not match up with the reported sex, it is likely that the sample has been mislabeled.\n\n\nBefore performing sex check, prunning should be performed (see \nhere\n).\nSex check can then easily be carried out using \nplink\n\n\nplink \n\\\n\n    --bfile EUR \n\\\n\n    --extract EUR.QC.prune.in \n\\\n\n    --keep EUR.valid.sample \n\\\n\n    --check-sex \n\\\n\n    --out EUR.QC\n\n\n\nThis will generate a file called \nEUR.sexcheck\n containing the F-statistics for each individual.\nFor male, the F-statistic should be \n 0.8 and Female should have a value \n 0.2.\n\n\n```R tab=\"Without library\"\n\n\nRead in file\n\n\nvalid \n- read.table(\"EUR.valid.sample\", header=T)\ndat \n- read.table(\"EUR.QC.sexcheck\", header=T)\nvalid \n- subset(dat, STATUS==\"OK\" \n FID %in% valid$FID)\nwrite.table(valid[,c(\"FID\", \"IID\")], \"EUR.QC.valid\", row.names=F, col.names=F, sep=\"\\t\") \n\n``\n`R tab\n=\nWith data.table\n\n\nlibrary\n(\ndata.table\n)\n\n\n# Read in file\n\nvalid \n-\n fread\n(\nEUR.valid.sample\n)\n\ndat \n-\n fread\n(\nEUR.QC.sexcheck\n)[\nFID\n%in%\nvalid\n$\nFID\n]\n\nfwrite\n(\ndat\n[\nSTATUS\n==\nOK\n,\nc\n(\nFID\n,\nIID\n)],\n \nEUR.QC.valid\n,\n sep\n=\n\\t\n)\n \n\n\n\nHow many samples were excluded due mismatched Sex information?\n2\n samples were excluded\nGenerate final QCed sample\n\n\nAfter performing the full analysis, you can generate a QCed data set with the following command\n\nplink \n\\\n\n    --bfile EUR \n\\\n\n    --make-bed \n\\\n\n    --out EUR.QC \n\\\n\n    --keep EUR.QC.valid \n\\\n\n    --extract EUR.QC.snplist\n\n\n\n\n\nNote\n\n\nFor some software, the \nEUR.QC.valid\n and \nEUR.QC.snplist\n can be passed as a parameter to perform the \nextraction directly. For those software (e.g. PRSice-2, lassosum, etc), this step is not required", 
            "title": "Target"
        }, 
        {
            "location": "/target/#genotype-file-format", 
            "text": "", 
            "title": "Genotype file format"
        }, 
        {
            "location": "/target/#basic-filterings", 
            "text": "The power and validity of PRS analyses are highly dependent on \nthe quality of the base and target data, therefore \nboth data sets must be quality controlled to the high standards \nimplemented in GWAS studies, e.g. removing SNPs with low genotyping rate, \nlow minor allele frequency, violates the Hardy-Weinberg Equilibrium and\nindividuals with low genotyping rate \n(see  Marees et al ).  The following  plink  command perform some basic filterings  plink  \\ \n    --bfile EUR  \\ \n    --maf  0 .05  \\ \n    --hwe 1e-6  \\ \n    --geno  0 .01  \\ \n    --mind  0 .01  \\ \n    --write-snplist  \\ \n    --make-just-fam  \\ \n    --out EUR.QC \nEach of the parameters corresponds to the following     Paramter  Value  Description      bfile  EUR  Inform  plink  that the input genotype files should have a prefix of  EUR    maf  0.05  Filter out any SNPs with minor allele frequency less than 0.05. Genotype error are more likely to influence SNPs with low MAF. Large sample size can adapt a lower MAF threshold    hwe  1e-6  Filtering SNPs with low p-value from the Hardy-Weinberg exact test. SNPs with significant p-value from the HWE test are more likely to harbor genotyping error or are under selection. Filtering should be performed on the control samples to avoid filtering SNPs that are causal (under selection in cases)    geno  0.01  Exclude SNPs that are missing in large proportion of subjects. A two pass filtering is usually performed (see  Marees et al ).    mind  0.01  Exclude individual who have a high rate of genotype missingness. This might indicate problems in the DNA sample. (see  Marees et al  for more details).    make-just-fam  -  Inform  plink  to only generate the QCed sample name to avoid generating the .bed file.    write-snplist  -  Inform  plink  to only generate the QCed SNP list to avoid generating the .bed file.    out  EUR  Inform  plink  that all output should have a prefix of  EUR     How many SNPs and samples were filtered? 5  samples removed due to high rate of genotype missingness 1  SNP removed due missing genotype data 872  SNPs were removed due to Hardy-Weinberg exact test results 242,459  SNPs were removed due to minor allele frequency  Note  Normally, we can generate a new genotype file using the new sample list.\nHowever,  this will use up a lot of storage space. Using  plink 's --extract ,  --exclude ,  --keep ,  --remove ,  --make-just-fam  and  --write-snplist  functions, we can work \nsolely on the list of samples and SNPs without duplicating the \ngenotype file, therefore reducing the storage space usage.", 
            "title": "Basic filterings"
        }, 
        {
            "location": "/target/#filter-related-samples", 
            "text": "Related samples in the target data might lead to overfitted results, \nhampering the generalizability of the results.   To remove related samples, we first need to perform prunning to remove highly correlated SNPs: plink  \\ \n    --bfile EUR  \\ \n    --keep EUR.QC.fam  \\ \n    --extract EUR.QC.snplist  \\ \n    --indep-pairwise  200   50   0 .25  \\ \n    --out EUR.QC  This will generate two files 1)  EUR.QC.prune.in  and 2)  EUR.QC.prune.out \nAll SNPs within  EUR.QC.prune.in  has a pairwise  \\(r^2   0.25\\)  Samples with more than third-degree relatedness ( \\(\\text{pi-hat}   0.125\\) ) can then be removed with   plink  \\ \n    --bfile EUR  \\ \n    --extract EUR.QC.prune.in  \\ \n    --keep EUR.QC.fam  \\ \n    --rel-cutoff  0 .125  \\ \n    --out EUR.QC  How many related samples were excluded? 2  samples were excluded  Note  A greedy algorithm is used to remove the related samples. Which depending\non the random seed used, might generate different results. To reproduce\nthe same result, you might need to specify the random seed usage.   PLINK's related sample removal does not take into account of the sample \nphenotype. If one would like to minimize lost of cases for example, \na software called GreedyRelated  can be used.", 
            "title": "Filter related samples"
        }, 
        {
            "location": "/target/#remove-samples-with-abnormal-heterozygosity-rate", 
            "text": "Individual with high or low heterozygosity rate can be contaminated or are inbreed.\nIt is therefore a good idea to remove these samples from our dataset before continuing the analyse.\nHeterozygosity rate can be calculated using  plink  after performing prunning.  plink  \\ \n    --bfile EUR  \\ \n    --extract EUR.QC.prune.in  \\ \n    --keep EUR.QC.rel.id  \\ \n    --het  \\ \n    --out EUR.QC  This will generate the  EUR.QC.het  file which contains the F coefficient estimates.\nIt will be easier to filter the samples using  R  instead of  awk :\nOpen a  R  section by tying  R  in your terminal  ```R tab=\"Without library\"\ndat  - read.table(\"EUR.QC.het\", header=T) # Read in the EUR.het file, specify it has header\nm  - mean(dat \\(F) # Calculate the mean  \ns  - sd(dat\\) F) # Calculate the SD\nvalid  - subset(dat, F  = m+3*s   F  = m-3*s) # Get any samples with F coefficient within 3 SD of the population mean\nwrite.table(valid[,c(1,2)], \"EUR.valid.sample\", quote=F, row.names=F) # print FID and IID for valid samples `` `R tab = With data.table  library ( data.table )  # Read in file \ndat  -  fread ( EUR.QC.het )  # Get samples with F coefficient within 3 SD of the population mean \nvalid  -  dat [ F = mean ( F ) +3 * sd ( F )     F = mean ( F ) -3 * sd ( F )]   # print FID and IID for valid samples \nfwrite ( valid [, c ( FID , IID )],   EUR.valid.sample ,  sep = \\t )    How many samples were excluded due to high heterozygosity rate? 7  samples were excluded", 
            "title": "Remove samples with abnormal heterozygosity rate"
        }, 
        {
            "location": "/target/#check-for-mis-matched-sex-information", 
            "text": "Sometimes, sample mislabeling can occur and will lead to invalid results. \nA good indication of mislabeled sample is a mismatch between the biological sex and the reported sex. \nIf the biological sex does not match up with the reported sex, it is likely that the sample has been mislabeled.  Before performing sex check, prunning should be performed (see  here ).\nSex check can then easily be carried out using  plink  plink  \\ \n    --bfile EUR  \\ \n    --extract EUR.QC.prune.in  \\ \n    --keep EUR.valid.sample  \\ \n    --check-sex  \\ \n    --out EUR.QC  This will generate a file called  EUR.sexcheck  containing the F-statistics for each individual.\nFor male, the F-statistic should be   0.8 and Female should have a value   0.2.  ```R tab=\"Without library\"", 
            "title": "Check for mis-matched Sex information"
        }, 
        {
            "location": "/target/#read-in-file", 
            "text": "valid  - read.table(\"EUR.valid.sample\", header=T)\ndat  - read.table(\"EUR.QC.sexcheck\", header=T)\nvalid  - subset(dat, STATUS==\"OK\"   FID %in% valid$FID)\nwrite.table(valid[,c(\"FID\", \"IID\")], \"EUR.QC.valid\", row.names=F, col.names=F, sep=\"\\t\")  `` `R tab = With data.table  library ( data.table )  # Read in file \nvalid  -  fread ( EUR.valid.sample ) \ndat  -  fread ( EUR.QC.sexcheck )[ FID %in% valid $ FID ] \nfwrite ( dat [ STATUS == OK , c ( FID , IID )],   EUR.QC.valid ,  sep = \\t )    How many samples were excluded due mismatched Sex information? 2  samples were excluded", 
            "title": "Read in file"
        }, 
        {
            "location": "/target/#generate-final-qced-sample", 
            "text": "After performing the full analysis, you can generate a QCed data set with the following command plink  \\ \n    --bfile EUR  \\ \n    --make-bed  \\ \n    --out EUR.QC  \\ \n    --keep EUR.QC.valid  \\ \n    --extract EUR.QC.snplist   Note  For some software, the  EUR.QC.valid  and  EUR.QC.snplist  can be passed as a parameter to perform the \nextraction directly. For those software (e.g. PRSice-2, lassosum, etc), this step is not required", 
            "title": "Generate final QCed sample"
        }
    ]
}